<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Diagnostics | Statistical Methods II</title>
  <meta name="description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="generator" content="bookdown 0.20.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Diagnostics | Statistical Methods II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="github-repo" content="dereksonderegger/STA_571_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Diagnostics | Statistical Methods II" />
  
  <meta name="twitter:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  

<meta name="author" content="Derek L. Sonderegger" />


<meta name="date" content="2020-10-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="6-two-way-anova.html"/>
<link rel="next" href="8-LogTransformations-Chapter.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Methods II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Statistical Theory</b></span></li>
<li class="chapter" data-level="1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html"><i class="fa fa-check"></i><b>1</b> Matrix Manipulation</a>
<ul>
<li class="chapter" data-level="" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="1.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_Introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#types-of-matrices"><i class="fa fa-check"></i><b>1.2</b> Types of Matrices</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalars"><i class="fa fa-check"></i><b>1.2.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vectors"><i class="fa fa-check"></i><b>1.2.2</b> Vectors</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix"><i class="fa fa-check"></i><b>1.2.3</b> Matrix</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#square-matrices"><i class="fa fa-check"></i><b>1.2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#symmetric-matrices"><i class="fa fa-check"></i><b>1.2.5</b> Symmetric Matrices</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#diagonal-matrices"><i class="fa fa-check"></i><b>1.2.6</b> Diagonal Matrices</a></li>
<li class="chapter" data-level="1.2.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#identity-matrices"><i class="fa fa-check"></i><b>1.2.7</b> Identity Matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#operations-on-matrices"><i class="fa fa-check"></i><b>1.3</b> Operations on Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#transpose"><i class="fa fa-check"></i><b>1.3.1</b> Transpose</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#addition-and-subtraction"><i class="fa fa-check"></i><b>1.3.2</b> Addition and Subtraction</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#multiplication"><i class="fa fa-check"></i><b>1.3.3</b> Multiplication</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vector-multiplication"><i class="fa fa-check"></i><b>1.3.4</b> Vector Multiplication</a></li>
<li class="chapter" data-level="1.3.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.3.5</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="1.3.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalar-times-a-matrix"><i class="fa fa-check"></i><b>1.3.6</b> Scalar times a Matrix</a></li>
<li class="chapter" data-level="1.3.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#determinant"><i class="fa fa-check"></i><b>1.3.7</b> Determinant</a></li>
<li class="chapter" data-level="1.3.8" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#inverse"><i class="fa fa-check"></i><b>1.3.8</b> Inverse</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#Exercises_MatrixTheory"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html"><i class="fa fa-check"></i><b>2</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#model-specifications"><i class="fa fa-check"></i><b>2.2</b> Model Specifications</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#simple-regression"><i class="fa fa-check"></i><b>2.2.1</b> Simple Regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#anova-model"><i class="fa fa-check"></i><b>2.2.2</b> ANOVA model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#parameter-estimation-1"><i class="fa fa-check"></i><b>2.3</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-location-paramters"><i class="fa fa-check"></i><b>2.3.1</b> Estimation of Location Paramters</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-variance-parameter"><i class="fa fa-check"></i><b>2.3.2</b> Estimation of Variance Parameter</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#standard-errors"><i class="fa fa-check"></i><b>2.4</b> Standard Errors</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#expectation-and-variance-of-a-random-vector"><i class="fa fa-check"></i><b>2.4.1</b> Expectation and variance of a random vector</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#variance-of-location-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Variance of Location Parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#summary-of-pertinent-results"><i class="fa fa-check"></i><b>2.4.3</b> Summary of pertinent results</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#r-example"><i class="fa fa-check"></i><b>2.5</b> R example</a></li>
<li class="chapter" data-level="2.6" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#Exercises_Estimation"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-inference.html"><a href="3-inference.html"><i class="fa fa-check"></i><b>3</b> Inference</a>
<ul>
<li class="chapter" data-level="" data-path="3-inference.html"><a href="3-inference.html#Inference_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="3.1" data-path="3-inference.html"><a href="3-inference.html#Inference_Introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-inference.html"><a href="3-inference.html#confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>3.2</b> Confidence Intervals and Hypothesis Tests</a></li>
<li class="chapter" data-level="3.3" data-path="3-inference.html"><a href="3-inference.html#f-tests"><i class="fa fa-check"></i><b>3.3</b> F-tests</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-inference.html"><a href="3-inference.html#theory"><i class="fa fa-check"></i><b>3.3.1</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-inference.html"><a href="3-inference.html#example"><i class="fa fa-check"></i><b>3.4</b> Example</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-inference.html"><a href="3-inference.html#testing-all-covariates"><i class="fa fa-check"></i><b>3.4.1</b> Testing All Covariates</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-inference.html"><a href="3-inference.html#testing-a-single-covariate"><i class="fa fa-check"></i><b>3.4.2</b> Testing a Single Covariate</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-inference.html"><a href="3-inference.html#testing-a-subset-of-covariates"><i class="fa fa-check"></i><b>3.4.3</b> Testing a Subset of Covariates</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-inference.html"><a href="3-inference.html#Inference_Exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-contrasts.html"><a href="4-contrasts.html"><i class="fa fa-check"></i><b>4</b> Contrasts</a>
<ul>
<li class="chapter" data-level="" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_Introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#estimate-and-variance"><i class="fa fa-check"></i><b>4.2</b> Estimate and variance</a></li>
<li class="chapter" data-level="4.3" data-path="4-contrasts.html"><a href="4-contrasts.html#estimating-contrasts-using-glht"><i class="fa fa-check"></i><b>4.3</b> Estimating contrasts using <code>glht()</code></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_glht_OneWayAnova"><i class="fa fa-check"></i><b>4.3.1</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_emmeans"><i class="fa fa-check"></i><b>4.4</b> Using <code>emmeans</code> Package</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_SimpleRegression"><i class="fa fa-check"></i><b>4.4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_OneWayAnova"><i class="fa fa-check"></i><b>4.4.2</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-contrasts.html"><a href="4-contrasts.html#Exercises_Contrasts"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>Statistical Models</b></span></li>
<li class="chapter" data-level="5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html"><i class="fa fa-check"></i><b>5</b> Analysis of Covariance (ANCOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Additive"><i class="fa fa-check"></i><b>5.2</b> Offset parallel Lines (aka additive models)</a></li>
<li class="chapter" data-level="5.3" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Interaction"><i class="fa fa-check"></i><b>5.3</b> Lines with different slopes (aka Interaction model)</a></li>
<li class="chapter" data-level="5.4" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Iris_Example"><i class="fa fa-check"></i><b>5.4</b> Iris Example</a></li>
<li class="chapter" data-level="5.5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html"><i class="fa fa-check"></i><b>6</b> Two-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#review-of-1-way-anova"><i class="fa fa-check"></i><b>6.1</b> Review of 1-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#an-example"><i class="fa fa-check"></i><b>6.1.1</b> An Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>6.1.2</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#pairwise-comparisons"><i class="fa fa-check"></i><b>6.1.3</b> Pairwise Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#two-way-anova-1"><i class="fa fa-check"></i><b>6.2</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#orthogonality"><i class="fa fa-check"></i><b>6.3</b> Orthogonality</a></li>
<li class="chapter" data-level="6.4" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#main-effects-model"><i class="fa fa-check"></i><b>6.4</b> Main Effects Model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees"><i class="fa fa-check"></i><b>6.4.1</b> Example - Fruit Trees</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table"><i class="fa fa-check"></i><b>6.4.2</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.4.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#estimating-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#interaction-model"><i class="fa fa-check"></i><b>6.5</b> Interaction Model</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table-1"><i class="fa fa-check"></i><b>6.5.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.5.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees-continued"><i class="fa fa-check"></i><b>6.5.2</b> Example - Fruit Trees (continued)</a></li>
<li class="chapter" data-level="6.5.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---warpbreaks"><i class="fa fa-check"></i><b>6.5.3</b> Example - Warpbreaks</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#Exercises_TwoWayANOVA"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html"><i class="fa fa-check"></i><b>7</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#detecting-assumption-violations"><i class="fa fa-check"></i><b>7.1</b> Detecting Assumption Violations</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#measures-of-influence"><i class="fa fa-check"></i><b>7.1.1</b> Measures of Influence</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.1.2</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#Exercises_Diagnostics"><i class="fa fa-check"></i><b>7.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html"><i class="fa fa-check"></i><b>8</b> Data Transformations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#a-review-of-logx-and-ex"><i class="fa fa-check"></i><b>8.1</b> A review of <span class="math inline">\(\log(x)\)</span> and <span class="math inline">\(e^x\)</span></a></li>
<li class="chapter" data-level="8.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-response"><i class="fa fa-check"></i><b>8.2</b> Transforming the Response</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#box-cox-family-of-transformations"><i class="fa fa-check"></i><b>8.2.1</b> Box-Cox Family of Transformations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-predictors"><i class="fa fa-check"></i><b>8.3</b> Transforming the predictors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#polynomials-of-a-predictor"><i class="fa fa-check"></i><b>8.3.1</b> Polynomials of a predictor</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-and-square-root-of-a-predictor"><i class="fa fa-check"></i><b>8.3.2</b> Log and Square Root of a predictor</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#galapagos-example"><i class="fa fa-check"></i><b>8.3.3</b> Galapagos Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#interpretation-of-log_10-and-log-transformed-variables"><i class="fa fa-check"></i><b>8.4</b> Interpretation of <span class="math inline">\(\log_{10}\)</span> and <span class="math inline">\(\log\)</span> transformed variables</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-un-transformed-covariates"><i class="fa fa-check"></i><b>8.4.1</b> Log-transformed response, un-transformed covariates</a></li>
<li class="chapter" data-level="8.4.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#un-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.2</b> Un-transformed response, log-transformed covariate</a></li>
<li class="chapter" data-level="8.4.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.3</b> Log-transformed response, log-transformed covariate</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#Transformation-Exercises"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-MultipleRegression-Chapter.html"><a href="9-MultipleRegression-Chapter.html"><i class="fa fa-check"></i><b>9</b> Multiple Regression</a></li>
<li class="chapter" data-level="10" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html"><i class="fa fa-check"></i><b>10</b> Correlated Covariates</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#interpretation-with-correlated-covariates"><i class="fa fa-check"></i><b>10.1</b> Interpretation with Correlated Covariates</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html"><i class="fa fa-check"></i><b>11</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#nested-models"><i class="fa fa-check"></i><b>11.1</b> Nested Models</a></li>
<li class="chapter" data-level="11.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#testing-based-model-selection"><i class="fa fa-check"></i><b>11.2</b> Testing-Based Model Selection</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example---u.s.-life-expectancy"><i class="fa fa-check"></i><b>11.2.1</b> Example - U.S. Life Expectancy</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#criterion-based-procedures"><i class="fa fa-check"></i><b>11.3</b> Criterion Based Procedures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#information-criterions"><i class="fa fa-check"></i><b>11.3.1</b> Information Criterions</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#adjusted-r-sq"><i class="fa fa-check"></i><b>11.3.2</b> Adjusted <code>R-sq</code></a></li>
<li class="chapter" data-level="11.3.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example-1"><i class="fa fa-check"></i><b>11.3.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#Exercises_VariableSelection"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-too-many-predictors-toomanypredictors-chapter.html"><a href="12-too-many-predictors-toomanypredictors-chapter.html"><i class="fa fa-check"></i><b>12</b> Too many Predictors {#TooManyPredictors_Chapter</a></li>
<li class="chapter" data-level="13" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#block-designs"><i class="fa fa-check"></i><b>13.1</b> Block Designs</a></li>
<li class="chapter" data-level="13.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#randomized-complete-block-design-rcbd"><i class="fa fa-check"></i><b>13.2</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="13.3" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#review-of-maximum-likelihood-methods"><i class="fa fa-check"></i><b>13.3</b> Review of Maximum Likelihood Methods</a></li>
<li class="chapter" data-level="13.4" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#way-anova-with-a-random-effect"><i class="fa fa-check"></i><b>13.4</b> 1-way ANOVA with a random effect</a></li>
<li class="chapter" data-level="13.5" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#blocks-as-random-variables"><i class="fa fa-check"></i><b>13.5</b> Blocks as Random Variables</a></li>
<li class="chapter" data-level="13.6" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#nested-effects"><i class="fa fa-check"></i><b>13.6</b> Nested Effects</a></li>
<li class="chapter" data-level="13.7" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#crossed-effects"><i class="fa fa-check"></i><b>13.7</b> Crossed Effects</a></li>
<li class="chapter" data-level="13.8" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#repeated-measures-longitudinal-studies"><i class="fa fa-check"></i><b>13.8</b> Repeated Measures / Longitudinal Studies</a></li>
<li class="chapter" data-level="13.9" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-and-prediction-intervals"><i class="fa fa-check"></i><b>13.9</b> Confidence and Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-intervals"><i class="fa fa-check"></i><b>13.9.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="13.9.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#prediction-intervals"><i class="fa fa-check"></i><b>13.9.2</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#Exercises_RandomEffects"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html"><i class="fa fa-check"></i><b>14</b> Binomial Regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#binomial-regression-model"><i class="fa fa-check"></i><b>14.1</b> Binomial Regression Model</a></li>
<li class="chapter" data-level="14.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#measures-of-fit-quality"><i class="fa fa-check"></i><b>14.2</b> Measures of Fit Quality</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#deviance"><i class="fa fa-check"></i><b>14.2.1</b> Deviance</a></li>
<li class="chapter" data-level="14.2.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>14.2.2</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#confidence-intervals-1"><i class="fa fa-check"></i><b>14.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="14.4" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#interpreting-model-coefficients"><i class="fa fa-check"></i><b>14.4</b> Interpreting model coefficients</a></li>
<li class="chapter" data-level="14.5" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#prediction-and-effective-dose-levels"><i class="fa fa-check"></i><b>14.5</b> Prediction and Effective Dose Levels</a></li>
<li class="chapter" data-level="14.6" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#overdispersion"><i class="fa fa-check"></i><b>14.6</b> Overdispersion</a></li>
<li class="chapter" data-level="14.7" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#roc-curves"><i class="fa fa-check"></i><b>14.7</b> ROC Curves</a></li>
<li class="chapter" data-level="14.8" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#Exercises_BinomialRegression"><i class="fa fa-check"></i><b>14.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-poisson-regression.html"><a href="15-poisson-regression.html"><i class="fa fa-check"></i><b>15</b> Poisson Regression</a></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="16" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html"><i class="fa fa-check"></i><b>16</b> Block Designs</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#randomized-complete-block-design-rcbd-1"><i class="fa fa-check"></i><b>16.1</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="16.2" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#split-plot-designs"><i class="fa fa-check"></i><b>16.2</b> Split-plot designs</a></li>
<li class="chapter" data-level="16.3" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#exercises"><i class="fa fa-check"></i><b>16.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html"><i class="fa fa-check"></i><b>17</b> Maximum Likelihood Priciple</a>
<ul>
<li class="chapter" data-level="" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#learning-outcomes-1"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="17.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#introduction-1"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#distributions"><i class="fa fa-check"></i><b>17.2</b> Distributions</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson"><i class="fa fa-check"></i><b>17.2.1</b> Poisson</a></li>
<li class="chapter" data-level="17.2.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential"><i class="fa fa-check"></i><b>17.2.2</b> Exponential</a></li>
<li class="chapter" data-level="17.2.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal"><i class="fa fa-check"></i><b>17.2.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#likelihood-function"><i class="fa fa-check"></i><b>17.3</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson-1"><i class="fa fa-check"></i><b>17.3.1</b> Poisson</a></li>
<li class="chapter" data-level="17.3.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential-example"><i class="fa fa-check"></i><b>17.3.2</b> Exponential Example</a></li>
<li class="chapter" data-level="17.3.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal-1"><i class="fa fa-check"></i><b>17.3.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#discussion"><i class="fa fa-check"></i><b>17.4</b> Discussion</a></li>
<li class="chapter" data-level="17.5" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exercises-1"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="project-appendix.html"><a href="project-appendix.html"><i class="fa fa-check"></i>Project Appendix</a>
<ul>
<li class="chapter" data-level="17.6" data-path="project-appendix.html"><a href="project-appendix.html#weeks-1-4-project-feasibility"><i class="fa fa-check"></i><b>17.6</b> Weeks 1 – 4 (Project Feasibility)</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="project-appendix.html"><a href="project-appendix.html#wibgis"><i class="fa fa-check"></i><b>17.6.1</b> WIBGIs</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Methods II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Diagnostics_Chapter" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Diagnostics</h1>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="7-Diagnostics-Chapter.html#cb175-1" aria-hidden="true"></a><span class="kw">library</span>(ggfortify)   <span class="co"># for autoplot for lm objects</span></span>
<span id="cb175-2"><a href="7-Diagnostics-Chapter.html#cb175-2" aria-hidden="true"></a><span class="kw">library</span>(emmeans)     <span class="co"># emmeans for pairwise constrasts.</span></span>
<span id="cb175-3"><a href="7-Diagnostics-Chapter.html#cb175-3" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)   <span class="co"># for dplyr, tidyr, ggplot2</span></span></code></pre></div>
<p>We will be interested in analyzing whether or not our linear model is a good model and whether or not the data violate any of the assumptions that are required. In general we will be interested in three classes of assumption violations and our diagnostic measures might be able detect one or more of the following issues:</p>
<ol style="list-style-type: decimal">
<li><p>Unusual observations that contribute too much influence to the analysis. These few observations might drastically change the outcome of the model.</p></li>
<li><p>Model misspecification. Our assumption that <span class="math inline">\(E\left[\boldsymbol{y}\right]=\boldsymbol{X}\boldsymbol{\beta}\)</span> might be wrong and we might need to include different covariates in the model to get a satisfactory result.</p></li>
<li><p>Error distribution. We have assumed that <span class="math inline">\(\epsilon_i \stackrel{iid}{\sim} N\left(0,\sigma^{2}\right)\)</span> but autocorrelation, heteroscedasticity, and non-normality might be present.</p></li>
</ol>
<p>Often problems with one of these can be corrected by transforming either the explanatory or response variables.</p>
<div id="detecting-assumption-violations" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Detecting Assumption Violations</h2>
<p>Throughout this chapter I will use data created by Francis Anscombe that show how simple linear regression can be misused. In particular, these data sets will show how our diagnostic measures will detect various departures from the model assumptions.</p>
<p>The data are available in R as a data frame <code>anscombe</code> and is loaded by default. The data consists of four datasets, each having the same linear regression <span class="math inline">\(\hat{y}=3+0.5\,x\)</span> but the data are drastically different.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="7-Diagnostics-Chapter.html#cb176-1" aria-hidden="true"></a><span class="co"># The anscombe dataset has 8 columns - x1,x2,x3,x4,y1,y2,y3,y4</span></span>
<span id="cb176-2"><a href="7-Diagnostics-Chapter.html#cb176-2" aria-hidden="true"></a><span class="co"># and I want it to have 3 columns - Set, X, Y</span></span>
<span id="cb176-3"><a href="7-Diagnostics-Chapter.html#cb176-3" aria-hidden="true"></a>Anscombe &lt;-<span class="st"> </span><span class="kw">rbind</span>( </span>
<span id="cb176-4"><a href="7-Diagnostics-Chapter.html#cb176-4" aria-hidden="true"></a>  <span class="kw">data.frame</span>(<span class="dt">x=</span>anscombe<span class="op">$</span>x1, <span class="dt">y=</span>anscombe<span class="op">$</span>y1, <span class="dt">set=</span><span class="st">&#39;Set 1&#39;</span>),</span>
<span id="cb176-5"><a href="7-Diagnostics-Chapter.html#cb176-5" aria-hidden="true"></a>  <span class="kw">data.frame</span>(<span class="dt">x=</span>anscombe<span class="op">$</span>x2, <span class="dt">y=</span>anscombe<span class="op">$</span>y2, <span class="dt">set=</span><span class="st">&#39;Set 2&#39;</span>),</span>
<span id="cb176-6"><a href="7-Diagnostics-Chapter.html#cb176-6" aria-hidden="true"></a>  <span class="kw">data.frame</span>(<span class="dt">x=</span>anscombe<span class="op">$</span>x3, <span class="dt">y=</span>anscombe<span class="op">$</span>y3, <span class="dt">set=</span><span class="st">&#39;Set 3&#39;</span>),</span>
<span id="cb176-7"><a href="7-Diagnostics-Chapter.html#cb176-7" aria-hidden="true"></a>  <span class="kw">data.frame</span>(<span class="dt">x=</span>anscombe<span class="op">$</span>x4, <span class="dt">y=</span>anscombe<span class="op">$</span>y4, <span class="dt">set=</span><span class="st">&#39;Set 4&#39;</span>)) </span>
<span id="cb176-8"><a href="7-Diagnostics-Chapter.html#cb176-8" aria-hidden="true"></a></span>
<span id="cb176-9"><a href="7-Diagnostics-Chapter.html#cb176-9" aria-hidden="true"></a><span class="co"># order them by their x values, and add an index column</span></span>
<span id="cb176-10"><a href="7-Diagnostics-Chapter.html#cb176-10" aria-hidden="true"></a>Anscombe &lt;-<span class="st"> </span>Anscombe <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb176-11"><a href="7-Diagnostics-Chapter.html#cb176-11" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(set) <span class="op">%&gt;%</span><span class="st">       </span><span class="co"># Every subsequent action happens by dataset</span></span>
<span id="cb176-12"><a href="7-Diagnostics-Chapter.html#cb176-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">arrange</span>(x,y) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># sort them on the x-values and if tied, by y-value</span></span>
<span id="cb176-13"><a href="7-Diagnostics-Chapter.html#cb176-13" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>( <span class="dt">index =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>() ) <span class="co"># give each observation within a set, an ID number</span></span>
<span id="cb176-14"><a href="7-Diagnostics-Chapter.html#cb176-14" aria-hidden="true"></a></span>
<span id="cb176-15"><a href="7-Diagnostics-Chapter.html#cb176-15" aria-hidden="true"></a><span class="co"># Make a nice graph</span></span>
<span id="cb176-16"><a href="7-Diagnostics-Chapter.html#cb176-16" aria-hidden="true"></a><span class="kw">ggplot</span>(Anscombe, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></span>
<span id="cb176-17"><a href="7-Diagnostics-Chapter.html#cb176-17" aria-hidden="true"></a><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb176-18"><a href="7-Diagnostics-Chapter.html#cb176-18" aria-hidden="true"></a><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>set, <span class="dt">scales=</span><span class="st">&#39;free&#39;</span>) <span class="op">+</span></span>
<span id="cb176-19"><a href="7-Diagnostics-Chapter.html#cb176-19" aria-hidden="true"></a><span class="st"> </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">formula=</span>y<span class="op">~</span>x, <span class="dt">se=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<div id="measures-of-influence" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Measures of Influence</h3>
<div id="standardized-residuals-aka-studentized" class="section level4" number="7.1.1.1">
<h4><span class="header-section-number">7.1.1.1</span> Standardized Residuals (aka Studentized )</h4>
<p>Recall that we have</p>
<p><span class="math display">\[\begin{aligned}\hat{\boldsymbol{y}}   
  &amp;=    \boldsymbol{X}\hat{\boldsymbol{\beta}}\\
    &amp;=  \boldsymbol{X}\left(\boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\boldsymbol{y}\\
    &amp;=  \boldsymbol{H}\boldsymbol{y}\\
\end{aligned}\]</span></p>
<p>where the “Hat Matrix” is <span class="math inline">\(\boldsymbol{H}=\boldsymbol{X}\left(\boldsymbol{X}^{T}\boldsymbol{X}\right)^{-1}\boldsymbol{X}^{T}\)</span> because we have <span class="math inline">\(\hat{\boldsymbol{y}}=\boldsymbol{H}\boldsymbol{y}\)</span>. The elements of <span class="math inline">\(\boldsymbol{H}\)</span> can be quite useful in diagnostics. It can be shown that the variance of the <span class="math inline">\(i\)</span>the residual is
<span class="math display">\[Var\left(\hat{\epsilon}_{i}\right)=\sigma^{2}\left(1-\boldsymbol{H}_{ii}\right)\]</span>
where <span class="math inline">\(\boldsymbol{H}_{ii}\)</span> is the <span class="math inline">\(i\)</span>th element of the main diagonal of <span class="math inline">\(\boldsymbol{H}\)</span>. This suggests that I could rescale my residuals to
<span class="math display">\[\hat{\epsilon}_{i}^{*}=\frac{\hat{\epsilon}_{i}}{\hat{\sigma}\sqrt{1-\boldsymbol{H}_{ii}}}\]</span> which, if the normality and homoscedasticity assumptions hold, should behave as a <span class="math inline">\(N\left(0,1\right)\)</span> sample.</p>
<p>These rescaled residuals are called “studentized residuals”, though R typically refers to them as “standardized”. Since we have a good intuition about the scale of a standard normal distribution, the scale of standardized residuals will give a good indicator if normality is violated.</p>
<p>There are actually two types of studentized residuals, typically called <em>internal</em> and <em>external</em> among statisticians. The version presented above is the <em>internal</em> version which can be obtained using the R function <code>rstandard()</code> while the <em>external</em> version is available using <code>rstudent()</code>. Whenever you see R present standardized residuals, they are talking about internally studentized residuals. For sake of clarity, I will use the term <em>standardized</em> as well.</p>
<div id="example---anscombes-set-3" class="section level5" number="7.1.1.1.1">
<h5><span class="header-section-number">7.1.1.1.1</span> Example - Anscombe’s set 3</h5>
<p>For the third dataset, the outlier is the ninth observation with <span class="math inline">\(x_{9}=13\)</span> and <span class="math inline">\(y_{9}=12.74\)</span>. We calculate the standardized residuals using the function <code>rstandard()</code> and plot them</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="7-Diagnostics-Chapter.html#cb177-1" aria-hidden="true"></a>Set3 &lt;-<span class="st"> </span>Anscombe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(set <span class="op">==</span><span class="st"> &#39;Set 3&#39;</span>) <span class="co"># Just set 3</span></span>
<span id="cb177-2"><a href="7-Diagnostics-Chapter.html#cb177-2" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>Set3)               <span class="co"># Fit the regression line</span></span>
<span id="cb177-3"><a href="7-Diagnostics-Chapter.html#cb177-3" aria-hidden="true"></a>Set3<span class="op">$</span>stdresid &lt;-<span class="st"> </span><span class="kw">rstandard</span>(model)           <span class="co"># rstandard() returns the standardized residuals</span></span>
<span id="cb177-4"><a href="7-Diagnostics-Chapter.html#cb177-4" aria-hidden="true"></a></span>
<span id="cb177-5"><a href="7-Diagnostics-Chapter.html#cb177-5" aria-hidden="true"></a><span class="kw">ggplot</span>(Set3, <span class="kw">aes</span>(<span class="dt">x=</span>index, <span class="dt">y=</span>stdresid)) <span class="op">+</span><span class="st">    </span><span class="co"># make a plot</span></span>
<span id="cb177-6"><a href="7-Diagnostics-Chapter.html#cb177-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb177-7"><a href="7-Diagnostics-Chapter.html#cb177-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&#39;Observation Index&#39;</span>, </span>
<span id="cb177-8"><a href="7-Diagnostics-Chapter.html#cb177-8" aria-hidden="true"></a>       <span class="dt">y=</span><span class="st">&#39;Standardized Residuals&#39;</span>, </span>
<span id="cb177-9"><a href="7-Diagnostics-Chapter.html#cb177-9" aria-hidden="true"></a>       <span class="dt">title=</span><span class="st">&#39;Standardized Residuals vs Observation Index&#39;</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p>and we notice that the outlier residual is really big. If the model assumptions were true, then the standardized residuals should follow a standard normal distribution, and I would need to have hundreds of observations before I wouldn’t be surprised to see a residual more than 3 standard deviations from 0.</p>
</div>
</div>
<div id="leverage" class="section level4" number="7.1.1.2">
<h4><span class="header-section-number">7.1.1.2</span> Leverage</h4>
<p>The extremely large standardized residual suggests that this data point is important, but we would like to quantify how important this observation actually is.</p>
<p>One way to quantify this is to look at the elements of <span class="math inline">\(\boldsymbol{H}\)</span>. Because <span class="math display">\[\hat{y}_{i}=\sum_{j=1}^{n}\boldsymbol{H}_{ij}y_{j}\]</span>
then the <span class="math inline">\(i\)</span>th row of <span class="math inline">\(\boldsymbol{H}\)</span> is a vector of weights that tell us how influential a point <span class="math inline">\(y_{j}\)</span> is for calculating the predicted value <span class="math inline">\(\hat{y}_{i}\)</span>. If I look at just the main diagonal of <span class="math inline">\(\boldsymbol{H}\)</span>, these are how much weight a point has on its predicted value. As such, I can think of the <span class="math inline">\(\boldsymbol{H}_{ii}\)</span> as the amount of leverage a particular data point has on the regression line. It can be shown that the leverages must be <span class="math inline">\(0 \le \boldsymbol{H}_{ii} \le 1\)</span> and that <span class="math inline">\(\sum \boldsymbol{H}_{ii} = p\)</span>.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="7-Diagnostics-Chapter.html#cb178-1" aria-hidden="true"></a>Set3 &lt;-<span class="st"> </span>Anscombe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>( set <span class="op">==</span><span class="st"> &#39;Set 3&#39;</span>)</span>
<span id="cb178-2"><a href="7-Diagnostics-Chapter.html#cb178-2" aria-hidden="true"></a>Set4 &lt;-<span class="st"> </span>Anscombe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>( set <span class="op">==</span><span class="st"> &#39;Set 4&#39;</span>)</span>
<span id="cb178-3"><a href="7-Diagnostics-Chapter.html#cb178-3" aria-hidden="true"></a></span>
<span id="cb178-4"><a href="7-Diagnostics-Chapter.html#cb178-4" aria-hidden="true"></a>model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> Set3 )</span>
<span id="cb178-5"><a href="7-Diagnostics-Chapter.html#cb178-5" aria-hidden="true"></a>model4 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> Set4 )</span>
<span id="cb178-6"><a href="7-Diagnostics-Chapter.html#cb178-6" aria-hidden="true"></a></span>
<span id="cb178-7"><a href="7-Diagnostics-Chapter.html#cb178-7" aria-hidden="true"></a>X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(model3)</span>
<span id="cb178-8"><a href="7-Diagnostics-Chapter.html#cb178-8" aria-hidden="true"></a>H &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>( <span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X)</span>
<span id="cb178-9"><a href="7-Diagnostics-Chapter.html#cb178-9" aria-hidden="true"></a></span>
<span id="cb178-10"><a href="7-Diagnostics-Chapter.html#cb178-10" aria-hidden="true"></a><span class="kw">round</span>(H, <span class="dt">digits=</span><span class="dv">2</span>) </span></code></pre></div>
<pre><code>##        1     2     3    4    5    6    7    8     9    10    11
## 1   0.32  0.27  0.23 0.18 0.14 0.09 0.05 0.00 -0.05 -0.09 -0.14
## 2   0.27  0.24  0.20 0.16 0.13 0.09 0.05 0.02 -0.02 -0.05 -0.09
## 3   0.23  0.20  0.17 0.15 0.12 0.09 0.06 0.04  0.01 -0.02 -0.05
## 4   0.18  0.16  0.15 0.13 0.11 0.09 0.07 0.05  0.04  0.02  0.00
## 5   0.14  0.13  0.12 0.11 0.10 0.09 0.08 0.07  0.06  0.05  0.05
## 6   0.09  0.09  0.09 0.09 0.09 0.09 0.09 0.09  0.09  0.09  0.09
## 7   0.05  0.05  0.06 0.07 0.08 0.09 0.10 0.11  0.12  0.13  0.14
## 8   0.00  0.02  0.04 0.05 0.07 0.09 0.11 0.13  0.15  0.16  0.18
## 9  -0.05 -0.02  0.01 0.04 0.06 0.09 0.12 0.15  0.17  0.20  0.23
## 10 -0.09 -0.05 -0.02 0.02 0.05 0.09 0.13 0.16  0.20  0.24  0.27
## 11 -0.14 -0.09 -0.05 0.00 0.05 0.09 0.14 0.18  0.23  0.27  0.32</code></pre>
<p>Fortunately there is already a function <code>hatvalues()</code> to compute these <span class="math inline">\(\boldsymbol{H}_{ii}\)</span> values for me. We will compare the leverages from Anscombe’s set 3 versus set 4.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="7-Diagnostics-Chapter.html#cb180-1" aria-hidden="true"></a>Set3 &lt;-<span class="st"> </span>Set3 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">leverage =</span> <span class="kw">hatvalues</span>(model3))  <span class="co"># add leverage columns</span></span>
<span id="cb180-2"><a href="7-Diagnostics-Chapter.html#cb180-2" aria-hidden="true"></a>Set4 &lt;-<span class="st"> </span>Set4 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">leverage =</span> <span class="kw">hatvalues</span>(model4))</span>
<span id="cb180-3"><a href="7-Diagnostics-Chapter.html#cb180-3" aria-hidden="true"></a></span>
<span id="cb180-4"><a href="7-Diagnostics-Chapter.html#cb180-4" aria-hidden="true"></a><span class="kw">ggplot</span>( <span class="kw">rbind</span>(Set3,Set4), <span class="kw">aes</span>(<span class="dt">x=</span>index, <span class="dt">y=</span>leverage) ) <span class="op">+</span></span>
<span id="cb180-5"><a href="7-Diagnostics-Chapter.html#cb180-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb180-6"><a href="7-Diagnostics-Chapter.html#cb180-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">facet_grid</span>( . <span class="op">~</span><span class="st"> </span>set )</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
<p>This leverage idea only picks out the <em>potential</em> for a specific value of <span class="math inline">\(x\)</span> to be influential, but does not actually measure influence. It has picked out the issue with the fourth data set, but does not adequately address the outlier in set 3.</p>
</div>
<div id="cooks-distance" class="section level4" number="7.1.1.3">
<h4><span class="header-section-number">7.1.1.3</span> Cook’s Distance</h4>
<p>To attempt to measure the actual influence of an observation <span class="math inline">\(\left\{ y_{i},\boldsymbol{x}_{i}^{T}\right\}\)</span> on the linear model, we consider the effect on the regression if we removed the observation and fit the same model. Let <span class="math display">\[\hat{\boldsymbol{y}}=\boldsymbol{X}\hat{\boldsymbol{\beta}}\]</span>
be the vector of predicted values, where <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is created using all of the data, and <span class="math inline">\(\hat{\boldsymbol{y}}_{(i)}=\boldsymbol{X}\hat{\boldsymbol{\beta}}_{(i)}\)</span> be the vector of predicted values where <span class="math inline">\(\hat{\boldsymbol{\beta}}_{(i)}\)</span> was estimated using all of the data except the <span class="math inline">\(i\)</span>th observation. Letting <span class="math inline">\(p\)</span> be the number of <span class="math inline">\(\beta_{j}\)</span> parameters as usual we define Cook’s distance of the <span class="math inline">\(i\)</span>th observation as
<span class="math display">\[ D_{i} = \frac{\left(\hat{\boldsymbol{y}}-\hat{\boldsymbol{y}}_{(i)}\right)^{T}\left(\hat{\boldsymbol{y}}-\hat{\boldsymbol{y}}_{(i)}\right)}{p\hat{\sigma}^{2}} = \frac{\sum_{j=1}^n(\hat{y}_{j}-(\hat{y}_{(i)})_j)^2}{p\hat{\sigma}^2}\]</span>
which boils down to saying if the predicted values have large changes when the <span class="math inline">\(i\)</span>th element is removed, then the distance is big. It can be shown that this formula can be simplified to
<span class="math display">\[D_{i}=\frac{\hat{\epsilon}_{i}^{*}\boldsymbol{H}_{ii}}{p\left(1-H_{ii}\right)}\]</span>
which expresses Cook’s distance in terms of the <span class="math inline">\(i\)</span>th studentized residual and the <span class="math inline">\(i\)</span>th leverage.</p>
<p>Nicely, the R function <code>cooks.distance()</code> will calculate Cook’s distance.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="7-Diagnostics-Chapter.html#cb181-1" aria-hidden="true"></a>Set3 &lt;-<span class="st"> </span>Set3 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">cooksd =</span> <span class="kw">cooks.distance</span>(model3))  </span>
<span id="cb181-2"><a href="7-Diagnostics-Chapter.html#cb181-2" aria-hidden="true"></a>Set4 &lt;-<span class="st"> </span>Set4 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">cooksd =</span> <span class="kw">cooks.distance</span>(model4))</span>
<span id="cb181-3"><a href="7-Diagnostics-Chapter.html#cb181-3" aria-hidden="true"></a></span>
<span id="cb181-4"><a href="7-Diagnostics-Chapter.html#cb181-4" aria-hidden="true"></a><span class="co"># Note: The high leverage point in set 4 has a Cook&#39;s distance of Infinity.</span></span>
<span id="cb181-5"><a href="7-Diagnostics-Chapter.html#cb181-5" aria-hidden="true"></a><span class="kw">ggplot</span>(<span class="kw">rbind</span>(Set3,Set4), <span class="kw">aes</span>(<span class="dt">x=</span>index, <span class="dt">y=</span>cooksd)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb181-6"><a href="7-Diagnostics-Chapter.html#cb181-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb181-7"><a href="7-Diagnostics-Chapter.html#cb181-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>set) <span class="op">+</span></span>
<span id="cb181-8"><a href="7-Diagnostics-Chapter.html#cb181-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;Cook&#39;s Distance&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_point).</code></pre>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<p>Some texts will give a rule of thumb that points with Cook’s distances greater than 1 should be considered influential, while other books claim a reasonable rule of thumb is <span class="math inline">\(4/\left(n-p-1\right)\)</span> where <span class="math inline">\(n\)</span> is the sample size, and <span class="math inline">\(p\)</span> is the number of parameters in <span class="math inline">\(\boldsymbol{\beta}\)</span>. My take on this, is that you should look for values that are highly different from the rest of your data.</p>
</div>
</div>
<div id="diagnostic-plots" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Diagnostic Plots</h3>
<p>After fitting a linear model in R, you have the option of looking at diagnostic plots that help to decide if any assumptions are being violated. We will step through each of the plots that are generated by the function <code>plot(model)</code> or using <code>ggplot2</code> using the package <code>ggfortify</code>.</p>
<p>In the package <code>ggfortify</code> there is a function that will calculate the diagnostics measures and add them to your dataset. This will simplify our graphing process.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="7-Diagnostics-Chapter.html#cb183-1" aria-hidden="true"></a>Set1 &lt;-<span class="st"> </span>Anscombe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(set <span class="op">==</span><span class="st"> &#39;Set 1&#39;</span>)</span>
<span id="cb183-2"><a href="7-Diagnostics-Chapter.html#cb183-2" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>Set1)</span>
<span id="cb183-3"><a href="7-Diagnostics-Chapter.html#cb183-3" aria-hidden="true"></a>Set1 &lt;-<span class="st"> </span><span class="kw">fortify</span>(model)  <span class="co"># add diagnostic measures to the dataset</span></span>
<span id="cb183-4"><a href="7-Diagnostics-Chapter.html#cb183-4" aria-hidden="true"></a>Set1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>) <span class="co"># show the dataset nicely</span></span></code></pre></div>
<pre><code>##        y  x  .hat .sigma .cooksd .fitted .resid .stdresid
## 1   4.26  4 0.318  1.273   0.123   5.000 -0.740    -0.725
## 2   5.68  5 0.236  1.310   0.004   5.501  0.179     0.166
## 3   7.24  6 0.173  1.220   0.127   6.001  1.239     1.102
## 4   4.82  7 0.127  1.147   0.154   6.501 -1.681    -1.455
## 5   6.95  8 0.100  1.311   0.000   7.001 -0.051    -0.043
## 6   8.81  9 0.091  1.218   0.062   7.501  1.309     1.110
## 7   8.04 10 0.100  1.312   0.000   8.001  0.039     0.033
## 8   8.33 11 0.127  1.310   0.002   8.501 -0.171    -0.148
## 9  10.84 12 0.173  1.100   0.279   9.001  1.839     1.635
## 10  7.58 13 0.236  1.056   0.489   9.501 -1.921    -1.778
## 11  9.96 14 0.318  1.311   0.000  10.001 -0.041    -0.041</code></pre>
<div id="residuals-vs-fitted" class="section level4" number="7.1.2.1">
<h4><span class="header-section-number">7.1.2.1</span> Residuals vs Fitted</h4>
<p>In the simple linear regression the most useful plot to look at was the residuals versus the <span class="math inline">\(x\)</span>-covariate, but we also saw that this was similar to looking at the residuals versus the fitted values. In the general linear model, we will look at the residuals versus the fitted values or possibly the studentized residuals versus the fitted values.</p>
<div id="polynomial-relationships" class="section level5" number="7.1.2.1.1">
<h5><span class="header-section-number">7.1.2.1.1</span> Polynomial relationships</h5>
<p>To explore how this plot can detect non-linear relationships between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, we will examine a data set from Ashton et al. (2007) that relates the length of a tortoise’s carapace to the number of eggs laid in a clutch. The data are</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="7-Diagnostics-Chapter.html#cb185-1" aria-hidden="true"></a>Eggs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb185-2"><a href="7-Diagnostics-Chapter.html#cb185-2" aria-hidden="true"></a>  <span class="dt">carapace    =</span> <span class="kw">c</span>(<span class="dv">284</span>,<span class="dv">290</span>,<span class="dv">290</span>,<span class="dv">290</span>,<span class="dv">298</span>,<span class="dv">299</span>,<span class="dv">302</span>,<span class="dv">306</span>,<span class="dv">306</span>,</span>
<span id="cb185-3"><a href="7-Diagnostics-Chapter.html#cb185-3" aria-hidden="true"></a>                  <span class="dv">309</span>,<span class="dv">310</span>,<span class="dv">311</span>,<span class="dv">317</span>,<span class="dv">317</span>,<span class="dv">320</span>,<span class="dv">323</span>,<span class="dv">334</span>,<span class="dv">334</span>),</span>
<span id="cb185-4"><a href="7-Diagnostics-Chapter.html#cb185-4" aria-hidden="true"></a>  <span class="dt">clutch.size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">7</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">10</span>,<span class="dv">8</span>,<span class="dv">8</span>,</span>
<span id="cb185-5"><a href="7-Diagnostics-Chapter.html#cb185-5" aria-hidden="true"></a>                  <span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">13</span>,<span class="dv">7</span>,<span class="dv">9</span>,<span class="dv">6</span>,<span class="dv">13</span>,<span class="dv">2</span>,<span class="dv">8</span>)) </span>
<span id="cb185-6"><a href="7-Diagnostics-Chapter.html#cb185-6" aria-hidden="true"></a><span class="kw">ggplot</span>(Eggs, <span class="kw">aes</span>(<span class="dt">x=</span>carapace, <span class="dt">y=</span>clutch.size)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb185-7"><a href="7-Diagnostics-Chapter.html#cb185-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>Looking at the data, it seems that we are violating the assumption that a linear model is appropriate, but we will fit the model anyway and look at the residual graph.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="7-Diagnostics-Chapter.html#cb186-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( clutch.size <span class="op">~</span><span class="st"> </span>carapace, <span class="dt">data=</span>Eggs )</span>
<span id="cb186-2"><a href="7-Diagnostics-Chapter.html#cb186-2" aria-hidden="true"></a><span class="kw">plot</span>(model, <span class="dt">which=</span><span class="dv">1</span>)      <span class="co"># Base R Function: which=1 tells R to only make the first plot</span></span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="7-Diagnostics-Chapter.html#cb187-1" aria-hidden="true"></a>lindia<span class="op">::</span><span class="kw">gg_diagnose</span>(model)                        <span class="co"># using lindia package</span></span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="7-Diagnostics-Chapter.html#cb188-1" aria-hidden="true"></a>lindia<span class="op">::</span><span class="kw">gg_diagnose</span>(model, <span class="dt">plot.all=</span><span class="ot">FALSE</span>)[[<span class="dv">3</span>]]   <span class="co"># using lindia package</span></span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="7-Diagnostics-Chapter.html#cb189-1" aria-hidden="true"></a><span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="dv">1</span>)  <span class="co"># same plot using ggplot2 and ggfortify package</span></span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-114-1.png" width="672" /></p>
<p>The blue curves going through the plot is a smoother of the residuals. Ideally this should be a flat line and I should see no trend in this plot. Clearly there is a quadratic trend as larger tortoises have larger clutch sizes until some point where the extremely large tortoises start laying fewer (perhaps the extremely large tortoises are extremely old as well). To correct for this, we should fit a model that is quadratic in <code>carapace length</code>. We will create a new covariate, <code>carapace.2</code>, which is the square of the carapace length and add it to the model.</p>
<p>In general I could write the quadratic model as
<span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i}+\beta_{2}x_{i}^{2}+\epsilon_{i}\]</span>
and note that my model is still a linear model with respect to covariates <span class="math inline">\(\boldsymbol{x}\)</span> and <span class="math inline">\(\boldsymbol{x}^{2}\)</span> because I can still write the model as
<span class="math display">\[\begin{aligned} \boldsymbol{y}    
  &amp;=    \boldsymbol{X}\boldsymbol{\beta}+\boldsymbol{\epsilon} \\
    &amp;=  \left[\begin{array}{ccc}
      1 &amp; x_{1} &amp; x_{1}^{2}\\
      1 &amp; x_{2} &amp; x_{2}^{2}\\
      1 &amp; x_{3} &amp; x_{3}^{2}\\
      \vdots &amp; \vdots &amp; \vdots\\
      1 &amp; x_{n} &amp; x_{n}^{2}
  \end{array}\right]\left[\begin{array}{c}
        \beta_{0}\\
        \beta_{1}\\
        \beta_{2}
\end{array}\right]
+
\left[\begin{array}{c}
\epsilon_{1}\\
\epsilon_{2}\\
\epsilon_{3}\\
\vdots\\
\epsilon_{n}
\end{array}\right]\end{aligned}\]</span></p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="7-Diagnostics-Chapter.html#cb190-1" aria-hidden="true"></a><span class="co"># add a new column that is carapace^2</span></span>
<span id="cb190-2"><a href="7-Diagnostics-Chapter.html#cb190-2" aria-hidden="true"></a>Eggs2 &lt;-<span class="st"> </span>Eggs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>( <span class="dt">carapace.2 =</span> carapace<span class="op">^</span><span class="dv">2</span> )</span>
<span id="cb190-3"><a href="7-Diagnostics-Chapter.html#cb190-3" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( clutch.size <span class="op">~</span><span class="st"> </span>carapace <span class="op">+</span><span class="st"> </span>carapace<span class="fl">.2</span>,    <span class="dt">data=</span>Eggs2 )</span>
<span id="cb190-4"><a href="7-Diagnostics-Chapter.html#cb190-4" aria-hidden="true"></a></span>
<span id="cb190-5"><a href="7-Diagnostics-Chapter.html#cb190-5" aria-hidden="true"></a><span class="co"># make R do it inside the formula... convenient</span></span>
<span id="cb190-6"><a href="7-Diagnostics-Chapter.html#cb190-6" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( clutch.size <span class="op">~</span><span class="st"> </span>carapace <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(carapace<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>Eggs )</span>
<span id="cb190-7"><a href="7-Diagnostics-Chapter.html#cb190-7" aria-hidden="true"></a></span>
<span id="cb190-8"><a href="7-Diagnostics-Chapter.html#cb190-8" aria-hidden="true"></a><span class="co"># Fit an arbitrary degree polynomial, I recommend this method for fitting the model!</span></span>
<span id="cb190-9"><a href="7-Diagnostics-Chapter.html#cb190-9" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( clutch.size <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(carapace, <span class="dv">2</span>),        <span class="dt">data=</span>Eggs )</span>
<span id="cb190-10"><a href="7-Diagnostics-Chapter.html#cb190-10" aria-hidden="true"></a></span>
<span id="cb190-11"><a href="7-Diagnostics-Chapter.html#cb190-11" aria-hidden="true"></a><span class="co"># If you use poly() in the formula, you must use &#39;data=&#39; here, </span></span>
<span id="cb190-12"><a href="7-Diagnostics-Chapter.html#cb190-12" aria-hidden="true"></a><span class="co"># otherwise you can skip it and R will do the right thing.</span></span>
<span id="cb190-13"><a href="7-Diagnostics-Chapter.html#cb190-13" aria-hidden="true"></a><span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="dv">1</span>, <span class="dt">data=</span>Eggs)  </span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-115-1.png" width="672" /></p>
<p>Now our residual plot versus fitted values does not show any trend, suggesting that the quadratic model is fitting the data well. Graphing the original data along with the predicted values confirms this.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="7-Diagnostics-Chapter.html#cb191-1" aria-hidden="true"></a><span class="co"># add the fitted and CI lwr/upr columns to my dataset </span></span>
<span id="cb191-2"><a href="7-Diagnostics-Chapter.html#cb191-2" aria-hidden="true"></a>Eggs &lt;-<span class="st"> </span>Eggs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb191-3"><a href="7-Diagnostics-Chapter.html#cb191-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">select</span>( <span class="op">-</span><span class="kw">matches</span>(<span class="st">&#39;fit&#39;</span>), <span class="op">-</span><span class="kw">matches</span>(<span class="st">&#39;lwr&#39;</span>), <span class="op">-</span><span class="kw">matches</span>(<span class="st">&#39;upr&#39;</span>) ) <span class="op">%&gt;%</span></span>
<span id="cb191-4"><a href="7-Diagnostics-Chapter.html#cb191-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">cbind</span>( <span class="kw">predict</span>(model, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>) )</span>
<span id="cb191-5"><a href="7-Diagnostics-Chapter.html#cb191-5" aria-hidden="true"></a></span>
<span id="cb191-6"><a href="7-Diagnostics-Chapter.html#cb191-6" aria-hidden="true"></a><span class="kw">ggplot</span>(Eggs, <span class="kw">aes</span>(<span class="dt">x=</span>carapace)) <span class="op">+</span></span>
<span id="cb191-7"><a href="7-Diagnostics-Chapter.html#cb191-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_ribbon</span>( <span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&#39;red&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb191-8"><a href="7-Diagnostics-Chapter.html#cb191-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>fit), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></span>
<span id="cb191-9"><a href="7-Diagnostics-Chapter.html#cb191-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>clutch.size)) </span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-116-1.png" width="672" /></p>
</div>
<div id="heteroskedasticity" class="section level5" number="7.1.2.1.2">
<h5><span class="header-section-number">7.1.2.1.2</span> Heteroskedasticity</h5>
<p>The plot of residuals versus fitted values can detect heteroskedasticity (non-constant variance) in the error terms.</p>
<p>To illustrate this, we turn to another dataset in the Faraway book. The dataset <code>airquality</code> uses data taken from an environmental study that measured four variables, ozone, solar radiation, temperature and wind speed for 153 consecutive days in New York. The goal is to predict the level of ozone using the weather variables.</p>
<p>We first graph all pairs of variables in the dataset.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="7-Diagnostics-Chapter.html#cb192-1" aria-hidden="true"></a><span class="kw">data</span>(airquality)</span>
<span id="cb192-2"><a href="7-Diagnostics-Chapter.html#cb192-2" aria-hidden="true"></a><span class="co"># pairs(~ Ozone + Solar.R + Wind + Temp, data=airquality)</span></span>
<span id="cb192-3"><a href="7-Diagnostics-Chapter.html#cb192-3" aria-hidden="true"></a>airquality <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>( Solar.R, Wind, Temp, Ozone) <span class="op">%&gt;%</span></span>
<span id="cb192-4"><a href="7-Diagnostics-Chapter.html#cb192-4" aria-hidden="true"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>()</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-117-1.png" width="672" /></p>
<p>and notice that ozone levels are positively correlated with solar radiation and temperature, and negatively correlated with wind speed. A linear relationship with wind might be suspect as is the increasing variability in the response to high temperature. However, we don’t know if those trends will remain after fitting the model, because there is some covariance among the predictors.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="7-Diagnostics-Chapter.html#cb193-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R <span class="op">+</span><span class="st"> </span>Wind <span class="op">+</span><span class="st"> </span>Temp, <span class="dt">data=</span>airquality)</span>
<span id="cb193-2"><a href="7-Diagnostics-Chapter.html#cb193-2" aria-hidden="true"></a><span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="dv">1</span>) </span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-118-1.png" width="672" /></p>
<p>As we feared, we have both a non-constant variance and a non-linear relationship. A transformation of the <span class="math inline">\(y\)</span> variable might be able to fix our problem.</p>
</div>
</div>
<div id="qqplots" class="section level4" number="7.1.2.2">
<h4><span class="header-section-number">7.1.2.2</span> QQplots</h4>
<p>If we are taking a sample of size <span class="math inline">\(n=10\)</span> from a standard normal distribution, then I should expect that the smallest observation will be negative. Intuitively, you would expect the smallest observation to be near the <span class="math inline">\(10\)</span>th percentile of the standard normal, and likewise the second smallest should be near the <span class="math inline">\(20\)</span>th percentile.</p>
<p>This idea needs a little modification because the largest observation cannot be near the <span class="math inline">\(100\)</span>th percentile (because that is <span class="math inline">\(\infty\)</span>). So we’ll adjust the estimates to still be spaced at <span class="math inline">\((1/n)\)</span> quantile increments, but starting at the <span class="math inline">\(0.5/n\)</span> quantile instead of the <span class="math inline">\(1/n\)</span> quantile. So the smallest observation should be near the <span class="math inline">\(0.05\)</span> quantile, the second smallest should be near the <span class="math inline">\(0.15\)</span> quantile, and the largest observation should be near the <span class="math inline">\(0.95\)</span> quantile. I will refer to these as the <em>theoretical quantiles</em>.</p>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-119-1.png" width="672" /></p>
<p>I can then graph the theoretical quantiles vs my observed values and if they lie on the 1-to-1 line, then my data comes from a standard normal distribution.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="7-Diagnostics-Chapter.html#cb194-1" aria-hidden="true"></a><span class="kw">set.seed</span>(<span class="dv">93516</span>)  <span class="co"># make random sample in the next code chunk consistant run-to-run</span></span>
<span id="cb194-2"><a href="7-Diagnostics-Chapter.html#cb194-2" aria-hidden="true"></a></span>
<span id="cb194-3"><a href="7-Diagnostics-Chapter.html#cb194-3" aria-hidden="true"></a>n &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb194-4"><a href="7-Diagnostics-Chapter.html#cb194-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">observed =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>) ) <span class="op">%&gt;%</span></span>
<span id="cb194-5"><a href="7-Diagnostics-Chapter.html#cb194-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">arrange</span>(observed) <span class="op">%&gt;%</span></span>
<span id="cb194-6"><a href="7-Diagnostics-Chapter.html#cb194-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>( <span class="dt">theoretical =</span> <span class="kw">qnorm</span>( (<span class="dv">1</span><span class="op">:</span>n <span class="fl">-.5</span>)<span class="op">/</span>n ) )</span>
<span id="cb194-7"><a href="7-Diagnostics-Chapter.html#cb194-7" aria-hidden="true"></a></span>
<span id="cb194-8"><a href="7-Diagnostics-Chapter.html#cb194-8" aria-hidden="true"></a><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x=</span>theoretical, <span class="dt">y=</span>observed) ) <span class="op">+</span><span class="st"> </span></span>
<span id="cb194-9"><a href="7-Diagnostics-Chapter.html#cb194-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb194-10"><a href="7-Diagnostics-Chapter.html#cb194-10" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_abline</span>( <span class="dt">intercept=</span><span class="dv">0</span>, <span class="dt">slope=</span><span class="dv">1</span>,  <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">alpha=</span>.<span class="dv">7</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb194-11"><a href="7-Diagnostics-Chapter.html#cb194-11" aria-hidden="true"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">main=</span><span class="st">&#39;Q-Q Plot: Observed vs Normal Distribution&#39;</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-120-1.png" width="672" /></p>
<p>In the context of a regression model, we wish to look at the residuals and see if there are obvious departures from normality. Returning to the air quality example, R will calculate the qqplot for us.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="7-Diagnostics-Chapter.html#cb195-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R <span class="op">+</span><span class="st"> </span>Wind <span class="op">+</span><span class="st"> </span>Temp, <span class="dt">data=</span>airquality)</span>
<span id="cb195-2"><a href="7-Diagnostics-Chapter.html#cb195-2" aria-hidden="true"></a><span class="kw">autoplot</span>(model, <span class="dt">which=</span><span class="dv">2</span>) </span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-121-1.png" width="672" /></p>
<p>In this case, we have a large number of residuals that are bigger than I would expect them to be based on them being from a normal distribution. We could further test this using the Shapiro-Wilks test and compare the standardized residuals against a <span class="math inline">\(N\left(0,1\right)\)</span> distribution.</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="7-Diagnostics-Chapter.html#cb196-1" aria-hidden="true"></a><span class="kw">shapiro.test</span>( <span class="kw">rstandard</span>(model) )</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rstandard(model)
## W = 0.9151, p-value = 2.819e-06</code></pre>
<p>The tail of the distribution of observed residuals is <em>far</em> from what we expect to see.</p>
</div>
<div id="scale-location-plot" class="section level4" number="7.1.2.3">
<h4><span class="header-section-number">7.1.2.3</span> Scale-Location Plot</h4>
<p>This plot is a variation on the fitted vs residuals plot, but the y-axis uses the square root of the absolute value of the standardized residuals. Supposedly this makes detecting increasing variance easier to detect, but I’m not convinced.</p>
</div>
<div id="residuals-vs-leverage-plus-cooks-distance" class="section level4" number="7.1.2.4">
<h4><span class="header-section-number">7.1.2.4</span> Residuals vs Leverage (plus Cook’s Distance)</h4>
<p>This plot lets the user examine the which observations have a high potential for being influential (i.e. high leverage) versus how large the residual is. Because Cook’s distance is a function of those two traits, we can also divide the graph up into regions by the value of Cook’s Distance.</p>
<p>Returning to Anscombe’s third set of data, we see</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="7-Diagnostics-Chapter.html#cb198-1" aria-hidden="true"></a>model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>Set3)</span>
<span id="cb198-2"><a href="7-Diagnostics-Chapter.html#cb198-2" aria-hidden="true"></a><span class="kw">autoplot</span>(model3, <span class="dt">which=</span><span class="dv">5</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-123-1.png" width="672" /></p>
<p>that one data point (observation 10) has an extremely large standardized residual. This is one plot where I prefer what the base graphics in R does compared to the <code>ggfortify</code> version. The base version of R adds some contour lines that mark where the contours of where Cook’s distance is 1/2 and 1.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="7-Diagnostics-Chapter.html#cb199-1" aria-hidden="true"></a><span class="kw">plot</span>(model3, <span class="dt">which=</span><span class="dv">5</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-124-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="Exercises_Diagnostics" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>In the ANCOVA chapter, we examined the relationship on dose of vitamin C on guinea pig tooth growth based on how the vitamin was delivered (orange juice vs a pill supplement).
<ol style="list-style-type: lower-alpha">
<li>Load the <code>ToothGrowth</code> data which is pre-loaded in base R.</li>
<li>Plot the data with <code>dose</code> level on the x-axis and tooth length growth (<code>len</code>) on the y-axis. Color the points by supplement type (<code>supp</code>).</li>
<li>Is the data evenly distributed along the x-axis? Comment on the wisdom of using this design.</li>
<li>Fit a linear model to these data and examine the diagnostic plots. What stands out to you?</li>
<li>Log-transform the dose variable and repeat parts (c) and (d). Comment on the effect of the log transformation.</li>
</ol></li>
<li>The dataset <code>infmort</code> in the <code>faraway</code> package has information about infant mortality from countries around the world. Be aware that this is a old data set and does not necessarily reflect current conditions. More information about the dataset can be found using <code>?faraway::infmort</code>. We will be interested in understanding how infant mortality is predicted by per capita income, world region, and oil export status.
<ol style="list-style-type: lower-alpha">
<li><p>Plot the relationship between income and mortality. This can be done using the command</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="7-Diagnostics-Chapter.html#cb200-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&#39;infmort&#39;</span>, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)</span>
<span id="cb200-2"><a href="7-Diagnostics-Chapter.html#cb200-2" aria-hidden="true"></a><span class="kw">pairs</span>(mortality <span class="op">~</span>., <span class="dt">data=</span>infmort)</span></code></pre></div>
<p>What do you notice about the relationship between mortality and income?</p></li>
<li><p>Fit a linear model without any interaction terms with all three covariates as predictors of infant mortality. Examine the diagnostic plots. What stands out?</p></li>
<li><p>Examine the pairs plot with log(mortality), income, and log(income). Which should be used in our model, <code>income</code> or <code>log(income)</code>?</p></li>
</ol></li>
<li>Using the <code>pressure</code> data in the <code>datasets</code> package, fit a model with pressure as the response and temperature as the predictor using transformations to obtain a good fit. Feel free to experiment with what might be considered a ridiculously complicated model with a high degree polynomial. These models can most easily be fit using the <code>poly(x, degree=p)</code> function in the formula specification where you swap out the covariate <code>x</code> and polynomial degree <code>p</code>.
<ol style="list-style-type: lower-alpha">
<li>Document your process of building your final model. Do not show graphs or computer output that is not relevant to your decision or that you do not wish to comment on.</li>
<li>Comment on the interpretability of your (possibly ridiculously complicated) model. Consider a situation where I’m designing a system where it is easy to measure temperature, but I am unable to measure pressure. Could we get by with just measuring temperature? What if I didn’t know the ideal gas law and I’m trying to better understand how temperature and pressure are related?</li>
</ol></li>
<li>We will consider the relationship between income and race using a subset of employed individuals from the American Community Survey.
<ol style="list-style-type: lower-alpha">
<li>Load the <code>EmployedACS</code> dataset from the <code>Lock5Data</code> package.</li>
<li>Create a box plot showing the relationship between <code>Race</code> and <code>Income</code>.</li>
<li>Fit an ANOVA model to this data and consider the diagnostic plots for the residuals. What do you notice?</li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="6-two-way-anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="8-LogTransformations-Chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/571/blob/master/07_Diagnostics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/dereksonderegger/571/raw/master/07_Diagnostics.Rmd",
"text": null
},
"download": [["Statistical_Methods_II.pdf", "PDF"], ["Statistical_Methods_II.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Variable Selection | Statistical Methods II</title>
  <meta name="description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="generator" content="bookdown 0.20.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Variable Selection | Statistical Methods II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="github-repo" content="dereksonderegger/STA_571_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Variable Selection | Statistical Methods II" />
  
  <meta name="twitter:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  

<meta name="author" content="Derek L. Sonderegger" />


<meta name="date" content="2020-10-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="10-CorrelatedCovariates-Chapter.html"/>
<link rel="next" href="12-too-many-predictors-toomanypredictors-chapter.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Methods II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Statistical Theory</b></span></li>
<li class="chapter" data-level="1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html"><i class="fa fa-check"></i><b>1</b> Matrix Manipulation</a>
<ul>
<li class="chapter" data-level="" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="1.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_Introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#types-of-matrices"><i class="fa fa-check"></i><b>1.2</b> Types of Matrices</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalars"><i class="fa fa-check"></i><b>1.2.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vectors"><i class="fa fa-check"></i><b>1.2.2</b> Vectors</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix"><i class="fa fa-check"></i><b>1.2.3</b> Matrix</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#square-matrices"><i class="fa fa-check"></i><b>1.2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#symmetric-matrices"><i class="fa fa-check"></i><b>1.2.5</b> Symmetric Matrices</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#diagonal-matrices"><i class="fa fa-check"></i><b>1.2.6</b> Diagonal Matrices</a></li>
<li class="chapter" data-level="1.2.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#identity-matrices"><i class="fa fa-check"></i><b>1.2.7</b> Identity Matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#operations-on-matrices"><i class="fa fa-check"></i><b>1.3</b> Operations on Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#transpose"><i class="fa fa-check"></i><b>1.3.1</b> Transpose</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#addition-and-subtraction"><i class="fa fa-check"></i><b>1.3.2</b> Addition and Subtraction</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#multiplication"><i class="fa fa-check"></i><b>1.3.3</b> Multiplication</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vector-multiplication"><i class="fa fa-check"></i><b>1.3.4</b> Vector Multiplication</a></li>
<li class="chapter" data-level="1.3.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.3.5</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="1.3.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalar-times-a-matrix"><i class="fa fa-check"></i><b>1.3.6</b> Scalar times a Matrix</a></li>
<li class="chapter" data-level="1.3.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#determinant"><i class="fa fa-check"></i><b>1.3.7</b> Determinant</a></li>
<li class="chapter" data-level="1.3.8" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#inverse"><i class="fa fa-check"></i><b>1.3.8</b> Inverse</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#Exercises_MatrixTheory"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html"><i class="fa fa-check"></i><b>2</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#model-specifications"><i class="fa fa-check"></i><b>2.2</b> Model Specifications</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#simple-regression"><i class="fa fa-check"></i><b>2.2.1</b> Simple Regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#anova-model"><i class="fa fa-check"></i><b>2.2.2</b> ANOVA model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#parameter-estimation-1"><i class="fa fa-check"></i><b>2.3</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-location-paramters"><i class="fa fa-check"></i><b>2.3.1</b> Estimation of Location Paramters</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-variance-parameter"><i class="fa fa-check"></i><b>2.3.2</b> Estimation of Variance Parameter</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#standard-errors"><i class="fa fa-check"></i><b>2.4</b> Standard Errors</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#expectation-and-variance-of-a-random-vector"><i class="fa fa-check"></i><b>2.4.1</b> Expectation and variance of a random vector</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#variance-of-location-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Variance of Location Parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#summary-of-pertinent-results"><i class="fa fa-check"></i><b>2.4.3</b> Summary of pertinent results</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#r-example"><i class="fa fa-check"></i><b>2.5</b> R example</a></li>
<li class="chapter" data-level="2.6" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#Exercises_Estimation"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-inference.html"><a href="3-inference.html"><i class="fa fa-check"></i><b>3</b> Inference</a>
<ul>
<li class="chapter" data-level="" data-path="3-inference.html"><a href="3-inference.html#Inference_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="3.1" data-path="3-inference.html"><a href="3-inference.html#Inference_Introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-inference.html"><a href="3-inference.html#confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>3.2</b> Confidence Intervals and Hypothesis Tests</a></li>
<li class="chapter" data-level="3.3" data-path="3-inference.html"><a href="3-inference.html#f-tests"><i class="fa fa-check"></i><b>3.3</b> F-tests</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-inference.html"><a href="3-inference.html#theory"><i class="fa fa-check"></i><b>3.3.1</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-inference.html"><a href="3-inference.html#example"><i class="fa fa-check"></i><b>3.4</b> Example</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-inference.html"><a href="3-inference.html#testing-all-covariates"><i class="fa fa-check"></i><b>3.4.1</b> Testing All Covariates</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-inference.html"><a href="3-inference.html#testing-a-single-covariate"><i class="fa fa-check"></i><b>3.4.2</b> Testing a Single Covariate</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-inference.html"><a href="3-inference.html#testing-a-subset-of-covariates"><i class="fa fa-check"></i><b>3.4.3</b> Testing a Subset of Covariates</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-inference.html"><a href="3-inference.html#Inference_Exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-contrasts.html"><a href="4-contrasts.html"><i class="fa fa-check"></i><b>4</b> Contrasts</a>
<ul>
<li class="chapter" data-level="" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_Introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#estimate-and-variance"><i class="fa fa-check"></i><b>4.2</b> Estimate and variance</a></li>
<li class="chapter" data-level="4.3" data-path="4-contrasts.html"><a href="4-contrasts.html#estimating-contrasts-using-glht"><i class="fa fa-check"></i><b>4.3</b> Estimating contrasts using <code>glht()</code></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_glht_OneWayAnova"><i class="fa fa-check"></i><b>4.3.1</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_emmeans"><i class="fa fa-check"></i><b>4.4</b> Using <code>emmeans</code> Package</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_SimpleRegression"><i class="fa fa-check"></i><b>4.4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_OneWayAnova"><i class="fa fa-check"></i><b>4.4.2</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-contrasts.html"><a href="4-contrasts.html#Exercises_Contrasts"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>Statistical Models</b></span></li>
<li class="chapter" data-level="5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html"><i class="fa fa-check"></i><b>5</b> Analysis of Covariance (ANCOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Additive"><i class="fa fa-check"></i><b>5.2</b> Offset parallel Lines (aka additive models)</a></li>
<li class="chapter" data-level="5.3" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Interaction"><i class="fa fa-check"></i><b>5.3</b> Lines with different slopes (aka Interaction model)</a></li>
<li class="chapter" data-level="5.4" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Iris_Example"><i class="fa fa-check"></i><b>5.4</b> Iris Example</a></li>
<li class="chapter" data-level="5.5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html"><i class="fa fa-check"></i><b>6</b> Two-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#review-of-1-way-anova"><i class="fa fa-check"></i><b>6.1</b> Review of 1-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#an-example"><i class="fa fa-check"></i><b>6.1.1</b> An Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>6.1.2</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#pairwise-comparisons"><i class="fa fa-check"></i><b>6.1.3</b> Pairwise Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#two-way-anova-1"><i class="fa fa-check"></i><b>6.2</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#orthogonality"><i class="fa fa-check"></i><b>6.3</b> Orthogonality</a></li>
<li class="chapter" data-level="6.4" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#main-effects-model"><i class="fa fa-check"></i><b>6.4</b> Main Effects Model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees"><i class="fa fa-check"></i><b>6.4.1</b> Example - Fruit Trees</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table"><i class="fa fa-check"></i><b>6.4.2</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.4.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#estimating-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#interaction-model"><i class="fa fa-check"></i><b>6.5</b> Interaction Model</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table-1"><i class="fa fa-check"></i><b>6.5.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.5.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees-continued"><i class="fa fa-check"></i><b>6.5.2</b> Example - Fruit Trees (continued)</a></li>
<li class="chapter" data-level="6.5.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---warpbreaks"><i class="fa fa-check"></i><b>6.5.3</b> Example - Warpbreaks</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#Exercises_TwoWayANOVA"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html"><i class="fa fa-check"></i><b>7</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#detecting-assumption-violations"><i class="fa fa-check"></i><b>7.1</b> Detecting Assumption Violations</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#measures-of-influence"><i class="fa fa-check"></i><b>7.1.1</b> Measures of Influence</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.1.2</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#Exercises_Diagnostics"><i class="fa fa-check"></i><b>7.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html"><i class="fa fa-check"></i><b>8</b> Data Transformations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#a-review-of-logx-and-ex"><i class="fa fa-check"></i><b>8.1</b> A review of <span class="math inline">\(\log(x)\)</span> and <span class="math inline">\(e^x\)</span></a></li>
<li class="chapter" data-level="8.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-response"><i class="fa fa-check"></i><b>8.2</b> Transforming the Response</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#box-cox-family-of-transformations"><i class="fa fa-check"></i><b>8.2.1</b> Box-Cox Family of Transformations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-predictors"><i class="fa fa-check"></i><b>8.3</b> Transforming the predictors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#polynomials-of-a-predictor"><i class="fa fa-check"></i><b>8.3.1</b> Polynomials of a predictor</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-and-square-root-of-a-predictor"><i class="fa fa-check"></i><b>8.3.2</b> Log and Square Root of a predictor</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#galapagos-example"><i class="fa fa-check"></i><b>8.3.3</b> Galapagos Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#interpretation-of-log_10-and-log-transformed-variables"><i class="fa fa-check"></i><b>8.4</b> Interpretation of <span class="math inline">\(\log_{10}\)</span> and <span class="math inline">\(\log\)</span> transformed variables</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-un-transformed-covariates"><i class="fa fa-check"></i><b>8.4.1</b> Log-transformed response, un-transformed covariates</a></li>
<li class="chapter" data-level="8.4.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#un-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.2</b> Un-transformed response, log-transformed covariate</a></li>
<li class="chapter" data-level="8.4.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.3</b> Log-transformed response, log-transformed covariate</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#Transformation-Exercises"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-MultipleRegression-Chapter.html"><a href="9-MultipleRegression-Chapter.html"><i class="fa fa-check"></i><b>9</b> Multiple Regression</a></li>
<li class="chapter" data-level="10" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html"><i class="fa fa-check"></i><b>10</b> Correlated Covariates</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#interpretation-with-correlated-covariates"><i class="fa fa-check"></i><b>10.1</b> Interpretation with Correlated Covariates</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html"><i class="fa fa-check"></i><b>11</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#nested-models"><i class="fa fa-check"></i><b>11.1</b> Nested Models</a></li>
<li class="chapter" data-level="11.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#testing-based-model-selection"><i class="fa fa-check"></i><b>11.2</b> Testing-Based Model Selection</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example---u.s.-life-expectancy"><i class="fa fa-check"></i><b>11.2.1</b> Example - U.S. Life Expectancy</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#criterion-based-procedures"><i class="fa fa-check"></i><b>11.3</b> Criterion Based Procedures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#information-criterions"><i class="fa fa-check"></i><b>11.3.1</b> Information Criterions</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#adjusted-r-sq"><i class="fa fa-check"></i><b>11.3.2</b> Adjusted <code>R-sq</code></a></li>
<li class="chapter" data-level="11.3.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example-1"><i class="fa fa-check"></i><b>11.3.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#Exercises_VariableSelection"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-too-many-predictors-toomanypredictors-chapter.html"><a href="12-too-many-predictors-toomanypredictors-chapter.html"><i class="fa fa-check"></i><b>12</b> Too many Predictors {#TooManyPredictors_Chapter</a></li>
<li class="chapter" data-level="13" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#block-designs"><i class="fa fa-check"></i><b>13.1</b> Block Designs</a></li>
<li class="chapter" data-level="13.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#randomized-complete-block-design-rcbd"><i class="fa fa-check"></i><b>13.2</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="13.3" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#review-of-maximum-likelihood-methods"><i class="fa fa-check"></i><b>13.3</b> Review of Maximum Likelihood Methods</a></li>
<li class="chapter" data-level="13.4" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#way-anova-with-a-random-effect"><i class="fa fa-check"></i><b>13.4</b> 1-way ANOVA with a random effect</a></li>
<li class="chapter" data-level="13.5" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#blocks-as-random-variables"><i class="fa fa-check"></i><b>13.5</b> Blocks as Random Variables</a></li>
<li class="chapter" data-level="13.6" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#nested-effects"><i class="fa fa-check"></i><b>13.6</b> Nested Effects</a></li>
<li class="chapter" data-level="13.7" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#crossed-effects"><i class="fa fa-check"></i><b>13.7</b> Crossed Effects</a></li>
<li class="chapter" data-level="13.8" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#repeated-measures-longitudinal-studies"><i class="fa fa-check"></i><b>13.8</b> Repeated Measures / Longitudinal Studies</a></li>
<li class="chapter" data-level="13.9" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-and-prediction-intervals"><i class="fa fa-check"></i><b>13.9</b> Confidence and Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-intervals"><i class="fa fa-check"></i><b>13.9.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="13.9.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#prediction-intervals"><i class="fa fa-check"></i><b>13.9.2</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#Exercises_RandomEffects"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html"><i class="fa fa-check"></i><b>14</b> Binomial Regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#binomial-regression-model"><i class="fa fa-check"></i><b>14.1</b> Binomial Regression Model</a></li>
<li class="chapter" data-level="14.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#measures-of-fit-quality"><i class="fa fa-check"></i><b>14.2</b> Measures of Fit Quality</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#deviance"><i class="fa fa-check"></i><b>14.2.1</b> Deviance</a></li>
<li class="chapter" data-level="14.2.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>14.2.2</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#confidence-intervals-1"><i class="fa fa-check"></i><b>14.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="14.4" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#interpreting-model-coefficients"><i class="fa fa-check"></i><b>14.4</b> Interpreting model coefficients</a></li>
<li class="chapter" data-level="14.5" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#prediction-and-effective-dose-levels"><i class="fa fa-check"></i><b>14.5</b> Prediction and Effective Dose Levels</a></li>
<li class="chapter" data-level="14.6" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#overdispersion"><i class="fa fa-check"></i><b>14.6</b> Overdispersion</a></li>
<li class="chapter" data-level="14.7" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#roc-curves"><i class="fa fa-check"></i><b>14.7</b> ROC Curves</a></li>
<li class="chapter" data-level="14.8" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#Exercises_BinomialRegression"><i class="fa fa-check"></i><b>14.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-poisson-regression.html"><a href="15-poisson-regression.html"><i class="fa fa-check"></i><b>15</b> Poisson Regression</a></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="16" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html"><i class="fa fa-check"></i><b>16</b> Block Designs</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#randomized-complete-block-design-rcbd-1"><i class="fa fa-check"></i><b>16.1</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="16.2" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#split-plot-designs"><i class="fa fa-check"></i><b>16.2</b> Split-plot designs</a></li>
<li class="chapter" data-level="16.3" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#exercises"><i class="fa fa-check"></i><b>16.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html"><i class="fa fa-check"></i><b>17</b> Maximum Likelihood Priciple</a>
<ul>
<li class="chapter" data-level="" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#learning-outcomes-1"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="17.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#introduction-1"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#distributions"><i class="fa fa-check"></i><b>17.2</b> Distributions</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson"><i class="fa fa-check"></i><b>17.2.1</b> Poisson</a></li>
<li class="chapter" data-level="17.2.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential"><i class="fa fa-check"></i><b>17.2.2</b> Exponential</a></li>
<li class="chapter" data-level="17.2.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal"><i class="fa fa-check"></i><b>17.2.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#likelihood-function"><i class="fa fa-check"></i><b>17.3</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson-1"><i class="fa fa-check"></i><b>17.3.1</b> Poisson</a></li>
<li class="chapter" data-level="17.3.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential-example"><i class="fa fa-check"></i><b>17.3.2</b> Exponential Example</a></li>
<li class="chapter" data-level="17.3.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal-1"><i class="fa fa-check"></i><b>17.3.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#discussion"><i class="fa fa-check"></i><b>17.4</b> Discussion</a></li>
<li class="chapter" data-level="17.5" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exercises-1"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="project-appendix.html"><a href="project-appendix.html"><i class="fa fa-check"></i>Project Appendix</a>
<ul>
<li class="chapter" data-level="17.6" data-path="project-appendix.html"><a href="project-appendix.html#weeks-1-4-project-feasibility"><i class="fa fa-check"></i><b>17.6</b> Weeks 1 – 4 (Project Feasibility)</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="project-appendix.html"><a href="project-appendix.html#wibgis"><i class="fa fa-check"></i><b>17.6.1</b> WIBGIs</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Methods II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="VariableSelection_Chapter" class="section level1" number="11">
<h1><span class="header-section-number">Chapter 11</span> Variable Selection</h1>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="11-VariableSelection-Chapter.html#cb251-1" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)    <span class="co"># dplyr, tidyr, ggplot2, etc</span></span></code></pre></div>
<p>Given a set of data, we are interested in selecting the best subset of predictors for the following reasons:</p>
<ol style="list-style-type: decimal">
<li><p>Occam’s Razor tells us that from a list of plausible model or explanations, the simplest is usually the best. In the statistics sense, I want the smallest model that adequately explains the observed data patterns.</p></li>
<li><p>Unnecessary predictors add noise to the estimates of other quantities and will waste degrees of freedom, possibly increasing the estimate of <span class="math inline">\(\hat{\sigma}^{2}\)</span>.</p></li>
<li><p>We might have variables that are co-linear.</p></li>
</ol>
<p>The problems that arise in the diagnostics of a model will often lead a researcher to consider other models, for example to include a quadratic term to account for curvature. The model building process is often an iterative procedure where we build a model, examine the diagnostic plots and consider what could be added or modified to correct issues observed.</p>
<div id="nested-models" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Nested Models</h2>
<p>Often one model is just a simplification of another and can be obtained by setting some subset of <span class="math inline">\(\beta_{i}\)</span> values equal to zero. Those models can be adequately compared by the F-test, which we have already made great use of.</p>
<p>We should be careful to note that we typically do not want to remove the main covariate from the model if the model uses the covariate in a more complicated fashion. For example, if my model is <span class="math display">\[y=\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\epsilon\]</span>
where <span class="math inline">\(\epsilon\sim N\left(0,\sigma^{2}\right)\)</span>, then considering the simplification <span class="math inline">\(\beta_{1}=0\)</span> and removing the effect of <span class="math inline">\(x\)</span> is not desirable because that forces the parabola to be symmetric about <span class="math inline">\(x=0\)</span>. Similarly, if the model contains an interaction effect, then the removal of the main effect drastically alters the interpretation of the interaction coefficients and should be avoided. Often times removing a lower complexity term while keeping a higher complexity term results in unintended consequences and is typically not recommended.</p>
</div>
<div id="testing-based-model-selection" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Testing-Based Model Selection</h2>
<p>Starting with a model that is likely too complex, consider a list of possible terms to remove and remove each in turn while evaluating the resulting model to the starting model using an F-test. Whichever term has the highest p-value is removed and the process is repeated until no more terms have non-significant p-values. This is often referred to as <em>backward selection</em>.</p>
<p>It should be noted that the cutoff value for significance here does not have to be <span class="math inline">\(\alpha=0.05\)</span>. If prediction performance is the primary goal, then a more liberal <span class="math inline">\(\alpha\)</span> level is appropriate.</p>
<p>Starting with a model that is likely too small, consider adding terms until there are no more terms that when added to the model are significant. This is called <em>forward selection</em>.</p>
<p>This is a hybrid between forward selection and backward elimination. At every stage, a term is either added or removed. This is referred to as <em>stepwise selection</em>.</p>
<p>Stepwise, forward, and backward selection are commonly used but there are some issues.</p>
<ol style="list-style-type: decimal">
<li><p>Because of the “one-at-a-time” nature of the addition/deletion, the most optimal model might not be found.</p></li>
<li><p>p-values should not be treated literally. Because the multiple comparisons issue is completely ignored, the p-values are lower than they should be if multiple comparisons were accounted for. As such, it is possible to sort through a huge number of potential covariates and find one with a low p-value simply by random chance. This is “data dredging” and is a serious issue.</p></li>
<li><p>As a non-thinking algorithm, these methods ignore the science behind that data and might include two variables that are highly collinear or might ignore variables that are scientifically interesting.</p></li>
</ol>
<div id="example---u.s.-life-expectancy" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Example - U.S. Life Expectancy</h3>
<p>Using data from the Census Bureau we can look at the life expectancy as a response to a number of predictors. One R function that is often convenient to use is the update() function that takes a <code>lm()</code> object and adds or removes things from the formula. The notation <code>. ~ .</code> means to leave the response and all the predictors alone, while <code>. ~ . + vnew</code> will add the main effect of <code>vnew</code> to the model.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="11-VariableSelection-Chapter.html#cb252-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&#39;state&#39;</span>)  <span class="co"># loads a matrix state.x77 and a vector of stat abbreviations</span></span>
<span id="cb252-2"><a href="11-VariableSelection-Chapter.html#cb252-2" aria-hidden="true"></a></span>
<span id="cb252-3"><a href="11-VariableSelection-Chapter.html#cb252-3" aria-hidden="true"></a><span class="co"># Convert from a matrix to a data frame with state abbreviations</span></span>
<span id="cb252-4"><a href="11-VariableSelection-Chapter.html#cb252-4" aria-hidden="true"></a>state.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(state.x77, <span class="dt">row.names=</span>state.abb)</span>
<span id="cb252-5"><a href="11-VariableSelection-Chapter.html#cb252-5" aria-hidden="true"></a><span class="kw">str</span>(state.data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    50 obs. of  8 variables:
##  $ Population: num  3615 365 2212 2110 21198 ...
##  $ Income    : num  3624 6315 4530 3378 5114 ...
##  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
##  $ Life.Exp  : num  69 69.3 70.5 70.7 71.7 ...
##  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
##  $ HS.Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
##  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
##  $ Area      : num  50708 566432 113417 51945 156361 ...</code></pre>
<p>We should first look at the</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="11-VariableSelection-Chapter.html#cb254-1" aria-hidden="true"></a>state.data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb254-2"><a href="11-VariableSelection-Chapter.html#cb254-2" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>( Life.Exp, Population<span class="op">:</span>Area ) <span class="op">%&gt;%</span></span>
<span id="cb254-3"><a href="11-VariableSelection-Chapter.html#cb254-3" aria-hidden="true"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>( <span class="dt">upper=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;points&#39;</span>), <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;cor&#39;</span>) )</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-154-1.png" width="672" /></p>
<p>I want to add a quadratic effect for <code>HS.Grad</code> rate and for <code>Income</code>. Also, we see that <code>Population</code> and <code>Area</code> seem to have some high skew to their distributions, so a log transformation might help. We’ll modify the data and then perform the backward elimination method starting with the model with all predictors as main effects.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="11-VariableSelection-Chapter.html#cb255-1" aria-hidden="true"></a>state.data &lt;-<span class="st"> </span>state.data <span class="op">%&gt;%</span></span>
<span id="cb255-2"><a href="11-VariableSelection-Chapter.html#cb255-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>( <span class="dt">HS.Grad.2 =</span> HS.Grad <span class="op">^</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb255-3"><a href="11-VariableSelection-Chapter.html#cb255-3" aria-hidden="true"></a>          <span class="dt">Income.2  =</span> Income  <span class="op">^</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb255-4"><a href="11-VariableSelection-Chapter.html#cb255-4" aria-hidden="true"></a>          <span class="dt">Log.Population =</span> <span class="kw">log</span>(Population),</span>
<span id="cb255-5"><a href="11-VariableSelection-Chapter.html#cb255-5" aria-hidden="true"></a>          <span class="dt">Log.Area =</span> <span class="kw">log</span>(Area)) <span class="op">%&gt;%</span></span>
<span id="cb255-6"><a href="11-VariableSelection-Chapter.html#cb255-6" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>( <span class="op">-</span>Population, <span class="op">-</span>Area )   <span class="co"># remove the original Population and Area covariates</span></span>
<span id="cb255-7"><a href="11-VariableSelection-Chapter.html#cb255-7" aria-hidden="true"></a></span>
<span id="cb255-8"><a href="11-VariableSelection-Chapter.html#cb255-8" aria-hidden="true"></a><span class="co"># explicitly define my starting model</span></span>
<span id="cb255-9"><a href="11-VariableSelection-Chapter.html#cb255-9" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span>Log.Population <span class="op">+</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Illiteracy <span class="op">+</span><span class="st"> </span></span>
<span id="cb255-10"><a href="11-VariableSelection-Chapter.html#cb255-10" aria-hidden="true"></a><span class="st">                    </span>Murder <span class="op">+</span><span class="st"> </span>HS.Grad <span class="op">+</span><span class="st"> </span>Frost <span class="op">+</span><span class="st"> </span>HS.Grad<span class="fl">.2</span> <span class="op">+</span><span class="st"> </span>Income<span class="fl">.2</span> <span class="op">+</span><span class="st">  </span>Log.Area, <span class="dt">data=</span>state.data)</span>
<span id="cb255-11"><a href="11-VariableSelection-Chapter.html#cb255-11" aria-hidden="true"></a><span class="co">#</span></span>
<span id="cb255-12"><a href="11-VariableSelection-Chapter.html#cb255-12" aria-hidden="true"></a><span class="co"># Define the same model, but using shorthand</span></span>
<span id="cb255-13"><a href="11-VariableSelection-Chapter.html#cb255-13" aria-hidden="true"></a><span class="co"># The &#39;.&#39; means everything else in the data frame</span></span>
<span id="cb255-14"><a href="11-VariableSelection-Chapter.html#cb255-14" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>( Life.Exp <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>state.data)</span>
<span id="cb255-15"><a href="11-VariableSelection-Chapter.html#cb255-15" aria-hidden="true"></a><span class="kw">summary</span>(m1)<span class="op">$</span>coefficients <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      61.174      6.984   8.759    0.000
## Income            0.004      0.003   1.517    0.137
## Illiteracy        0.367      0.388   0.946    0.350
## Murder           -0.304      0.049  -6.214    0.000
## HS.Grad          -0.031      0.208  -0.151    0.881
## Frost            -0.004      0.003  -1.068    0.292
## HS.Grad.2         0.001      0.002   0.394    0.696
## Income.2          0.000      0.000  -1.518    0.137
## Log.Population    0.191      0.150   1.273    0.211
## Log.Area          0.100      0.113   0.885    0.382</code></pre>
<p>The signs make reasonable sense (higher murder rates decrease life expectancy) but covariates like <code>Income</code> are not significant, which is surprising. The largest p-value is <code>HS.Grad</code>. However, I don’t want to remove the lower-order graduation term and keep the squared-term. So instead I will remove both of them since they are the highest p-values. Notice that <code>HS.Grad</code> is correlated with <code>Income</code> and <code>Illiteracy</code>.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="11-VariableSelection-Chapter.html#cb257-1" aria-hidden="true"></a><span class="co"># Remove Graduation Rate from the model from the model</span></span>
<span id="cb257-2"><a href="11-VariableSelection-Chapter.html#cb257-2" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">update</span>(m1, .<span class="op">~</span>. <span class="op">-</span><span class="st"> </span>HS.Grad <span class="op">-</span><span class="st"> </span>HS.Grad<span class="fl">.2</span>)</span>
<span id="cb257-3"><a href="11-VariableSelection-Chapter.html#cb257-3" aria-hidden="true"></a><span class="kw">summary</span>(m1)<span class="op">$</span>coefficients <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      60.894      6.100   9.983    0.000
## Income            0.004      0.002   1.711    0.094
## Illiteracy        0.087      0.373   0.233    0.817
## Murder           -0.318      0.048  -6.686    0.000
## Frost            -0.006      0.003  -1.807    0.078
## Income.2          0.000      0.000  -1.581    0.121
## Log.Population    0.041      0.132   0.309    0.759
## Log.Area          0.206      0.103   1.995    0.053</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="11-VariableSelection-Chapter.html#cb259-1" aria-hidden="true"></a><span class="co"># Next remove Illiteracy</span></span>
<span id="cb259-2"><a href="11-VariableSelection-Chapter.html#cb259-2" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">update</span>(m1, .<span class="op">~</span>. <span class="op">-</span><span class="st"> </span>Illiteracy)</span>
<span id="cb259-3"><a href="11-VariableSelection-Chapter.html#cb259-3" aria-hidden="true"></a><span class="kw">summary</span>(m1)<span class="op">$</span>coefficients <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      61.779      4.717  13.098    0.000
## Income            0.004      0.002   1.872    0.068
## Murder           -0.314      0.042  -7.423    0.000
## Frost            -0.006      0.003  -2.345    0.024
## Income.2          0.000      0.000  -1.699    0.097
## Log.Population    0.041      0.130   0.314    0.755
## Log.Area          0.198      0.097   2.048    0.047</code></pre>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="11-VariableSelection-Chapter.html#cb261-1" aria-hidden="true"></a><span class="co"># And Log.Population...</span></span>
<span id="cb261-2"><a href="11-VariableSelection-Chapter.html#cb261-2" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">update</span>(m1, .<span class="op">~</span>. <span class="op">-</span><span class="st"> </span>Log.Population)</span>
<span id="cb261-3"><a href="11-VariableSelection-Chapter.html#cb261-3" aria-hidden="true"></a><span class="kw">summary</span>(m1)<span class="op">$</span>coefficients <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   61.413      4.523  13.577    0.000
## Income         0.004      0.002   2.257    0.029
## Murder        -0.309      0.039  -7.828    0.000
## Frost         -0.006      0.002  -2.612    0.012
## Income.2       0.000      0.000  -2.044    0.047
## Log.Area       0.200      0.096   2.091    0.042</code></pre>
<p>The removal of <code>Income.2</code> is a tough decision because the p-value is very close to <span class="math inline">\(\alpha=0.05\)</span> and might be left in if it makes model interpretation easier or if the researcher feels a quadratic effect in income is appropriate (perhaps rich people are too stressed?).</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="11-VariableSelection-Chapter.html#cb263-1" aria-hidden="true"></a><span class="kw">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Life.Exp ~ Income + Murder + Frost + Income.2 + 
##     Log.Area, data = state.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.28858 -0.50631 -0.07242  0.49738  1.75839 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.141e+01  4.523e+00  13.577  &lt; 2e-16 ***
## Income       4.212e-03  1.867e-03   2.257   0.0290 *  
## Murder      -3.092e-01  3.950e-02  -7.828 7.14e-10 ***
## Frost       -6.487e-03  2.483e-03  -2.612   0.0123 *  
## Income.2    -4.188e-07  2.049e-07  -2.044   0.0470 *  
## Log.Area     2.002e-01  9.576e-02   2.091   0.0424 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7349 on 44 degrees of freedom
## Multiple R-squared:  0.7309, Adjusted R-squared:  0.7003 
## F-statistic:  23.9 on 5 and 44 DF,  p-value: 1.549e-11</code></pre>
<p>We are left with a model that adequately explains <code>Life.Exp</code> but we should be careful to note that just because a covariate was removed from the model does not imply that it isn’t related to the response. For example, being a high school graduate is highly correlated with not being illiterate as is <code>Income</code> and thus replacing <code>Illiteracy</code> shows that illiteracy is associated with lower life expectancy, but it is not as predictive as <code>Income</code>.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="11-VariableSelection-Chapter.html#cb265-1" aria-hidden="true"></a>m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span>Illiteracy<span class="op">+</span>Murder<span class="op">+</span>Frost, <span class="dt">data=</span>state.data)</span>
<span id="cb265-2"><a href="11-VariableSelection-Chapter.html#cb265-2" aria-hidden="true"></a><span class="kw">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Life.Exp ~ Illiteracy + Murder + Frost, data = state.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.59010 -0.46961  0.00394  0.57060  1.92292 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 74.556717   0.584251 127.611  &lt; 2e-16 ***
## Illiteracy  -0.601761   0.298927  -2.013  0.04998 *  
## Murder      -0.280047   0.043394  -6.454 6.03e-08 ***
## Frost       -0.008691   0.002959  -2.937  0.00517 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7911 on 46 degrees of freedom
## Multiple R-squared:  0.6739, Adjusted R-squared:  0.6527 
## F-statistic: 31.69 on 3 and 46 DF,  p-value: 2.915e-11</code></pre>
<p>Notice that the <span class="math inline">\(R^{2}\)</span> values for both models are quite similar <span class="math inline">\(0.7309\)</span> vs <span class="math inline">\(0.6739\)</span> but the first model with the higher <span class="math inline">\(R^{2}\)</span> has one more predictor variable? Which model should I prefer? I can’t do an F-test because these models are not nested.</p>
</div>
</div>
<div id="criterion-based-procedures" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Criterion Based Procedures</h2>
<div id="information-criterions" class="section level3" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Information Criterions</h3>
<p>It is often necessary to compare models that are not nested. For example, I might want to compare
<span class="math display">\[y=\beta_{0}+\beta_{1}x+\epsilon\]</span>
vs
<span class="math display">\[y=\beta_{0}+\beta_{2}w+\epsilon\]</span></p>
<p>This comparison comes about naturally when doing forward model selection and we are looking for the “best” covariate to add to the model first.</p>
<p>Akaike introduced his criterion (which he called “An Information Criterion”) as
<span class="math display">\[AIC=\underset{\textrm{decreases if RSS decreases}}{\underbrace{-2\,\log L\left(\hat{\boldsymbol{\beta}},\hat{\sigma}|\,\textrm{data}\,\right)}}+\underset{\textrm{increases as p increases}}{\underbrace{2p}}\]</span>
where
<span class="math inline">\(L\left(\hat{\boldsymbol{\beta}}|\,\textrm{data}\,\right)\)</span> is the likelihood function and <span class="math inline">\(p\)</span> is the number of elements in the <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>
vector and we regard a lower AIC value as better. Notice the <span class="math inline">\(2p\)</span>
term is essentially a penalty on adding addition covariates so to lower the AIC value, a new predictor must lower the negative log likelihood more than it increases the penalty.</p>
<p>To convince ourselves that the first summand decreases with decreasing RSS in the standard linear model, we examine the likelihood function
<span class="math display">\[\begin{aligned}
f\left(\boldsymbol{y}\,|\,\boldsymbol{\beta},\sigma,\boldsymbol{X}\right)   &amp;=  \frac{1}{\left(2\pi\sigma^{2}\right)^{n/2}}\exp\left[-\frac{1}{2\sigma^{2}}\left(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\beta}\right)^{T}\left(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\beta}\right)\right] \\
    &amp;=  L\left(\boldsymbol{\beta},\sigma\,|\,\boldsymbol{y},\boldsymbol{X}\right)
\end{aligned}\]</span>
and we could re-write this as
<span class="math display">\[\begin{aligned}
\log L\left(\hat{\boldsymbol{\beta}},\hat{\sigma}\,|\,\textrm{data}\right)  &amp;=  -\log\left(\left(2\pi\hat{\sigma}^{2}\right)^{n/2}\right)-\frac{1}{2\hat{\sigma}^{2}}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right)^{T}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right) \\
    &amp;=  -\frac{n}{2}\log\left(2\pi\hat{\sigma}^{2}\right)-\frac{1}{2\hat{\sigma}^{2}}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right)^{T}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right) \\
    &amp;=  -\frac{1}{2}\left[n\log\left(2\pi\hat{\sigma}^{2}\right)+\frac{1}{\hat{\sigma}^{2}}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right)^{T}\left(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}}\right)\right] \\
    &amp;=  -\frac{1}{2}\left[+n\log\left(2\pi\right)+n\log\hat{\sigma}^{2}+\frac{1}{\hat{\sigma}^{2}}RSS\right]
\end{aligned}\]</span></p>
<p>It isn’t clear what we should do with the <span class="math inline">\(n\log\left(2\pi\right)\)</span> term in the <span class="math inline">\(\log L()\)</span> function. There are some compelling reasons to ignore it and just use the second, and there are reasons to use both terms. Unfortunately, statisticians have not settled on one convention or the other and different software packages might therefore report different values for AIC.</p>
<p>As a general rule of thumb, if the difference in AIC values is less than two then the models are not significantly different, differences between 2 and 4 AIC units are marginally significant and any difference greater than 4 AIC units is highly significant.</p>
<p>Notice that while this allows us to compare models that are not nested, it does require that the same data are used to fit both models. Because I could start out with my data frame including both <span class="math inline">\(x\)</span> and <span class="math inline">\(x^{2}\)</span>, (or more generally <span class="math inline">\(x\)</span> and <span class="math inline">\(f\left(x\right)\)</span> for some function <span class="math inline">\(f()\)</span>) you can regard a transformation of a covariate as “the same data”. However, a transformation of a y-variable is not and therefore we cannot use AIC to compare a models <code>log(y) ~ x</code> versus the model <code>y ~ x</code>.</p>
<p>Another criterion that might be used is <em>Bayes Information Criterion</em> (BIC) which is</p>
<p><span class="math display">\[BIC=-2\,\log L\left(\hat{\boldsymbol{\beta}},\hat{\sigma}|\,\textrm{data}\,\right)+p\log n\]</span></p>
<p>and this criterion punishes large models more than AIC does (because <span class="math inline">\(\log n&gt;2\)</span> for <span class="math inline">\(n\ge8\)</span>)</p>
<p>The AIC value of a linear model can be found using the AIC() on a <code>lm()</code>() object.</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="11-VariableSelection-Chapter.html#cb267-1" aria-hidden="true"></a><span class="kw">AIC</span>(m1)</span></code></pre></div>
<pre><code>## [1] 118.6942</code></pre>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="11-VariableSelection-Chapter.html#cb269-1" aria-hidden="true"></a><span class="kw">AIC</span>(m2)</span></code></pre></div>
<pre><code>## [1] 124.2947</code></pre>
<p>Because the AIC value for the first model is lower, we would prefer the first model that includes both <code>Income</code> and <code>Income.2</code> compared to model 2, which was <code>Life.Exp ~ Illiteracy+Murder+Frost</code>.</p>
</div>
<div id="adjusted-r-sq" class="section level3" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Adjusted <code>R-sq</code></h3>
<p>One of the problems with <span class="math inline">\(R^{2}\)</span> is that it makes no adjustment for how many parameters in the model. Recall that <span class="math inline">\(R^{2}\)</span> was defined as
<span class="math display">\[R^{2}=\frac{RSS_{S}-RSS_{C}}{RSS_{S}}=1-\frac{RSS_{C}}{RSS_{S}}\]</span>
where the simple model was the intercept only model. We can create an <span class="math inline">\(R_{adj}^{2}\)</span> statistic that attempts to add a penalty for having too many parameters by defining
<span class="math display">\[R_{adj}^{2}=1-\frac{RSS_{C}/\left(n-p\right)}{RSS_{S}/\left(n-1\right)}\]</span>
With this adjusted definition, adding a variable to the model that has no predictive power will decrease <span class="math inline">\(R_{adj}^{2}\)</span>.</p>
</div>
<div id="example-1" class="section level3" number="11.3.3">
<h3><span class="header-section-number">11.3.3</span> Example</h3>
<p>Returning to the life expectancy data, we could start with a simple model add covariates to the model that have the lowest AIC values. R makes this easy with the function <code>add1()</code> which will take a linear model (which includes the data frame that originally defined it) and will sequentially add all of the possible terms that are not currently in the model and report the AIC values for each model.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="11-VariableSelection-Chapter.html#cb271-1" aria-hidden="true"></a><span class="co"># Define the biggest model I wish to consider</span></span>
<span id="cb271-2"><a href="11-VariableSelection-Chapter.html#cb271-2" aria-hidden="true"></a>biggest &lt;-<span class="st"> </span>Life.Exp <span class="op">~</span><span class="st"> </span>Log.Population <span class="op">+</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Illiteracy <span class="op">+</span><span class="st"> </span>Murder <span class="op">+</span><span class="st"> </span></span>
<span id="cb271-3"><a href="11-VariableSelection-Chapter.html#cb271-3" aria-hidden="true"></a><span class="st">                      </span>HS.Grad <span class="op">+</span><span class="st"> </span>Frost <span class="op">+</span><span class="st"> </span>Log.Area <span class="op">+</span><span class="st"> </span>HS.Grad<span class="fl">.2</span> <span class="op">+</span><span class="st"> </span>Income<span class="fl">.2</span></span>
<span id="cb271-4"><a href="11-VariableSelection-Chapter.html#cb271-4" aria-hidden="true"></a></span>
<span id="cb271-5"><a href="11-VariableSelection-Chapter.html#cb271-5" aria-hidden="true"></a><span class="co"># Define the model I wish to start with</span></span>
<span id="cb271-6"><a href="11-VariableSelection-Chapter.html#cb271-6" aria-hidden="true"></a>m &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>state.data)</span>
<span id="cb271-7"><a href="11-VariableSelection-Chapter.html#cb271-7" aria-hidden="true"></a></span>
<span id="cb271-8"><a href="11-VariableSelection-Chapter.html#cb271-8" aria-hidden="true"></a><span class="kw">add1</span>(m, <span class="dt">scope=</span>biggest)  <span class="co"># what is the best addition to make?</span></span></code></pre></div>
<pre><code>## Single term additions
## 
## Model:
## Life.Exp ~ 1
##                Df Sum of Sq    RSS     AIC
## &lt;none&gt;                      88.299  30.435
## Log.Population  1     1.054 87.245  31.835
## Income          1    10.223 78.076  26.283
## Illiteracy      1    30.578 57.721  11.179
## Murder          1    53.838 34.461 -14.609
## HS.Grad         1    29.931 58.368  11.737
## Frost           1     6.064 82.235  28.878
## Log.Area        1     1.042 87.257  31.842
## HS.Grad.2       1    27.414 60.885  13.848
## Income.2        1     7.464 80.835  28.020</code></pre>
<p>Clearly the addition of <code>Murder</code> to the model results in the lowest AIC value, so we will add <code>Murder</code> to the model. Notice the <code>&lt;none&gt;</code> row corresponds to the model m which we started with and it has a <code>RSS=88.299</code>. For each model considered, R will calculate the <code>RSS_{C}</code> for the new model and will calculate the difference between the starting model and the more complicated model and display this in the Sum of Squares column.</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="11-VariableSelection-Chapter.html#cb273-1" aria-hidden="true"></a>m &lt;-<span class="st"> </span><span class="kw">update</span>(m, . <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>Murder)  <span class="co"># add murder to the model</span></span>
<span id="cb273-2"><a href="11-VariableSelection-Chapter.html#cb273-2" aria-hidden="true"></a><span class="kw">add1</span>(m, <span class="dt">scope=</span>biggest)          <span class="co"># what should I add next?</span></span></code></pre></div>
<pre><code>## Single term additions
## 
## Model:
## Life.Exp ~ Murder
##                Df Sum of Sq    RSS     AIC
## &lt;none&gt;                      34.461 -14.609
## Log.Population  1    2.9854 31.476 -17.140
## Income          1    2.4047 32.057 -16.226
## Illiteracy      1    0.2732 34.188 -13.007
## HS.Grad         1    4.6910 29.770 -19.925
## Frost           1    3.1346 31.327 -17.378
## Log.Area        1    1.4583 33.003 -14.771
## HS.Grad.2       1    4.4396 30.022 -19.505
## Income.2        1    1.8972 32.564 -15.441</code></pre>
<p>There is a companion function to <code>add1()</code> that finds the best term to drop. It is conveniently named <code>drop1()</code> but here the <code>scope</code> parameter defines the smallest model to be considered.</p>
<p>It would be nice if all of this work was automated. Again, R makes our life easy and the function <code>step()</code> does exactly this. The set of models searched is determined by the scope argument which can be a <em>list</em> of two formulas with components upper and lower or it can be a single formula, or it can be blank. The right-hand-side of its lower component defines the smallest model to be considered and the right-hand-side of the upper component defines the largest model to be considered. If <code>scope</code> is a single formula, it specifies the upper component, and the lower model taken to be the intercept-only model. If scope is missing, the initial model is used as the upper model.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="11-VariableSelection-Chapter.html#cb275-1" aria-hidden="true"></a>smallest &lt;-<span class="st"> </span>Life.Exp <span class="op">~</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb275-2"><a href="11-VariableSelection-Chapter.html#cb275-2" aria-hidden="true"></a>biggest &lt;-<span class="st"> </span>Life.Exp <span class="op">~</span><span class="st"> </span>Log.Population <span class="op">+</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Illiteracy <span class="op">+</span><span class="st"> </span></span>
<span id="cb275-3"><a href="11-VariableSelection-Chapter.html#cb275-3" aria-hidden="true"></a><span class="st">                      </span>Murder <span class="op">+</span><span class="st"> </span>HS.Grad <span class="op">+</span><span class="st"> </span>Frost <span class="op">+</span><span class="st"> </span>Log.Area <span class="op">+</span><span class="st"> </span>HS.Grad<span class="fl">.2</span> <span class="op">+</span><span class="st"> </span>Income<span class="fl">.2</span></span>
<span id="cb275-4"><a href="11-VariableSelection-Chapter.html#cb275-4" aria-hidden="true"></a>m &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span>Income, <span class="dt">data=</span>state.data)</span>
<span id="cb275-5"><a href="11-VariableSelection-Chapter.html#cb275-5" aria-hidden="true"></a>stats<span class="op">::</span><span class="kw">step</span>(m, <span class="dt">scope=</span><span class="kw">list</span>(<span class="dt">lower=</span>smallest, <span class="dt">upper=</span>biggest))</span></code></pre></div>
<pre><code>## Start:  AIC=26.28
## Life.Exp ~ Income
## 
##                  Df Sum of Sq    RSS     AIC
## + Murder          1    46.020 32.057 -16.226
## + Illiteracy      1    21.109 56.968  12.523
## + HS.Grad         1    19.770 58.306  13.684
## + Income.2        1    19.062 59.015  14.288
## + HS.Grad.2       1    17.193 60.884  15.847
## + Frost           1     3.188 74.889  26.199
## &lt;none&gt;                        78.076  26.283
## + Log.Population  1     1.298 76.779  27.445
## + Log.Area        1     0.994 77.082  27.642
## - Income          1    10.223 88.299  30.435
## 
## Step:  AIC=-16.23
## Life.Exp ~ Income + Murder
## 
##                  Df Sum of Sq    RSS     AIC
## + Frost           1     3.918 28.138 -20.745
## + Income.2        1     3.036 29.021 -19.200
## + HS.Grad         1     2.388 29.668 -18.097
## + Log.Population  1     2.371 29.686 -18.068
## + HS.Grad.2       1     2.199 29.857 -17.780
## &lt;none&gt;                        32.057 -16.226
## + Log.Area        1     1.229 30.827 -16.181
## - Income          1     2.405 34.461 -14.609
## + Illiteracy      1     0.011 32.046 -14.242
## - Murder          1    46.020 78.076  26.283
## 
## Step:  AIC=-20.74
## Life.Exp ~ Income + Murder + Frost
## 
##                  Df Sum of Sq    RSS     AIC
## + HS.Grad         1     2.949 25.189 -24.280
## + HS.Grad.2       1     2.764 25.375 -23.914
## + Log.Area        1     2.122 26.017 -22.664
## + Income.2        1     2.017 26.121 -22.465
## &lt;none&gt;                        28.138 -20.745
## + Illiteracy      1     0.950 27.189 -20.461
## + Log.Population  1     0.792 27.347 -20.172
## - Income          1     3.188 31.327 -17.378
## - Frost           1     3.918 32.057 -16.226
## - Murder          1    46.750 74.889  26.199
## 
## Step:  AIC=-24.28
## Life.Exp ~ Income + Murder + Frost + HS.Grad
## 
##                  Df Sum of Sq    RSS     AIC
## + Log.Population  1     2.279 22.911 -27.021
## + Income.2        1     1.864 23.326 -26.124
## - Income          1     0.182 25.372 -25.920
## &lt;none&gt;                        25.189 -24.280
## + Log.Area        1     0.570 24.619 -23.425
## + HS.Grad.2       1     0.218 24.972 -22.714
## + Illiteracy      1     0.131 25.058 -22.541
## - HS.Grad         1     2.949 28.138 -20.745
## - Frost           1     4.479 29.668 -18.097
## - Murder          1    32.877 58.067  15.478
## 
## Step:  AIC=-27.02
## Life.Exp ~ Income + Murder + Frost + HS.Grad + Log.Population
## 
##                  Df Sum of Sq    RSS     AIC
## - Income          1     0.011 22.921 -28.998
## &lt;none&gt;                        22.911 -27.021
## + Income.2        1     0.579 22.331 -26.302
## + Log.Area        1     0.207 22.704 -25.475
## + Illiteracy      1     0.052 22.859 -25.134
## + HS.Grad.2       1     0.009 22.901 -25.042
## - Frost           1     2.107 25.017 -24.623
## - Log.Population  1     2.279 25.189 -24.280
## - HS.Grad         1     4.436 27.347 -20.172
## - Murder          1    33.706 56.616  16.214
## 
## Step:  AIC=-29
## Life.Exp ~ Murder + Frost + HS.Grad + Log.Population
## 
##                  Df Sum of Sq    RSS     AIC
## &lt;none&gt;                        22.921 -28.998
## + Log.Area        1     0.216 22.705 -27.471
## + Illiteracy      1     0.052 22.870 -27.111
## + Income.2        1     0.034 22.887 -27.073
## + HS.Grad.2       1     0.012 22.909 -27.024
## + Income          1     0.011 22.911 -27.021
## - Frost           1     2.214 25.135 -26.387
## - Log.Population  1     2.450 25.372 -25.920
## - HS.Grad         1     6.959 29.881 -17.741
## - Murder          1    34.109 57.031  14.578</code></pre>
<pre><code>## 
## Call:
## lm(formula = Life.Exp ~ Murder + Frost + HS.Grad + Log.Population, 
##     data = state.data)
## 
## Coefficients:
##    (Intercept)          Murder           Frost         HS.Grad  Log.Population  
##      68.720810       -0.290016       -0.005174        0.054550        0.246836</code></pre>
<p>Notice that our model selected by <code>step()</code> is not the same model we obtained when we started with the biggest model and removed things based on p-values.</p>
<p>The log-likelihood is only defined up to an additive constant, and there are different conventional constants used. This is more annoying than anything because all we care about for model selection is the difference between AIC values of two models and the additive constant cancels. The only time it matters is when you have two different ways of extracting the AIC values. Recall the model we fit using the top-down approach was</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="11-VariableSelection-Chapter.html#cb278-1" aria-hidden="true"></a><span class="co"># m1 was</span></span>
<span id="cb278-2"><a href="11-VariableSelection-Chapter.html#cb278-2" aria-hidden="true"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Murder <span class="op">+</span><span class="st"> </span>Frost <span class="op">+</span><span class="st"> </span>Income<span class="fl">.2</span>, <span class="dt">data =</span> state.data)</span>
<span id="cb278-3"><a href="11-VariableSelection-Chapter.html#cb278-3" aria-hidden="true"></a><span class="kw">AIC</span>(m1)</span></code></pre></div>
<pre><code>## [1] 121.4293</code></pre>
<p>and the model selected by the stepwise algorithm was</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="11-VariableSelection-Chapter.html#cb280-1" aria-hidden="true"></a>m3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Life.Exp <span class="op">~</span><span class="st"> </span>Murder <span class="op">+</span><span class="st"> </span>Frost <span class="op">+</span><span class="st"> </span>HS.Grad <span class="op">+</span><span class="st"> </span>Log.Population, <span class="dt">data =</span> state.data)</span>
<span id="cb280-2"><a href="11-VariableSelection-Chapter.html#cb280-2" aria-hidden="true"></a><span class="kw">AIC</span>(m3)</span></code></pre></div>
<pre><code>## [1] 114.8959</code></pre>
<p>Because <code>step()</code> and <code>AIC()</code> are following different conventions the absolute value of the AICs are different, but the difference between the two is constant no matter which function we use.</p>
<p>First we calculate the difference using the AIC() function:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="11-VariableSelection-Chapter.html#cb282-1" aria-hidden="true"></a><span class="kw">AIC</span>(m1) <span class="op">-</span><span class="st"> </span><span class="kw">AIC</span>(m3)</span></code></pre></div>
<pre><code>## [1] 6.533434</code></pre>
<p>and next we use <code>add1()</code> on both models to see what the AIC values for each.</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="11-VariableSelection-Chapter.html#cb284-1" aria-hidden="true"></a><span class="kw">add1</span>(m1, <span class="dt">scope=</span>biggest)</span></code></pre></div>
<pre><code>## Single term additions
## 
## Model:
## Life.Exp ~ Income + Murder + Frost + Income.2
##                Df Sum of Sq    RSS     AIC
## &lt;none&gt;                      26.121 -22.465
## Log.Population  1   0.10296 26.018 -20.662
## Illiteracy      1   0.10097 26.020 -20.658
## HS.Grad         1   2.79527 23.326 -26.124
## Log.Area        1   2.36019 23.761 -25.200
## HS.Grad.2       1   2.79698 23.324 -26.127</code></pre>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="11-VariableSelection-Chapter.html#cb286-1" aria-hidden="true"></a><span class="kw">add1</span>(m3, <span class="dt">scope=</span>biggest)</span></code></pre></div>
<pre><code>## Single term additions
## 
## Model:
## Life.Exp ~ Murder + Frost + HS.Grad + Log.Population
##            Df Sum of Sq    RSS     AIC
## &lt;none&gt;                  22.921 -28.998
## Income      1  0.010673 22.911 -27.021
## Illiteracy  1  0.051595 22.870 -27.111
## Log.Area    1  0.215741 22.706 -27.471
## HS.Grad.2   1  0.011894 22.909 -27.024
## Income.2    1  0.034356 22.887 -27.073</code></pre>
<p>Using these results, we can calculate the difference in AIC values to be the same as we calculated before <span class="math display">\[\begin{aligned}
-22.465--28.998 &amp;=  -22.465 + 28.998 \\
    &amp;=  6.533
    \end{aligned}\]</span></p>
</div>
</div>
<div id="Exercises_VariableSelection" class="section level2" number="11.4">
<h2><span class="header-section-number">11.4</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li>Consider the <code>prostate</code> data from the <code>faraway</code> package. The variable <code>lpsa</code> is a measurement of a prostate specific antigen which higher levels are indicative of prostate cancer. Use <code>lpsa</code> as the response and all the other variables as predictors (no interactions). Determine the “best” model using:
<ol style="list-style-type: lower-alpha">
<li>Backward elimination using the analysis of variance F-statistic as the criteria.</li>
<li>Forward selection using AIC as the criteria.</li>
</ol></li>
<li>Again from the <code>faraway</code> package, use the <code>divusa</code> which has divorce rates for each year from 1920-1996 along with other population information for each year. Use <code>divorce</code> as the response variable and all other variables as the predictors.
<ol style="list-style-type: lower-alpha">
<li>Determine the best model using stepwise selection starting from the intercept only model and the most complex model being all main effects (no interactions). Use the F-statistic to determine significance. Note: add1(), drop1(), and step() allow an option of test=‘F’ to use an F-test instead of AIC.</li>
<li>Following the stepwise selection, comment on the relationship between p-values used and the AIC difference observed. Do the AIC rules of thumb match the p-value interpretation?</li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="10-CorrelatedCovariates-Chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="12-too-many-predictors-toomanypredictors-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/571/blob/master/11_Variable_Selection.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/dereksonderegger/571/raw/master/11_Variable_Selection.Rmd",
"text": null
},
"download": [["Statistical_Methods_II.pdf", "PDF"], ["Statistical_Methods_II.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

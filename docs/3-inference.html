<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Inference | Statistical Methods II</title>
  <meta name="description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="generator" content="bookdown 0.20.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Inference | Statistical Methods II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="github-repo" content="dereksonderegger/STA_571_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Inference | Statistical Methods II" />
  
  <meta name="twitter:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  

<meta name="author" content="Derek L. Sonderegger" />


<meta name="date" content="2020-10-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="2-parameter-estimation.html"/>
<link rel="next" href="4-contrasts.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Methods II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Statistical Theory</b></span></li>
<li class="chapter" data-level="1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html"><i class="fa fa-check"></i><b>1</b> Matrix Manipulation</a>
<ul>
<li class="chapter" data-level="" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="1.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_Introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#types-of-matrices"><i class="fa fa-check"></i><b>1.2</b> Types of Matrices</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalars"><i class="fa fa-check"></i><b>1.2.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vectors"><i class="fa fa-check"></i><b>1.2.2</b> Vectors</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix"><i class="fa fa-check"></i><b>1.2.3</b> Matrix</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#square-matrices"><i class="fa fa-check"></i><b>1.2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#symmetric-matrices"><i class="fa fa-check"></i><b>1.2.5</b> Symmetric Matrices</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#diagonal-matrices"><i class="fa fa-check"></i><b>1.2.6</b> Diagonal Matrices</a></li>
<li class="chapter" data-level="1.2.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#identity-matrices"><i class="fa fa-check"></i><b>1.2.7</b> Identity Matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#operations-on-matrices"><i class="fa fa-check"></i><b>1.3</b> Operations on Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#transpose"><i class="fa fa-check"></i><b>1.3.1</b> Transpose</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#addition-and-subtraction"><i class="fa fa-check"></i><b>1.3.2</b> Addition and Subtraction</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#multiplication"><i class="fa fa-check"></i><b>1.3.3</b> Multiplication</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vector-multiplication"><i class="fa fa-check"></i><b>1.3.4</b> Vector Multiplication</a></li>
<li class="chapter" data-level="1.3.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.3.5</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="1.3.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalar-times-a-matrix"><i class="fa fa-check"></i><b>1.3.6</b> Scalar times a Matrix</a></li>
<li class="chapter" data-level="1.3.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#determinant"><i class="fa fa-check"></i><b>1.3.7</b> Determinant</a></li>
<li class="chapter" data-level="1.3.8" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#inverse"><i class="fa fa-check"></i><b>1.3.8</b> Inverse</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#Exercises_MatrixTheory"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html"><i class="fa fa-check"></i><b>2</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#model-specifications"><i class="fa fa-check"></i><b>2.2</b> Model Specifications</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#simple-regression"><i class="fa fa-check"></i><b>2.2.1</b> Simple Regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#anova-model"><i class="fa fa-check"></i><b>2.2.2</b> ANOVA model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#parameter-estimation-1"><i class="fa fa-check"></i><b>2.3</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-location-paramters"><i class="fa fa-check"></i><b>2.3.1</b> Estimation of Location Paramters</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-variance-parameter"><i class="fa fa-check"></i><b>2.3.2</b> Estimation of Variance Parameter</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#standard-errors"><i class="fa fa-check"></i><b>2.4</b> Standard Errors</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#expectation-and-variance-of-a-random-vector"><i class="fa fa-check"></i><b>2.4.1</b> Expectation and variance of a random vector</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#variance-of-location-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Variance of Location Parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#summary-of-pertinent-results"><i class="fa fa-check"></i><b>2.4.3</b> Summary of pertinent results</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#r-example"><i class="fa fa-check"></i><b>2.5</b> R example</a></li>
<li class="chapter" data-level="2.6" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#Exercises_Estimation"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-inference.html"><a href="3-inference.html"><i class="fa fa-check"></i><b>3</b> Inference</a>
<ul>
<li class="chapter" data-level="" data-path="3-inference.html"><a href="3-inference.html#Inference_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="3.1" data-path="3-inference.html"><a href="3-inference.html#Inference_Introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-inference.html"><a href="3-inference.html#confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>3.2</b> Confidence Intervals and Hypothesis Tests</a></li>
<li class="chapter" data-level="3.3" data-path="3-inference.html"><a href="3-inference.html#f-tests"><i class="fa fa-check"></i><b>3.3</b> F-tests</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-inference.html"><a href="3-inference.html#theory"><i class="fa fa-check"></i><b>3.3.1</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-inference.html"><a href="3-inference.html#example"><i class="fa fa-check"></i><b>3.4</b> Example</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-inference.html"><a href="3-inference.html#testing-all-covariates"><i class="fa fa-check"></i><b>3.4.1</b> Testing All Covariates</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-inference.html"><a href="3-inference.html#testing-a-single-covariate"><i class="fa fa-check"></i><b>3.4.2</b> Testing a Single Covariate</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-inference.html"><a href="3-inference.html#testing-a-subset-of-covariates"><i class="fa fa-check"></i><b>3.4.3</b> Testing a Subset of Covariates</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-inference.html"><a href="3-inference.html#Inference_Exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-contrasts.html"><a href="4-contrasts.html"><i class="fa fa-check"></i><b>4</b> Contrasts</a>
<ul>
<li class="chapter" data-level="" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_Introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#estimate-and-variance"><i class="fa fa-check"></i><b>4.2</b> Estimate and variance</a></li>
<li class="chapter" data-level="4.3" data-path="4-contrasts.html"><a href="4-contrasts.html#estimating-contrasts-using-glht"><i class="fa fa-check"></i><b>4.3</b> Estimating contrasts using <code>glht()</code></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_glht_OneWayAnova"><i class="fa fa-check"></i><b>4.3.1</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_emmeans"><i class="fa fa-check"></i><b>4.4</b> Using <code>emmeans</code> Package</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_SimpleRegression"><i class="fa fa-check"></i><b>4.4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_OneWayAnova"><i class="fa fa-check"></i><b>4.4.2</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-contrasts.html"><a href="4-contrasts.html#Exercises_Contrasts"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>Statistical Models</b></span></li>
<li class="chapter" data-level="5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html"><i class="fa fa-check"></i><b>5</b> Analysis of Covariance (ANCOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Additive"><i class="fa fa-check"></i><b>5.2</b> Offset parallel Lines (aka additive models)</a></li>
<li class="chapter" data-level="5.3" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Interaction"><i class="fa fa-check"></i><b>5.3</b> Lines with different slopes (aka Interaction model)</a></li>
<li class="chapter" data-level="5.4" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Iris_Example"><i class="fa fa-check"></i><b>5.4</b> Iris Example</a></li>
<li class="chapter" data-level="5.5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html"><i class="fa fa-check"></i><b>6</b> Two-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#review-of-1-way-anova"><i class="fa fa-check"></i><b>6.1</b> Review of 1-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#an-example"><i class="fa fa-check"></i><b>6.1.1</b> An Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>6.1.2</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#pairwise-comparisons"><i class="fa fa-check"></i><b>6.1.3</b> Pairwise Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#two-way-anova-1"><i class="fa fa-check"></i><b>6.2</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#orthogonality"><i class="fa fa-check"></i><b>6.3</b> Orthogonality</a></li>
<li class="chapter" data-level="6.4" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#main-effects-model"><i class="fa fa-check"></i><b>6.4</b> Main Effects Model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees"><i class="fa fa-check"></i><b>6.4.1</b> Example - Fruit Trees</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table"><i class="fa fa-check"></i><b>6.4.2</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.4.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#estimating-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#interaction-model"><i class="fa fa-check"></i><b>6.5</b> Interaction Model</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table-1"><i class="fa fa-check"></i><b>6.5.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.5.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees-continued"><i class="fa fa-check"></i><b>6.5.2</b> Example - Fruit Trees (continued)</a></li>
<li class="chapter" data-level="6.5.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---warpbreaks"><i class="fa fa-check"></i><b>6.5.3</b> Example - Warpbreaks</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#Exercises_TwoWayANOVA"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html"><i class="fa fa-check"></i><b>7</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#detecting-assumption-violations"><i class="fa fa-check"></i><b>7.1</b> Detecting Assumption Violations</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#measures-of-influence"><i class="fa fa-check"></i><b>7.1.1</b> Measures of Influence</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.1.2</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#Exercises_Diagnostics"><i class="fa fa-check"></i><b>7.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html"><i class="fa fa-check"></i><b>8</b> Data Transformations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#a-review-of-logx-and-ex"><i class="fa fa-check"></i><b>8.1</b> A review of <span class="math inline">\(\log(x)\)</span> and <span class="math inline">\(e^x\)</span></a></li>
<li class="chapter" data-level="8.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-response"><i class="fa fa-check"></i><b>8.2</b> Transforming the Response</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#box-cox-family-of-transformations"><i class="fa fa-check"></i><b>8.2.1</b> Box-Cox Family of Transformations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-predictors"><i class="fa fa-check"></i><b>8.3</b> Transforming the predictors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#polynomials-of-a-predictor"><i class="fa fa-check"></i><b>8.3.1</b> Polynomials of a predictor</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-and-square-root-of-a-predictor"><i class="fa fa-check"></i><b>8.3.2</b> Log and Square Root of a predictor</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#galapagos-example"><i class="fa fa-check"></i><b>8.3.3</b> Galapagos Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#interpretation-of-log_10-and-log-transformed-variables"><i class="fa fa-check"></i><b>8.4</b> Interpretation of <span class="math inline">\(\log_{10}\)</span> and <span class="math inline">\(\log\)</span> transformed variables</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-un-transformed-covariates"><i class="fa fa-check"></i><b>8.4.1</b> Log-transformed response, un-transformed covariates</a></li>
<li class="chapter" data-level="8.4.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#un-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.2</b> Un-transformed response, log-transformed covariate</a></li>
<li class="chapter" data-level="8.4.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.3</b> Log-transformed response, log-transformed covariate</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#Transformation-Exercises"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-MultipleRegression-Chapter.html"><a href="9-MultipleRegression-Chapter.html"><i class="fa fa-check"></i><b>9</b> Multiple Regression</a></li>
<li class="chapter" data-level="10" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html"><i class="fa fa-check"></i><b>10</b> Correlated Covariates</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#interpretation-with-correlated-covariates"><i class="fa fa-check"></i><b>10.1</b> Interpretation with Correlated Covariates</a></li>
<li class="chapter" data-level="10.2" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#solutions"><i class="fa fa-check"></i><b>10.2</b> Solutions</a></li>
<li class="chapter" data-level="10.3" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#exercises"><i class="fa fa-check"></i><b>10.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html"><i class="fa fa-check"></i><b>11</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#nested-models"><i class="fa fa-check"></i><b>11.1</b> Nested Models</a></li>
<li class="chapter" data-level="11.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#testing-based-model-selection"><i class="fa fa-check"></i><b>11.2</b> Testing-Based Model Selection</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example---u.s.-life-expectancy"><i class="fa fa-check"></i><b>11.2.1</b> Example - U.S. Life Expectancy</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#criterion-based-procedures"><i class="fa fa-check"></i><b>11.3</b> Criterion Based Procedures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#information-criterions"><i class="fa fa-check"></i><b>11.3.1</b> Information Criterions</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#adjusted-r-sq"><i class="fa fa-check"></i><b>11.3.2</b> Adjusted <code>R-sq</code></a></li>
<li class="chapter" data-level="11.3.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example-1"><i class="fa fa-check"></i><b>11.3.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#Exercises_VariableSelection"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-too-many-predictors-toomanypredictors-chapter.html"><a href="12-too-many-predictors-toomanypredictors-chapter.html"><i class="fa fa-check"></i><b>12</b> Too many Predictors {#TooManyPredictors_Chapter</a></li>
<li class="chapter" data-level="13" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#block-designs"><i class="fa fa-check"></i><b>13.1</b> Block Designs</a></li>
<li class="chapter" data-level="13.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#randomized-complete-block-design-rcbd"><i class="fa fa-check"></i><b>13.2</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="13.3" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#review-of-maximum-likelihood-methods"><i class="fa fa-check"></i><b>13.3</b> Review of Maximum Likelihood Methods</a></li>
<li class="chapter" data-level="13.4" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#way-anova-with-a-random-effect"><i class="fa fa-check"></i><b>13.4</b> 1-way ANOVA with a random effect</a></li>
<li class="chapter" data-level="13.5" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#blocks-as-random-variables"><i class="fa fa-check"></i><b>13.5</b> Blocks as Random Variables</a></li>
<li class="chapter" data-level="13.6" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#nested-effects"><i class="fa fa-check"></i><b>13.6</b> Nested Effects</a></li>
<li class="chapter" data-level="13.7" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#crossed-effects"><i class="fa fa-check"></i><b>13.7</b> Crossed Effects</a></li>
<li class="chapter" data-level="13.8" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#repeated-measures-longitudinal-studies"><i class="fa fa-check"></i><b>13.8</b> Repeated Measures / Longitudinal Studies</a></li>
<li class="chapter" data-level="13.9" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-and-prediction-intervals"><i class="fa fa-check"></i><b>13.9</b> Confidence and Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-intervals"><i class="fa fa-check"></i><b>13.9.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="13.9.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#prediction-intervals"><i class="fa fa-check"></i><b>13.9.2</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#Exercises_RandomEffects"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html"><i class="fa fa-check"></i><b>14</b> Binomial Regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#binomial-regression-model"><i class="fa fa-check"></i><b>14.1</b> Binomial Regression Model</a></li>
<li class="chapter" data-level="14.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#measures-of-fit-quality"><i class="fa fa-check"></i><b>14.2</b> Measures of Fit Quality</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#deviance"><i class="fa fa-check"></i><b>14.2.1</b> Deviance</a></li>
<li class="chapter" data-level="14.2.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>14.2.2</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#confidence-intervals-1"><i class="fa fa-check"></i><b>14.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="14.4" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#interpreting-model-coefficients"><i class="fa fa-check"></i><b>14.4</b> Interpreting model coefficients</a></li>
<li class="chapter" data-level="14.5" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#prediction-and-effective-dose-levels"><i class="fa fa-check"></i><b>14.5</b> Prediction and Effective Dose Levels</a></li>
<li class="chapter" data-level="14.6" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#overdispersion"><i class="fa fa-check"></i><b>14.6</b> Overdispersion</a></li>
<li class="chapter" data-level="14.7" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#roc-curves"><i class="fa fa-check"></i><b>14.7</b> ROC Curves</a></li>
<li class="chapter" data-level="14.8" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#Exercises_BinomialRegression"><i class="fa fa-check"></i><b>14.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-poisson-regression.html"><a href="15-poisson-regression.html"><i class="fa fa-check"></i><b>15</b> Poisson Regression</a></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="16" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html"><i class="fa fa-check"></i><b>16</b> Block Designs</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#randomized-complete-block-design-rcbd-1"><i class="fa fa-check"></i><b>16.1</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="16.2" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#split-plot-designs"><i class="fa fa-check"></i><b>16.2</b> Split-plot designs</a></li>
<li class="chapter" data-level="16.3" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#exercises-1"><i class="fa fa-check"></i><b>16.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html"><i class="fa fa-check"></i><b>17</b> Maximum Likelihood Priciple</a>
<ul>
<li class="chapter" data-level="" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#learning-outcomes-1"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="17.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#introduction-1"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#distributions"><i class="fa fa-check"></i><b>17.2</b> Distributions</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson"><i class="fa fa-check"></i><b>17.2.1</b> Poisson</a></li>
<li class="chapter" data-level="17.2.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential"><i class="fa fa-check"></i><b>17.2.2</b> Exponential</a></li>
<li class="chapter" data-level="17.2.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal"><i class="fa fa-check"></i><b>17.2.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#likelihood-function"><i class="fa fa-check"></i><b>17.3</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson-1"><i class="fa fa-check"></i><b>17.3.1</b> Poisson</a></li>
<li class="chapter" data-level="17.3.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential-example"><i class="fa fa-check"></i><b>17.3.2</b> Exponential Example</a></li>
<li class="chapter" data-level="17.3.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal-1"><i class="fa fa-check"></i><b>17.3.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#discussion"><i class="fa fa-check"></i><b>17.4</b> Discussion</a></li>
<li class="chapter" data-level="17.5" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exercises-2"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="project-appendix.html"><a href="project-appendix.html"><i class="fa fa-check"></i>Project Appendix</a>
<ul>
<li class="chapter" data-level="17.6" data-path="project-appendix.html"><a href="project-appendix.html#weeks-1-4-project-feasibility"><i class="fa fa-check"></i><b>17.6</b> Weeks 1 – 4 (Project Feasibility)</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="project-appendix.html"><a href="project-appendix.html#wibgis"><i class="fa fa-check"></i><b>17.6.1</b> WIBGIs</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Methods II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Inference</h1>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="3-inference.html#cb13-1" aria-hidden="true"></a><span class="kw">library</span>(tidymodels) <span class="co"># Grab model results as data frames</span></span>
<span id="cb13-2"><a href="3-inference.html#cb13-2" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)  <span class="co"># ggplot2, dplyr, tidyr</span></span></code></pre></div>
<div id="Inference_LearningOutcomes" class="section level3 unnumbered">
<h3>Learning Outcomes</h3>
<ul>
<li>Utilize <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> and its standard errors of to produce confidence intervals and hypothesis tests for <span class="math inline">\(\beta_j\)</span> values.</li>
<li>Convert hypothesis tests for <span class="math inline">\(\beta_j=0\)</span> into a model comparison F-test.</li>
<li>Utilize F-tests to perform a hypothesis test of multiple <span class="math inline">\(\beta_j\)</span> values all being equal to zero. This is the simple vs complex model comparison.</li>
<li>Create confidence intervals for <span class="math inline">\(\beta_j\)</span> values leveraging the normality assumption of residuals.</li>
</ul>
</div>
<div id="Inference_Introduction" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>The goal of statistics is to take information calculated from sample data and use that information to estimate population parameters. The problem is that the sample statistic is only a rough guess and if we were to collect another sample of data, we’d get a different sample statistic and thus a different parameter estimate. Therefore, we need to utilize the sample statistics to create confidence intervals and make hypothesis tests about those parameters.</p>
<ul>
<li>Introduce the inference ideas about why we care.</li>
<li>Introduce the Gala data set.</li>
<li></li>
</ul>
<p>In this chapter, we’ll consider a dataset about the Galápagos Islands relating the number of tortoise species on an island to various island characteristics such as size, maximum elevation, etc. The set contains <span class="math inline">\(n=30\)</span> islands and</p>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>Species</code></td>
<td>Number of tortoise species found on the island</td>
</tr>
<tr class="even">
<td><code>Endimics</code></td>
<td>Number of tortoise species endemic to the island</td>
</tr>
<tr class="odd">
<td><code>Elevation</code></td>
<td>Elevation of the highest point on the island</td>
</tr>
<tr class="even">
<td><code>Area</code></td>
<td>Area of the island (km<span class="math inline">\(^2\)</span>)</td>
</tr>
<tr class="odd">
<td><code>Nearest</code></td>
<td>Distance to the nearest neighboring island (km)</td>
</tr>
<tr class="even">
<td><code>Scruz</code></td>
<td>Distance to the Santa Cruz islands (km)</td>
</tr>
<tr class="odd">
<td><code>Adjacent</code></td>
<td>Area of the nearest adjacent island (km<span class="math inline">\(^2\)</span>)</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="3-inference.html#cb14-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&#39;gala&#39;</span>, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)     <span class="co"># import the data set</span></span>
<span id="cb14-2"><a href="3-inference.html#cb14-2" aria-hidden="true"></a><span class="kw">head</span>(gala)                          <span class="co"># show the first couple of rows</span></span></code></pre></div>
<pre><code>##              Species Endemics  Area Elevation Nearest Scruz Adjacent
## Baltra            58       23 25.09       346     0.6   0.6     1.84
## Bartolome         31       21  1.24       109     0.6  26.3   572.33
## Caldwell           3        3  0.21       114     2.8  58.7     0.78
## Champion          25        9  0.10        46     1.9  47.4     0.18
## Coamano            2        1  0.05        77     1.9   1.9   903.82
## Daphne.Major      18       11  0.34       119     8.0   8.0     1.84</code></pre>
</div>
<div id="confidence-intervals-and-hypothesis-tests" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Confidence Intervals and Hypothesis Tests</h2>
<p>We can now state the general method of creating confidence intervals
and perform hypothesis tests for any element of <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>The general recipe for a <span class="math inline">\((1-\alpha)*100\%\)</span> confidence interval is
<span class="math display">\[\textrm{Estimate} \pm Q^*_{1-\alpha/2} \;\textrm{StdErr( Estimate )}\]</span>
where <span class="math inline">\(Q^*_{1-\alpha/2}\)</span> is the <span class="math inline">\(1-\alpha/2\)</span> quantile from some appropriate distribution. The mathematical details about which distribution the quantile should come from are often obscure, but usually involve the degrees of freedom <span class="math inline">\(n-p\)</span> where <span class="math inline">\(p\)</span> is the number of parameters in the “signal” part of the model.</p>
<p>The confidence interval formula for the <span class="math inline">\(\beta\)</span> parameters in a linear model is
<span class="math display">\[\hat{\beta}_{j}\pm t^*_{1-\alpha/2, n-p}\,StdErr\left(\hat{\beta}_{j}\right)\]</span></p>
<p>where <span class="math inline">\(t^*_{1-\alpha/2, n-p}\)</span> is the <span class="math inline">\(1-\alpha/2\)</span> quantile from the t-distribution with <span class="math inline">\(n-p\)</span> degrees of freedom. A test statistic for testing <span class="math inline">\(H_{0}:\,\beta_{j}=0\)</span> versus <span class="math inline">\(H_{a}:\,\beta_{j}\ne0\)</span> is</p>
<p><span class="math display">\[t_{n-p}=\frac{\hat{\beta}_{j}-0}{StdErr\left(\hat{\beta}_{j}\right)}\]</span></p>
</div>
<div id="f-tests" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> F-tests</h2>
<p>We wish to develop a rigorous way to compare nested models and decide if a complicated model explains enough more variability than a simple model to justify the additional intellectual effort of thinking about the data in the complicated fashion.</p>
<p>It is important to specify that we are developing a way of testing nested models. By nested, we mean that the simple model can be created from the full model just by setting one or more model parameters to zero. This method doesn’t constrain us for testing just a single parameter being possibly zero. Instead we can test if an entire set of parameters all possibly being equal to zero.</p>
<div id="theory" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Theory</h3>
<p>Recall that in the simple regression and ANOVA cases we were interested in comparing a simple model versus a more complex model. For each model we computed the sum of squares error (SSE) and said that if the complicated model performed much better than the simple then <span class="math inline">\(SSE_{simple}\gg SSE_{complex}\)</span>.</p>
<p>Recall from the estimation chapter, the model parameter estimates are found by using the <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> values that minimize the SSE. If it were to turn out that a <span class="math inline">\(\hat{\beta}_j\)</span> of zero minimized SSE, then zero would be estimate. Next consider that we are requiring the simple model to be a simplification of the complex model by setting certain parameters to zero. So we are considering a simple model that sets <span class="math inline">\(\hat{\beta}_j=0\)</span> and vs a complex model that allows for <span class="math inline">\(\hat{\beta}_j\)</span> to be any real value (including), then because we select <span class="math inline">\(\hat{\beta}_j\)</span> to be the value that minimizes SSE, then <span class="math inline">\(SSE_{simple} \ge SSE_{complex}\)</span>.</p>
<p>We’ll define <span class="math inline">\(SSE_{difference} = SSE_{simple} - SSE{complex} \ge 0\)</span> and observe that if the complex model is a much better fit to the data, then <span class="math inline">\(SSE_{difference}\)</span> is large. But how large is large enough to be statistically significant? In part, it depends on how many more parameters were added to the model and what the amount of unexplained variability left in the complex model. Let <span class="math inline">\(df_{diff}\)</span> be the number of parameters difference between the simple and complex models.</p>
<p>As with most test statistics, the F statistic can be considered as a “Signal-to-Noise” ratio where the signal part is the increased amount of variability explained per additional parameter by the complex model and the noise part is just the MSE of the complex model.</p>
<p><span class="math display">\[F = \frac{\textrm{Signal}}{\textrm{Noise}} = \frac{RSS_{difference}/df_{diff}}{RSS_{complex}/df_{complex}}\]</span></p>
<p>and we claimed that if the null hypothesis was true (i.e. the complex model is an unnecessary obfuscation of the simple), then this ratio follows an F-distribution with degrees of freedom <span class="math inline">\(df_{diff}\)</span> and <span class="math inline">\(df_{complex}\)</span>.</p>
<p>The F-distribution is centered near one and we should reject the simple model (in favor of the complex model) if this F statistic is much larger than one. Therefore the p-value for the test is</p>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>This hypothesis test doesn’t require a particular difference in number of parameters in each model, while the single parameter t-test is stuck testing if just a single parameter is possibly zero. In the single parameter test case, the t-test and F-test give the same prior hypothesis test previous t-test. The a corresponding t-test and F-test will give the same p-value and therefore the same inference about if <span class="math inline">\(\beta_j\)</span> is possibly zero.</p>
</div>
</div>
<div id="example" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Example</h2>
<p>We will consider a data set from Johnson and Raven (1973) which also appears in Weisberg (1985). This data set is concerned with the number of tortoise species on <span class="math inline">\(n=30\)</span> different islands in the Galapagos. The variables of interest in the data set are:</p>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>Species</code></td>
<td>Number of tortoise species found on the island</td>
</tr>
<tr class="even">
<td><code>Endimics</code></td>
<td>Number of tortoise species endemic to the island</td>
</tr>
<tr class="odd">
<td><code>Elevation</code></td>
<td>Elevation of the highest point on the island</td>
</tr>
<tr class="even">
<td><code>Area</code></td>
<td>Area of the island (km<span class="math inline">\(^2\)</span>)</td>
</tr>
<tr class="odd">
<td><code>Nearest</code></td>
<td>Distance to the nearest neighboring island (km)</td>
</tr>
<tr class="even">
<td><code>Scruz</code></td>
<td>Distance to the Santa Cruz islands (km)</td>
</tr>
<tr class="odd">
<td><code>Adjacent</code></td>
<td>Area of the nearest adjacent island (km<span class="math inline">\(^2\)</span>)</td>
</tr>
</tbody>
</table>
<p>We will first read in the data set from the package <code>faraway</code>.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="3-inference.html#cb16-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&#39;gala&#39;</span>, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)     <span class="co"># import the data set</span></span>
<span id="cb16-2"><a href="3-inference.html#cb16-2" aria-hidden="true"></a><span class="kw">head</span>(gala)                          <span class="co"># show the first couple of rows</span></span></code></pre></div>
<pre><code>##              Species Endemics  Area Elevation Nearest Scruz Adjacent
## Baltra            58       23 25.09       346     0.6   0.6     1.84
## Bartolome         31       21  1.24       109     0.6  26.3   572.33
## Caldwell           3        3  0.21       114     2.8  58.7     0.78
## Champion          25        9  0.10        46     1.9  47.4     0.18
## Coamano            2        1  0.05        77     1.9   1.9   903.82
## Daphne.Major      18       11  0.34       119     8.0   8.0     1.84</code></pre>
<p>First we will create the full model that predicts the number of species as a function of elevation, area, nearest, scruz and adjacent. Notice that this model has <span class="math inline">\(p=6\)</span> <span class="math inline">\(\beta_{i}\)</span> values (one for each coefficient plus the intercept).</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1 Area_i + \beta_2 Elevation_i + \beta_3 Nearest_i + \beta_4 Scruz_i + \beta_5 Adjacent_i + \epsilon_i\]</span></p>
<p>We can happily fit this model just by adding terms on the left hand side of the model formula. Notice that R creates the design matrix <span class="math inline">\(X\)</span> for us.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="3-inference.html#cb18-1" aria-hidden="true"></a>M.c &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st"> </span>Area <span class="op">+</span><span class="st"> </span>Elevation <span class="op">+</span><span class="st"> </span>Nearest <span class="op">+</span><span class="st"> </span>Scruz <span class="op">+</span><span class="st"> </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb18-2"><a href="3-inference.html#cb18-2" aria-hidden="true"></a><span class="kw">model.matrix</span>(M.c)  <span class="co"># this is the design matrix X.</span></span></code></pre></div>
<pre><code>##              (Intercept)    Area Elevation Nearest Scruz Adjacent
## Baltra                 1   25.09       346     0.6   0.6     1.84
## Bartolome              1    1.24       109     0.6  26.3   572.33
## Caldwell               1    0.21       114     2.8  58.7     0.78
## Champion               1    0.10        46     1.9  47.4     0.18
## Coamano                1    0.05        77     1.9   1.9   903.82
## Daphne.Major           1    0.34       119     8.0   8.0     1.84
## Daphne.Minor           1    0.08        93     6.0  12.0     0.34
## Darwin                 1    2.33       168    34.1 290.2     2.85
## Eden                   1    0.03        71     0.4   0.4    17.95
## Enderby                1    0.18       112     2.6  50.2     0.10
## Espanola               1   58.27       198     1.1  88.3     0.57
## Fernandina             1  634.49      1494     4.3  95.3  4669.32
## Gardner1               1    0.57        49     1.1  93.1    58.27
## Gardner2               1    0.78       227     4.6  62.2     0.21
## Genovesa               1   17.35        76    47.4  92.2   129.49
## Isabela                1 4669.32      1707     0.7  28.1   634.49
## Marchena               1  129.49       343    29.1  85.9    59.56
## Onslow                 1    0.01        25     3.3  45.9     0.10
## Pinta                  1   59.56       777    29.1 119.6   129.49
## Pinzon                 1   17.95       458    10.7  10.7     0.03
## Las.Plazas             1    0.23        94     0.5   0.6    25.09
## Rabida                 1    4.89       367     4.4  24.4   572.33
## SanCristobal           1  551.62       716    45.2  66.6     0.57
## SanSalvador            1  572.33       906     0.2  19.8     4.89
## SantaCruz              1  903.82       864     0.6   0.0     0.52
## SantaFe                1   24.08       259    16.5  16.5     0.52
## SantaMaria             1  170.92       640     2.6  49.2     0.10
## Seymour                1    1.84       147     0.6   9.6    25.09
## Tortuga                1    1.24       186     6.8  50.9    17.95
## Wolf                   1    2.85       253    34.1 254.7     2.33
## attr(,&quot;assign&quot;)
## [1] 0 1 2 3 4 5</code></pre>
<p>All the usual calculations from chapter two can be calculated and we can see the summary table for this regression as follows:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="3-inference.html#cb20-1" aria-hidden="true"></a><span class="kw">summary</span>(M.c)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Species ~ Area + Elevation + Nearest + Scruz + Adjacent, 
##     data = gala)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -111.679  -34.898   -7.862   33.460  182.584 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  7.068221  19.154198   0.369 0.715351    
## Area        -0.023938   0.022422  -1.068 0.296318    
## Elevation    0.319465   0.053663   5.953 3.82e-06 ***
## Nearest      0.009144   1.054136   0.009 0.993151    
## Scruz       -0.240524   0.215402  -1.117 0.275208    
## Adjacent    -0.074805   0.017700  -4.226 0.000297 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 60.98 on 24 degrees of freedom
## Multiple R-squared:  0.7658, Adjusted R-squared:  0.7171 
## F-statistic:  15.7 on 5 and 24 DF,  p-value: 6.838e-07</code></pre>
<div id="testing-all-covariates" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Testing All Covariates</h3>
<p>The first test we might want to do is to test if any of the covariates are significant. That is to say that we want to test the full model versus the simple null hypothesis model
<span class="math display">\[y_{i}=\beta_{0}+\epsilon_{i}\]</span>
that has no covariates and only a y-intercept. So we will create a simple model</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="3-inference.html#cb22-1" aria-hidden="true"></a>M.s &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>gala)</span></code></pre></div>
<p>and calculate the appropriate Residual Sums of Squares (RSS) for each model, along with the difference in degrees of freedom between the two models.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="3-inference.html#cb23-1" aria-hidden="true"></a>RSS.c &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">resid</span>(M.c)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb23-2"><a href="3-inference.html#cb23-2" aria-hidden="true"></a>RSS.s &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">resid</span>(M.s)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb23-3"><a href="3-inference.html#cb23-3" aria-hidden="true"></a>df.diff &lt;-<span class="st"> </span><span class="dv">5</span>               <span class="co"># complex model has 5 additional parameters</span></span>
<span id="cb23-4"><a href="3-inference.html#cb23-4" aria-hidden="true"></a>df.c &lt;-<span class="st"> </span><span class="dv">30</span> <span class="op">-</span><span class="st"> </span><span class="dv">6</span>             <span class="co"># complex model has 24 degrees of freedom left</span></span></code></pre></div>
<p>The F-statistic for this test is therefore</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="3-inference.html#cb24-1" aria-hidden="true"></a>F.stat &lt;-<span class="st">  </span>( (RSS.s <span class="op">-</span><span class="st"> </span>RSS.c) <span class="op">/</span><span class="st"> </span>df.diff ) <span class="op">/</span><span class="st"> </span>( RSS.c <span class="op">/</span><span class="st"> </span>df.c )</span>
<span id="cb24-2"><a href="3-inference.html#cb24-2" aria-hidden="true"></a>F.stat</span></code></pre></div>
<pre><code>## [1] 15.69941</code></pre>
<p>and should be compared against the F-distribution with <span class="math inline">\(5\)</span> and <span class="math inline">\(24\)</span> degrees of freedom. Because a large difference between RSS.s and RSS.c would be evidence for the alternative, larger model, the p-value for this test is <span class="math display">\[p-value=P\left(F_{5,24}\ge\mathtt{F.stat}\right)\]</span></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="3-inference.html#cb26-1" aria-hidden="true"></a>p.value &lt;-<span class="st">  </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(<span class="fl">15.699</span>, <span class="dv">5</span>, <span class="dv">24</span>)</span>
<span id="cb26-2"><a href="3-inference.html#cb26-2" aria-hidden="true"></a>p.value</span></code></pre></div>
<pre><code>## [1] 6.839486e-07</code></pre>
<p>Both the F.stat and its p-value are given at the bottom of the summary table. However, I might be interested in creating an ANOVA table for this situation.</p>
<table>
<thead>
<tr class="header">
<th>Source</th>
<th>df</th>
<th>Sum Sq</th>
<th>Mean Sq</th>
<th>F</th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Difference</td>
<td><span class="math inline">\(p-1\)</span></td>
<td><span class="math inline">\(RSS_d\)</span></td>
<td><span class="math inline">\(MSE_d = RSS_d / (p-1)\)</span></td>
<td><span class="math inline">\(MSE_d/MSE_c\)</span></td>
<td><span class="math inline">\(P(F &gt; F_{p-1,n-p})\)</span></td>
</tr>
<tr class="even">
<td>Complex</td>
<td><span class="math inline">\(n-p\)</span></td>
<td><span class="math inline">\(RSS_c\)</span></td>
<td><span class="math inline">\(MSE_c = RSS_c / (n-p)\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Simple</td>
<td><span class="math inline">\(n-1\)</span></td>
<td><span class="math inline">\(RSS_s\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>This type of table is often shown in textbooks, but base functions in R don’t produce exactly this table. Instead the <code>anova(simple, complex)</code> command produces the following:</p>
<table>
<thead>
<tr class="header">
<th>Models</th>
<th>df</th>
<th>RSS</th>
<th>Diff in RSS</th>
<th>F</th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Simple</td>
<td><span class="math inline">\(n-1\)</span></td>
<td><span class="math inline">\(RSS_s\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Complex</td>
<td><span class="math inline">\(n-p\)</span></td>
<td><span class="math inline">\(RSS_c\)</span></td>
<td><span class="math inline">\(RSS_d\)</span></td>
<td><span class="math inline">\(MSE_d/MSE_c\)</span></td>
<td><span class="math inline">\(P(F &gt; F_{p-1,n-p})\)</span></td>
</tr>
</tbody>
</table>
<p>can be obtained from R by using the <code>anova()</code> function on the two models of interest. This representation skips showing the Mean Squared calculations.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="3-inference.html#cb28-1" aria-hidden="true"></a><span class="kw">anova</span>(M.s, M.c)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Species ~ 1
## Model 2: Species ~ Area + Elevation + Nearest + Scruz + Adjacent
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     29 381081                                  
## 2     24  89231  5    291850 15.699 6.838e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="testing-a-single-covariate" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Testing a Single Covariate</h3>
<p>For a particular covariate, <span class="math inline">\(\beta_{j}\)</span>, we might wish to perform a test to see if it can be removed from the model. It can be shown that the F-statistic can be re-written as</p>
<p><span class="math display">\[\begin{aligned}
F   &amp;=  \frac{\left[RSS_{s}-RSS_{c}\right]/1}{RSS_{c}/\left(n-p\right)}\\
    &amp;=  \vdots\\
    &amp;=  \left[\frac{\hat{\beta_{j}}}{SE\left(\hat{\beta}_{j}\right)}\right]^{2}\\
    &amp;= t^{2}
\end{aligned}\]</span>
where <span class="math inline">\(t\)</span> has a t-distribution with <span class="math inline">\(n-p\)</span> degrees of freedom under the null hypothesis that the simple model is sufficient.</p>
<p>We consider the case of removing the covariate <code>Area</code> from the model and will calculate our test statistic using both methods.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="3-inference.html#cb30-1" aria-hidden="true"></a>M.c &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st"> </span>Area <span class="op">+</span><span class="st"> </span>Elevation <span class="op">+</span><span class="st"> </span>Nearest <span class="op">+</span><span class="st"> </span>Scruz <span class="op">+</span><span class="st"> </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb30-2"><a href="3-inference.html#cb30-2" aria-hidden="true"></a>M.s &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st">        </span>Elevation <span class="op">+</span><span class="st"> </span>Nearest <span class="op">+</span><span class="st"> </span>Scruz <span class="op">+</span><span class="st"> </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb30-3"><a href="3-inference.html#cb30-3" aria-hidden="true"></a>RSS.c &lt;-<span class="st"> </span><span class="kw">sum</span>( <span class="kw">resid</span>(M.c)<span class="op">^</span><span class="dv">2</span> )</span>
<span id="cb30-4"><a href="3-inference.html#cb30-4" aria-hidden="true"></a>RSS.s &lt;-<span class="st"> </span><span class="kw">sum</span>( <span class="kw">resid</span>(M.s)<span class="op">^</span><span class="dv">2</span> )</span>
<span id="cb30-5"><a href="3-inference.html#cb30-5" aria-hidden="true"></a>df.d &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb30-6"><a href="3-inference.html#cb30-6" aria-hidden="true"></a>df.c &lt;-<span class="st"> </span><span class="dv">30-6</span></span>
<span id="cb30-7"><a href="3-inference.html#cb30-7" aria-hidden="true"></a>F.stat &lt;-<span class="st"> </span>((RSS.s <span class="op">-</span><span class="st"> </span>RSS.c)<span class="op">/</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(RSS.c <span class="op">/</span><span class="st"> </span>df.c)</span>
<span id="cb30-8"><a href="3-inference.html#cb30-8" aria-hidden="true"></a>F.stat</span></code></pre></div>
<pre><code>## [1] 1.139792</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="3-inference.html#cb32-1" aria-hidden="true"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pf</span>(F.stat, <span class="dv">1</span>, <span class="dv">24</span>)</span></code></pre></div>
<pre><code>## [1] 0.296318</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="3-inference.html#cb34-1" aria-hidden="true"></a><span class="kw">sqrt</span>(F.stat)</span></code></pre></div>
<pre><code>## [1] 1.067611</code></pre>
<p>To calculate it using the estimated coefficient and its standard error, we must grab those values from the summary table</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="3-inference.html#cb36-1" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(M.c)  <span class="co"># get the coefficient table </span></span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   term        estimate std.error statistic    p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 (Intercept)  7.07      19.2      0.369   0.715     
## 2 Area        -0.0239     0.0224  -1.07    0.296     
## 3 Elevation    0.319      0.0537   5.95    0.00000382
## 4 Nearest      0.00914    1.05     0.00867 0.993     
## 5 Scruz       -0.241      0.215   -1.12    0.275     
## 6 Adjacent    -0.0748     0.0177  -4.23    0.000297</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="3-inference.html#cb38-1" aria-hidden="true"></a>beta.area    &lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">tidy</span>(M.c)[<span class="dv">2</span>,<span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>()   <span class="co"># pull turns it into a scalar</span></span>
<span id="cb38-2"><a href="3-inference.html#cb38-2" aria-hidden="true"></a>SE.beta.area &lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">tidy</span>(M.c)[<span class="dv">2</span>,<span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>()</span>
<span id="cb38-3"><a href="3-inference.html#cb38-3" aria-hidden="true"></a>t &lt;-<span class="st"> </span>beta.area <span class="op">/</span><span class="st"> </span>SE.beta.area</span>
<span id="cb38-4"><a href="3-inference.html#cb38-4" aria-hidden="true"></a>t</span></code></pre></div>
<pre><code>## [1] -1.067611</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="3-inference.html#cb40-1" aria-hidden="true"></a><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(t, <span class="dv">24</span>)</span></code></pre></div>
<pre><code>## [1] 0.296318</code></pre>
<p>All that hand calculation is tedious, so we can again use the <code>anova()</code>() command to compare the two models.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="3-inference.html#cb42-1" aria-hidden="true"></a><span class="kw">anova</span>(M.s, M.c)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Species ~ Elevation + Nearest + Scruz + Adjacent
## Model 2: Species ~ Area + Elevation + Nearest + Scruz + Adjacent
##   Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)
## 1     25 93469                           
## 2     24 89231  1    4237.7 1.1398 0.2963</code></pre>
</div>
<div id="testing-a-subset-of-covariates" class="section level3" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Testing a Subset of Covariates</h3>
<p>Often a researcher will want to remove a subset of covariates from the model. In the Galapagos example, Area, Nearest, and Scruz all have non-significant p-values and would be removed when comparing the full model to the model without that one covariate. While each of them might be non-significant, is the sum of all three significant?</p>
<p>Because the individual <span class="math inline">\(\hat{\beta}_{j}\)</span> values are not independent, then we cannot claim that the subset is not statistically significant just because each variable in turn was insignificant. Instead we again create simple and complex models in the same fashion as we have previously done.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="3-inference.html#cb44-1" aria-hidden="true"></a>M.c &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st"> </span>Area <span class="op">+</span><span class="st"> </span>Elevation <span class="op">+</span><span class="st"> </span>Nearest <span class="op">+</span><span class="st"> </span>Scruz <span class="op">+</span><span class="st"> </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb44-2"><a href="3-inference.html#cb44-2" aria-hidden="true"></a>M.s &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st">        </span>Elevation <span class="op">+</span><span class="st">                   </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb44-3"><a href="3-inference.html#cb44-3" aria-hidden="true"></a><span class="kw">anova</span>(M.s, M.c)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Species ~ Elevation + Adjacent
## Model 2: Species ~ Area + Elevation + Nearest + Scruz + Adjacent
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     27 100003                           
## 2     24  89231  3     10772 0.9657  0.425</code></pre>
<p>We find a large p-value associated with this test and can safely stay with the null hypothesis, that the simple model is sufficient to explain the observed variability in the number of species of tortoise.</p>
</div>
</div>
<div id="Inference_Exercises" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>The dataset prostate in package <code>faraway</code> has information about a study of 97 men with prostate cancer. We import the data and examine the first four observations using the following commands.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="3-inference.html#cb46-1" aria-hidden="true"></a><span class="kw">data</span>(prostate, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)</span>
<span id="cb46-2"><a href="3-inference.html#cb46-2" aria-hidden="true"></a><span class="kw">head</span>(prostate)</span></code></pre></div>
<p>It is possible to get information about the data set using the command <code>help(prostate)</code>. Fit a model with <code>lpsa</code> as the response and all the other variables as predictors.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Compute <span class="math inline">\(90\%\)</span> and <span class="math inline">\(95\%\)</span> confidence intervals for the parameter associated with <code>age</code>. Using just these intervals, what could we deduced about the p-value for age in the regression summary. <em>Hint: look at the help for the function <code>confint()</code>. You’ll find the <code>level</code> option to be helpful. Alternatively use the <code>broom::tidy()</code> function with the <code>conf.int=TRUE</code> option and also use the <code>level=</code> option as well.</em></p></li>
<li><p>Remove all the predictors that are not significant at the <span class="math inline">\(5\%\)</span> level. Test this model against the original model. Which is preferred?</p></li>
</ol></li>
<li><p>Thirty samples of cheddar cheese were analyzed for their content of acetic acid, hydrogen sulfide and lactic acid. Each sample was tasted and scored by a panel of judges and the average taste score produces. Used the <code>cheddar</code> dataset from the <code>faraway</code> package (import it the same way you did in problem one, but now use <code>cheddar</code>) to answer the following:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Fit a regression model with taste as the response and the three chemical contents as predictors. Identify the predictors that are statistically significant at the <span class="math inline">\(5\%\)</span> level.</p></li>
<li><p><code>Acetic</code> and <code>H2S</code> are measured on a log<span class="math inline">\(_{10}\)</span> scale. Create two new columns in the <code>cheddar</code> data frame that contain the values on their original scale. Fit a linear model that uses the three covariates on their non-log scale. Identify the predictors that are statistically significant at the 5% level for this model.</p></li>
<li><p>Can we use an <span class="math inline">\(F\)</span>-test to compare these two models? Explain why or why not. Which model provides a better fit to the data? Explain your reasoning.</p></li>
<li><p>For the model in part (a), if a sample of cheese were to have <code>H2S</code> increased by 2 (where H2S is on the log scale and we increase this value by 2 using some method), what change in taste would be expected? What caveates must be made in this interpretation? <em>Hint: I don’t want to get into interpreting parameters on the log scale just yet. So just interpret this as adding 2 to the covariate value and predicting the change in taste.</em></p></li>
</ol></li>
<li><p>The <code>sat</code> data set in the <code>faraway</code> package gives data collected to study the relationship between expenditures on public education and test results.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Fit a model that with <code>total</code> SAT score as the response and only the intercept as a covariate.</p></li>
<li><p>Fit a model with <code>total</code> SAT score as the response and <code>expend</code>, <code>ratio</code>, and <code>salary</code> as predictors (along with the intercept).</p></li>
<li><p>Compare the models in parts (a) and (b) using an F-test. Is the larger model superior?</p></li>
<li><p>Examine the summary table of the larger model? Does this contradict your results in part (c)? What might be causing this issue? Create a graph or summary diagnostics to support your guess.</p></li>
<li><p>Fit the model with <code>salary</code> and <code>ratio</code> (along with the intercept) as predictor variables and examine the summary table. Which covariates are significant?</p></li>
<li><p>Now add <code>takers</code> to the model (so the model now includes three predictor variables along with the intercept). Test the hypothesis that <span class="math inline">\(\beta_{takers}=0\)</span> using the summary table.</p></li>
<li><p>Discuss why <code>ratio</code> was not significant in the model in part (e) but was significant in part (f). <em>Hint: Look at the Residual Standard Error <span class="math inline">\(\hat{\sigma}\)</span> in each model and argue that each t-statistic is some variant of a “signal-to-noise” ratio and that the “noise” part is reduced in the second model.</em></p></li>
</ol></li>
<li><p>In this exercise, we will show that adding a covariate to the model that is just random noise will decrease the model Sum of Squared Error (SSE).</p>
<ol style="list-style-type: lower-alpha">
<li><p>Fit a linear model to the <code>trees</code> dataset that is always preloaded in R. Recall that this dataset has observations from 31 cherry trees with variables tree height, girth and volume of lumber produced. Fit Volume ~ Height.</p></li>
<li><p>From this simple regression model, obtain the SSE. <em>Hint: you can calculate this yourself, pull it from the broom::glance() output where it is entitled <code>deviance</code> or extract it from the output of the <code>anova()</code> command.</em></p></li>
<li><p>Add a new covariate to the model named <code>Noise</code> that is generated at random from a uniform distribution using the following code:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="3-inference.html#cb47-1" aria-hidden="true"></a>trees &lt;-<span class="st"> </span>trees <span class="op">%&gt;%</span></span>
<span id="cb47-2"><a href="3-inference.html#cb47-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>( <span class="dt">Noise =</span> <span class="kw">runif</span>( <span class="kw">n</span>() ) )</span></code></pre></div></li>
<li><p>Fit a linear model that includes this new <code>Noise</code> variable in addition to the <code>Height</code>. Calculate the SSE error in the same manner as before. Does it decrease or increase. Quantify how much it has changed.</p></li>
<li><p>Repeat parts (c) and (d) several times. Comment on the trend in change in SSE. <em>Hint: This isn’t strictly necessary but is how I would go about answering this question. Wrap parts (c) and (d) in a <code>for</code> loop and generate a data.frame of a couple hundred runs. Then make a density plot of the SSE values for the complex models and add a vertical line on the graph of the simple model SSE.</em></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="3-inference.html#cb48-1" aria-hidden="true"></a>results &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb48-2"><a href="3-inference.html#cb48-2" aria-hidden="true"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2000</span> ){</span>
<span id="cb48-3"><a href="3-inference.html#cb48-3" aria-hidden="true"></a>  <span class="co"># Do stuff</span></span>
<span id="cb48-4"><a href="3-inference.html#cb48-4" aria-hidden="true"></a>  results &lt;-<span class="st"> </span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rbind</span>( <span class="kw">glance</span>(model) ) </span>
<span id="cb48-5"><a href="3-inference.html#cb48-5" aria-hidden="true"></a>}</span>
<span id="cb48-6"><a href="3-inference.html#cb48-6" aria-hidden="true"></a><span class="kw">ggplot</span>(results, <span class="kw">aes</span>(<span class="dt">x=</span>deviance)) <span class="op">+</span></span>
<span id="cb48-7"><a href="3-inference.html#cb48-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_density</span>() <span class="op">+</span></span>
<span id="cb48-8"><a href="3-inference.html#cb48-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>( <span class="dt">xintercept =</span> simple.SSE )</span></code></pre></div></li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-parameter-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-contrasts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/571/blob/master/03_Inference.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/dereksonderegger/571/raw/master/03_Inference.Rmd",
"text": null
},
"download": [["Statistical_Methods_II.pdf", "PDF"], ["Statistical_Methods_II.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

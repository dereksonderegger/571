<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Data Transformations | Statistical Methods II</title>
  <meta name="description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="generator" content="bookdown 0.20.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Data Transformations | Statistical Methods II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  <meta name="github-repo" content="dereksonderegger/STA_571_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Data Transformations | Statistical Methods II" />
  
  <meta name="twitter:description" content="The second semester of an Intro Stats course designed for graduate students in Biology, Forestry, Ecology, etc." />
  

<meta name="author" content="Derek L. Sonderegger" />


<meta name="date" content="2020-10-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="7-Diagnostics-Chapter.html"/>
<link rel="next" href="9-MultipleRegression-Chapter.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Methods II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Statistical Theory</b></span></li>
<li class="chapter" data-level="1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html"><i class="fa fa-check"></i><b>1</b> Matrix Manipulation</a>
<ul>
<li class="chapter" data-level="" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="1.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#MatrixTheory_Introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#types-of-matrices"><i class="fa fa-check"></i><b>1.2</b> Types of Matrices</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalars"><i class="fa fa-check"></i><b>1.2.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vectors"><i class="fa fa-check"></i><b>1.2.2</b> Vectors</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix"><i class="fa fa-check"></i><b>1.2.3</b> Matrix</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#square-matrices"><i class="fa fa-check"></i><b>1.2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#symmetric-matrices"><i class="fa fa-check"></i><b>1.2.5</b> Symmetric Matrices</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#diagonal-matrices"><i class="fa fa-check"></i><b>1.2.6</b> Diagonal Matrices</a></li>
<li class="chapter" data-level="1.2.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#identity-matrices"><i class="fa fa-check"></i><b>1.2.7</b> Identity Matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#operations-on-matrices"><i class="fa fa-check"></i><b>1.3</b> Operations on Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#transpose"><i class="fa fa-check"></i><b>1.3.1</b> Transpose</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#addition-and-subtraction"><i class="fa fa-check"></i><b>1.3.2</b> Addition and Subtraction</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#multiplication"><i class="fa fa-check"></i><b>1.3.3</b> Multiplication</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#vector-multiplication"><i class="fa fa-check"></i><b>1.3.4</b> Vector Multiplication</a></li>
<li class="chapter" data-level="1.3.5" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.3.5</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="1.3.6" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#scalar-times-a-matrix"><i class="fa fa-check"></i><b>1.3.6</b> Scalar times a Matrix</a></li>
<li class="chapter" data-level="1.3.7" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#determinant"><i class="fa fa-check"></i><b>1.3.7</b> Determinant</a></li>
<li class="chapter" data-level="1.3.8" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#inverse"><i class="fa fa-check"></i><b>1.3.8</b> Inverse</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-matrix-manipulation.html"><a href="1-matrix-manipulation.html#Exercises_MatrixTheory"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html"><i class="fa fa-check"></i><b>2</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#model-specifications"><i class="fa fa-check"></i><b>2.2</b> Model Specifications</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#simple-regression"><i class="fa fa-check"></i><b>2.2.1</b> Simple Regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#anova-model"><i class="fa fa-check"></i><b>2.2.2</b> ANOVA model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#parameter-estimation-1"><i class="fa fa-check"></i><b>2.3</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-location-paramters"><i class="fa fa-check"></i><b>2.3.1</b> Estimation of Location Paramters</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#estimation-of-variance-parameter"><i class="fa fa-check"></i><b>2.3.2</b> Estimation of Variance Parameter</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#standard-errors"><i class="fa fa-check"></i><b>2.4</b> Standard Errors</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#expectation-and-variance-of-a-random-vector"><i class="fa fa-check"></i><b>2.4.1</b> Expectation and variance of a random vector</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#variance-of-location-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Variance of Location Parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#summary-of-pertinent-results"><i class="fa fa-check"></i><b>2.4.3</b> Summary of pertinent results</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#r-example"><i class="fa fa-check"></i><b>2.5</b> R example</a></li>
<li class="chapter" data-level="2.6" data-path="2-parameter-estimation.html"><a href="2-parameter-estimation.html#Exercises_Estimation"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-inference.html"><a href="3-inference.html"><i class="fa fa-check"></i><b>3</b> Inference</a>
<ul>
<li class="chapter" data-level="" data-path="3-inference.html"><a href="3-inference.html#Inference_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="3.1" data-path="3-inference.html"><a href="3-inference.html#Inference_Introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3-inference.html"><a href="3-inference.html#confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>3.2</b> Confidence Intervals and Hypothesis Tests</a></li>
<li class="chapter" data-level="3.3" data-path="3-inference.html"><a href="3-inference.html#f-tests"><i class="fa fa-check"></i><b>3.3</b> F-tests</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3-inference.html"><a href="3-inference.html#theory"><i class="fa fa-check"></i><b>3.3.1</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-inference.html"><a href="3-inference.html#example"><i class="fa fa-check"></i><b>3.4</b> Example</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3-inference.html"><a href="3-inference.html#testing-all-covariates"><i class="fa fa-check"></i><b>3.4.1</b> Testing All Covariates</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-inference.html"><a href="3-inference.html#testing-a-single-covariate"><i class="fa fa-check"></i><b>3.4.2</b> Testing a Single Covariate</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-inference.html"><a href="3-inference.html#testing-a-subset-of-covariates"><i class="fa fa-check"></i><b>3.4.3</b> Testing a Subset of Covariates</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-inference.html"><a href="3-inference.html#Inference_Exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-contrasts.html"><a href="4-contrasts.html"><i class="fa fa-check"></i><b>4</b> Contrasts</a>
<ul>
<li class="chapter" data-level="" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_LearningOutcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_Introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#estimate-and-variance"><i class="fa fa-check"></i><b>4.2</b> Estimate and variance</a></li>
<li class="chapter" data-level="4.3" data-path="4-contrasts.html"><a href="4-contrasts.html#estimating-contrasts-using-glht"><i class="fa fa-check"></i><b>4.3</b> Estimating contrasts using <code>glht()</code></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_glht_OneWayAnova"><i class="fa fa-check"></i><b>4.3.1</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_emmeans"><i class="fa fa-check"></i><b>4.4</b> Using <code>emmeans</code> Package</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_SimpleRegression"><i class="fa fa-check"></i><b>4.4.1</b> Simple Regression</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-contrasts.html"><a href="4-contrasts.html#Contrasts_OneWayAnova"><i class="fa fa-check"></i><b>4.4.2</b> 1-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-contrasts.html"><a href="4-contrasts.html#Exercises_Contrasts"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>Statistical Models</b></span></li>
<li class="chapter" data-level="5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html"><i class="fa fa-check"></i><b>5</b> Analysis of Covariance (ANCOVA)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Additive"><i class="fa fa-check"></i><b>5.2</b> Offset parallel Lines (aka additive models)</a></li>
<li class="chapter" data-level="5.3" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Interaction"><i class="fa fa-check"></i><b>5.3</b> Lines with different slopes (aka Interaction model)</a></li>
<li class="chapter" data-level="5.4" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Iris_Example"><i class="fa fa-check"></i><b>5.4</b> Iris Example</a></li>
<li class="chapter" data-level="5.5" data-path="5-ANCOVA-Chapter.html"><a href="5-ANCOVA-Chapter.html#ANCOVA_Exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html"><i class="fa fa-check"></i><b>6</b> Two-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#review-of-1-way-anova"><i class="fa fa-check"></i><b>6.1</b> Review of 1-way ANOVA</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#an-example"><i class="fa fa-check"></i><b>6.1.1</b> An Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>6.1.2</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#pairwise-comparisons"><i class="fa fa-check"></i><b>6.1.3</b> Pairwise Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#two-way-anova-1"><i class="fa fa-check"></i><b>6.2</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#orthogonality"><i class="fa fa-check"></i><b>6.3</b> Orthogonality</a></li>
<li class="chapter" data-level="6.4" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#main-effects-model"><i class="fa fa-check"></i><b>6.4</b> Main Effects Model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees"><i class="fa fa-check"></i><b>6.4.1</b> Example - Fruit Trees</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table"><i class="fa fa-check"></i><b>6.4.2</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.4.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#estimating-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> Estimating Contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#interaction-model"><i class="fa fa-check"></i><b>6.5</b> Interaction Model</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#anova-table-1"><i class="fa fa-check"></i><b>6.5.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="6.5.2" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---fruit-trees-continued"><i class="fa fa-check"></i><b>6.5.2</b> Example - Fruit Trees (continued)</a></li>
<li class="chapter" data-level="6.5.3" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#example---warpbreaks"><i class="fa fa-check"></i><b>6.5.3</b> Example - Warpbreaks</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-two-way-anova.html"><a href="6-two-way-anova.html#Exercises_TwoWayANOVA"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html"><i class="fa fa-check"></i><b>7</b> Diagnostics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#detecting-assumption-violations"><i class="fa fa-check"></i><b>7.1</b> Detecting Assumption Violations</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#measures-of-influence"><i class="fa fa-check"></i><b>7.1.1</b> Measures of Influence</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.1.2</b> Diagnostic Plots</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-Diagnostics-Chapter.html"><a href="7-Diagnostics-Chapter.html#Exercises_Diagnostics"><i class="fa fa-check"></i><b>7.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html"><i class="fa fa-check"></i><b>8</b> Data Transformations</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#a-review-of-logx-and-ex"><i class="fa fa-check"></i><b>8.1</b> A review of <span class="math inline">\(\log(x)\)</span> and <span class="math inline">\(e^x\)</span></a></li>
<li class="chapter" data-level="8.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-response"><i class="fa fa-check"></i><b>8.2</b> Transforming the Response</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#box-cox-family-of-transformations"><i class="fa fa-check"></i><b>8.2.1</b> Box-Cox Family of Transformations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#transforming-the-predictors"><i class="fa fa-check"></i><b>8.3</b> Transforming the predictors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#polynomials-of-a-predictor"><i class="fa fa-check"></i><b>8.3.1</b> Polynomials of a predictor</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-and-square-root-of-a-predictor"><i class="fa fa-check"></i><b>8.3.2</b> Log and Square Root of a predictor</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#galapagos-example"><i class="fa fa-check"></i><b>8.3.3</b> Galapagos Example</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#interpretation-of-log_10-and-log-transformed-variables"><i class="fa fa-check"></i><b>8.4</b> Interpretation of <span class="math inline">\(\log_{10}\)</span> and <span class="math inline">\(\log\)</span> transformed variables</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-un-transformed-covariates"><i class="fa fa-check"></i><b>8.4.1</b> Log-transformed response, un-transformed covariates</a></li>
<li class="chapter" data-level="8.4.2" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#un-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.2</b> Un-transformed response, log-transformed covariate</a></li>
<li class="chapter" data-level="8.4.3" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#log-transformed-response-log-transformed-covariate"><i class="fa fa-check"></i><b>8.4.3</b> Log-transformed response, log-transformed covariate</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8-LogTransformations-Chapter.html"><a href="8-LogTransformations-Chapter.html#Transformation-Exercises"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-MultipleRegression-Chapter.html"><a href="9-MultipleRegression-Chapter.html"><i class="fa fa-check"></i><b>9</b> Multiple Regression</a></li>
<li class="chapter" data-level="10" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html"><i class="fa fa-check"></i><b>10</b> Correlated Covariates</a>
<ul>
<li class="chapter" data-level="10.1" data-path="10-CorrelatedCovariates-Chapter.html"><a href="10-CorrelatedCovariates-Chapter.html#interpretation-with-correlated-covariates"><i class="fa fa-check"></i><b>10.1</b> Interpretation with Correlated Covariates</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html"><i class="fa fa-check"></i><b>11</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="11.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#nested-models"><i class="fa fa-check"></i><b>11.1</b> Nested Models</a></li>
<li class="chapter" data-level="11.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#testing-based-model-selection"><i class="fa fa-check"></i><b>11.2</b> Testing-Based Model Selection</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example---u.s.-life-expectancy"><i class="fa fa-check"></i><b>11.2.1</b> Example - U.S. Life Expectancy</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#criterion-based-procedures"><i class="fa fa-check"></i><b>11.3</b> Criterion Based Procedures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#information-criterions"><i class="fa fa-check"></i><b>11.3.1</b> Information Criterions</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#adjusted-r-sq"><i class="fa fa-check"></i><b>11.3.2</b> Adjusted <code>R-sq</code></a></li>
<li class="chapter" data-level="11.3.3" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#example-1"><i class="fa fa-check"></i><b>11.3.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-VariableSelection-Chapter.html"><a href="11-VariableSelection-Chapter.html#Exercises_VariableSelection"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-too-many-predictors-toomanypredictors-chapter.html"><a href="12-too-many-predictors-toomanypredictors-chapter.html"><i class="fa fa-check"></i><b>12</b> Too many Predictors {#TooManyPredictors_Chapter</a></li>
<li class="chapter" data-level="13" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html"><i class="fa fa-check"></i><b>13</b> Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#block-designs"><i class="fa fa-check"></i><b>13.1</b> Block Designs</a></li>
<li class="chapter" data-level="13.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#randomized-complete-block-design-rcbd"><i class="fa fa-check"></i><b>13.2</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="13.3" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#review-of-maximum-likelihood-methods"><i class="fa fa-check"></i><b>13.3</b> Review of Maximum Likelihood Methods</a></li>
<li class="chapter" data-level="13.4" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#way-anova-with-a-random-effect"><i class="fa fa-check"></i><b>13.4</b> 1-way ANOVA with a random effect</a></li>
<li class="chapter" data-level="13.5" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#blocks-as-random-variables"><i class="fa fa-check"></i><b>13.5</b> Blocks as Random Variables</a></li>
<li class="chapter" data-level="13.6" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#nested-effects"><i class="fa fa-check"></i><b>13.6</b> Nested Effects</a></li>
<li class="chapter" data-level="13.7" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#crossed-effects"><i class="fa fa-check"></i><b>13.7</b> Crossed Effects</a></li>
<li class="chapter" data-level="13.8" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#repeated-measures-longitudinal-studies"><i class="fa fa-check"></i><b>13.8</b> Repeated Measures / Longitudinal Studies</a></li>
<li class="chapter" data-level="13.9" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-and-prediction-intervals"><i class="fa fa-check"></i><b>13.9</b> Confidence and Prediction Intervals</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#confidence-intervals"><i class="fa fa-check"></i><b>13.9.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="13.9.2" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#prediction-intervals"><i class="fa fa-check"></i><b>13.9.2</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="13-mixed-effects-models.html"><a href="13-mixed-effects-models.html#Exercises_RandomEffects"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html"><i class="fa fa-check"></i><b>14</b> Binomial Regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#binomial-regression-model"><i class="fa fa-check"></i><b>14.1</b> Binomial Regression Model</a></li>
<li class="chapter" data-level="14.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#measures-of-fit-quality"><i class="fa fa-check"></i><b>14.2</b> Measures of Fit Quality</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#deviance"><i class="fa fa-check"></i><b>14.2.1</b> Deviance</a></li>
<li class="chapter" data-level="14.2.2" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>14.2.2</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#confidence-intervals-1"><i class="fa fa-check"></i><b>14.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="14.4" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#interpreting-model-coefficients"><i class="fa fa-check"></i><b>14.4</b> Interpreting model coefficients</a></li>
<li class="chapter" data-level="14.5" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#prediction-and-effective-dose-levels"><i class="fa fa-check"></i><b>14.5</b> Prediction and Effective Dose Levels</a></li>
<li class="chapter" data-level="14.6" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#overdispersion"><i class="fa fa-check"></i><b>14.6</b> Overdispersion</a></li>
<li class="chapter" data-level="14.7" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#roc-curves"><i class="fa fa-check"></i><b>14.7</b> ROC Curves</a></li>
<li class="chapter" data-level="14.8" data-path="14-binomial-regression.html"><a href="14-binomial-regression.html#Exercises_BinomialRegression"><i class="fa fa-check"></i><b>14.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-poisson-regression.html"><a href="15-poisson-regression.html"><i class="fa fa-check"></i><b>15</b> Poisson Regression</a></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="16" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html"><i class="fa fa-check"></i><b>16</b> Block Designs</a>
<ul>
<li class="chapter" data-level="16.1" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#randomized-complete-block-design-rcbd-1"><i class="fa fa-check"></i><b>16.1</b> Randomized Complete Block Design (RCBD)</a></li>
<li class="chapter" data-level="16.2" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#split-plot-designs"><i class="fa fa-check"></i><b>16.2</b> Split-plot designs</a></li>
<li class="chapter" data-level="16.3" data-path="16-block-designs-1.html"><a href="16-block-designs-1.html#exercises"><i class="fa fa-check"></i><b>16.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html"><i class="fa fa-check"></i><b>17</b> Maximum Likelihood Priciple</a>
<ul>
<li class="chapter" data-level="" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#learning-outcomes-1"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="17.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#introduction-1"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#distributions"><i class="fa fa-check"></i><b>17.2</b> Distributions</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson"><i class="fa fa-check"></i><b>17.2.1</b> Poisson</a></li>
<li class="chapter" data-level="17.2.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential"><i class="fa fa-check"></i><b>17.2.2</b> Exponential</a></li>
<li class="chapter" data-level="17.2.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal"><i class="fa fa-check"></i><b>17.2.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#likelihood-function"><i class="fa fa-check"></i><b>17.3</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#poisson-1"><i class="fa fa-check"></i><b>17.3.1</b> Poisson</a></li>
<li class="chapter" data-level="17.3.2" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exponential-example"><i class="fa fa-check"></i><b>17.3.2</b> Exponential Example</a></li>
<li class="chapter" data-level="17.3.3" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#normal-1"><i class="fa fa-check"></i><b>17.3.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#discussion"><i class="fa fa-check"></i><b>17.4</b> Discussion</a></li>
<li class="chapter" data-level="17.5" data-path="17-maximum-likelihood-priciple.html"><a href="17-maximum-likelihood-priciple.html#exercises-1"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="project-appendix.html"><a href="project-appendix.html"><i class="fa fa-check"></i>Project Appendix</a>
<ul>
<li class="chapter" data-level="17.6" data-path="project-appendix.html"><a href="project-appendix.html#weeks-1-4-project-feasibility"><i class="fa fa-check"></i><b>17.6</b> Weeks 1 – 4 (Project Feasibility)</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="project-appendix.html"><a href="project-appendix.html#wibgis"><i class="fa fa-check"></i><b>17.6.1</b> WIBGIs</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Methods II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="LogTransformations-Chapter" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Data Transformations</h1>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="8-LogTransformations-Chapter.html#cb204-1" aria-hidden="true"></a><span class="kw">library</span>(ggfortify)   <span class="co"># for autoplot for lm objects</span></span>
<span id="cb204-2"><a href="8-LogTransformations-Chapter.html#cb204-2" aria-hidden="true"></a><span class="kw">library</span>(emmeans)     <span class="co"># emmeans for pairwise constrasts.</span></span>
<span id="cb204-3"><a href="8-LogTransformations-Chapter.html#cb204-3" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)   <span class="co"># for dplyr, tidyr, ggplot2</span></span></code></pre></div>
<p>Transformations of the response variable and/or the predictor variables can drastically improve the model fit and can correct violations of the model assumptions. We might also create new predictor variables that are functions of existing variables. These include quadratic and higher order polynomial terms and interaction terms.</p>
<p>Often we are presented with data and we would like to fit a linear model to the data. Unfortunately the data might not satisfy all of the assumptions of a linear model. For the simple linear model
<span class="math display">\[y_i=\beta_{0}+\beta_{1}x_i+\epsilon_i\]</span>
where <span class="math inline">\(\epsilon_i \stackrel{iid}{\sim} N\left(0,\sigma^{2}\right)\)</span>, the necessary assumptions are:</p>
<ol style="list-style-type: decimal">
<li>Independent errors</li>
<li>Errors have constant variance, no matter what the x-value (or equivalently the fitted value)</li>
<li>Errors are normally distributed</li>
<li>The model contains all the appropriate covariates and no more.</li>
</ol>
<p>In general, a transformation of the response variable can be used to address the 2nd and 3rd assumptions, and adding new covariates to the model will be how to address deficiencies of assumption 4. Because of the interpretability properties we will develop here, <span class="math inline">\(\log()\)</span> transformations are very popular, if they are useful.</p>
<div id="a-review-of-logx-and-ex" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> A review of <span class="math inline">\(\log(x)\)</span> and <span class="math inline">\(e^x\)</span></h2>
<p>One of the most common transformations that is used on either the response <span class="math inline">\(y\)</span> or the covariates <span class="math inline">\(x\)</span> is the <span class="math inline">\(\log()\)</span> function. In this next section we will consider <span class="math inline">\(\log()\)</span> with base <span class="math inline">\(e\)</span>. However, if you prefer <span class="math inline">\(\log_2()\)</span> or <span class="math inline">\(\log_{10}\)</span> you may substitute <span class="math inline">\(e\)</span> with <span class="math inline">\(2\)</span> or <span class="math inline">\(10\)</span> everywhere.</p>
<p>In primary school you might have learned that the <span class="math inline">\(\log()\)</span> function looks like this:
<img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-128-1.png" width="672" /></p>
<p>Critical aspects to notice about <span class="math inline">\(\log(x)\)</span>:</p>
<ol style="list-style-type: decimal">
<li>As <span class="math inline">\(x \to 0\)</span>, <span class="math inline">\(\log(x) \to -\infty\)</span>.</li>
<li>At <span class="math inline">\(x=1\)</span> we have <span class="math inline">\(log(x=1) = 0\)</span>.</li>
<li>As <span class="math inline">\(x \to \infty\)</span>, <span class="math inline">\(\log(x) \to \infty\)</span> as well, but at a <em>much</em> slower rate.</li>
<li>Even though <span class="math inline">\(log(x)\)</span> is only defined for <span class="math inline">\(x&gt;0\)</span>, the result can take on any real value, positive or negative.</li>
</ol>
<p>The inverse function of <span class="math inline">\(\log(x)\)</span> is <span class="math inline">\(e^x = \exp(x)\)</span>, where <span class="math inline">\(e=2.71828\dots\)</span> which looks like this:
<img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-129-1.png" width="672" /></p>
<p>Critical aspects to notice about <span class="math inline">\(e^x\)</span>:</p>
<ol style="list-style-type: decimal">
<li>as <span class="math inline">\(x \to -\infty\)</span>, <span class="math inline">\(e^x \to 0\)</span>.</li>
<li>At <span class="math inline">\(x =0\)</span> we have <span class="math inline">\(e^0 = 1\)</span>.</li>
<li>as <span class="math inline">\(x \to \infty\)</span>, <span class="math inline">\(e^x \to \infty\)</span> as well, but at a <em>much</em> faster rate.</li>
<li>The function <span class="math inline">\(e^x\)</span> can be evaluated for any real number, but the result is always <span class="math inline">\(&gt;0\)</span>.</li>
</ol>
<p>Finally we have that <span class="math inline">\(e^x\)</span> and <span class="math inline">\(log(x)\)</span> are inverse functions of each other by the following identity:
<span class="math display">\[x = \log\left( e^x \right )\]</span> and
<span class="math display">\[x = e^{\log(x)} \;\;\; \textrm{ if } x &gt;0\]</span></p>
<p>Also it is important to note that the <span class="math inline">\(\log\)</span> function has some interesting properties in that it makes operations “1-operation easier”.
<span class="math display">\[\begin{aligned} 
\log\left(a^{b}\right)        &amp;=    b\log a  \\
\log\left(\frac{a}{b}\right)    &amp;=  \log a-\log b \\
\log\left(ab\right)           &amp;=    \log a+\log b
\end{aligned}\]</span></p>
<p>One final aspect of exponents that we will utilize is that
<span class="math display">\[ e^{a+b} = e^a e^b\]</span></p>
<p>The reason we like using a <span class="math inline">\(\log()\)</span> transformation is that it acts differently on large values than small. In particular for <span class="math inline">\(x &gt;1\)</span> we have that <span class="math inline">\(\log(x)\)</span> makes all of the smaller, but the transformation on big values of <span class="math inline">\(x\)</span> is more extreme. Consider the following, where most of the x-values are small, but we have a few that are quite large. Those large values will have extremely high leverage and we’d like to reduce that.</p>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-130-1.png" width="672" /></p>
</div>
<div id="transforming-the-response" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Transforming the Response</h2>
<p>When the normality or constant variance assumption is violated, sometimes it is possible to transform the response to satisfy the assumption. Often times count data is analyzed as <code>log(count)</code> and weights are analyzed after taking a square root or cube root transform. Statistics involving income or other monetary values are usually analyzed on the log scale so as to reduce the leverage of high income observations.</p>
<p>While we may want to transform the response in order to satisfy the statistical assumptions, it is often necessary to back-transform to the original scale. For example if we fit a linear model for income (<span class="math inline">\(y\)</span>) based on the amount of schooling the individual has received (<span class="math inline">\(x\)</span>)
<span class="math display">\[\log y=\beta_{0}+\beta_{1}x+\epsilon\]</span>
then we might want to give a prediction interval for an <span class="math inline">\(x_{0}\)</span> value. The predicted <span class="math inline">\(log(income)\)</span> value is
<span class="math display">\[\log\left(\hat{y}_{0}\right)=\hat{\beta}_{0}+\hat{\beta}_{x}x_{0}\]</span>
and we could calculate the appropriate predicted income as <span class="math inline">\(\hat{y}_{0}=e^{log\left(\hat{y}_{0}\right)}\)</span>. Likewise if we had a confidence interval or prediction interval for <span class="math inline">\(\log\left(\hat{y}_{0}\right)\)</span> of the form <span class="math inline">\(\left(l,u\right)\)</span> then the appropriate interval for <span class="math inline">\(\hat{y}_{0}\)</span> is <span class="math inline">\(\left(e^{l},e^{u}\right)\)</span>. Notice that while <span class="math inline">\(\left(l,u\right)\)</span> might be symmetric about <span class="math inline">\(\log\left(\hat{y}_{0}\right)\)</span>, the back-transformed interval is not symmetric about <span class="math inline">\(\hat{y}_{0}\)</span>.</p>
<p>Unfortunately the interpretation of the regression coefficients <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> on the un-transformed scale becomes more complicated. This is a very serious difficulty and might sway a researcher from transforming their data.</p>
<div id="box-cox-family-of-transformations" class="section level3" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Box-Cox Family of Transformations</h3>
<p>The Box-Cox method is a popular way of determining what transformation to make. It is intended for responses that are strictly positive (because <span class="math inline">\(\log0=-\infty\)</span> and the square root of a number gives complex numbers, which we don’t know how to address in regression). The transformation is defined as <span class="math display">\[g\left(y\right)=\begin{cases}
\frac{y^{\lambda}-1}{\lambda} &amp; \lambda\ne0\\
\log y &amp; \lambda=0
\end{cases}\]</span>
This transformation is a smooth family of transformations because <span class="math display">\[\lim_{\lambda\to0}\frac{y^{\lambda}-1}{\lambda}=\log y\]</span>
In the case that <span class="math inline">\(\lambda\ne 0\)</span>, then a researcher will usually use the simpler transformation <span class="math inline">\(y^{\lambda}\)</span> because the subtraction and division does not change anything in a non-linear fashion. Thus for purposes of addressing the assumption violations, all we care about is the <span class="math inline">\(y^{\lambda}\)</span> and prefer the simpler (i.e. more interpretable) transformation.</p>
<p>Finding the best transformation can be done by adding the <span class="math inline">\(\lambda\)</span> parameter to the model and finding the value that maximizes the log-likelihood function. Fortunately, we don’t have to do this by hand, as the function <code>boxcox()</code> in the <code>MASS</code> library will do all the heavy calculation for us.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="8-LogTransformations-Chapter.html#cb205-1" aria-hidden="true"></a><span class="kw">data</span>(gala, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)</span>
<span id="cb205-2"><a href="8-LogTransformations-Chapter.html#cb205-2" aria-hidden="true"></a>g &lt;-<span class="st"> </span><span class="kw">lm</span>(Species <span class="op">~</span><span class="st"> </span>Area <span class="op">+</span><span class="st"> </span>Elevation <span class="op">+</span><span class="st"> </span>Nearest <span class="op">+</span><span class="st"> </span>Scruz <span class="op">+</span><span class="st"> </span>Adjacent, <span class="dt">data=</span>gala)</span>
<span id="cb205-3"><a href="8-LogTransformations-Chapter.html#cb205-3" aria-hidden="true"></a></span>
<span id="cb205-4"><a href="8-LogTransformations-Chapter.html#cb205-4" aria-hidden="true"></a><span class="co"># I don&#39;t like loading the MASS package because it includes a select() function</span></span>
<span id="cb205-5"><a href="8-LogTransformations-Chapter.html#cb205-5" aria-hidden="true"></a><span class="co"># that fights with dplyr::select(), so whenever I use a function in the MASS</span></span>
<span id="cb205-6"><a href="8-LogTransformations-Chapter.html#cb205-6" aria-hidden="true"></a><span class="co"># package, I just call it using the package::function() naming.</span></span>
<span id="cb205-7"><a href="8-LogTransformations-Chapter.html#cb205-7" aria-hidden="true"></a><span class="co"># </span></span>
<span id="cb205-8"><a href="8-LogTransformations-Chapter.html#cb205-8" aria-hidden="true"></a><span class="co"># #MASS::boxcox(g, lambda=seq(-2,2, by=.1))  # Set lambda range manually...</span></span>
<span id="cb205-9"><a href="8-LogTransformations-Chapter.html#cb205-9" aria-hidden="true"></a>MASS<span class="op">::</span><span class="kw">boxcox</span>( g )   <span class="co"># With default lambda range.</span></span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-131-1.png" width="672" /></p>
<p>The optimal transformation for these data would be <span class="math inline">\(y^{1/4}=\sqrt[4]{y}\)</span> but that is an extremely uncommon transformation. Instead we should pick the nearest “standard” transformation which would suggest that we should use either the <span class="math inline">\(\log y\)</span> or <span class="math inline">\(\sqrt{y}\)</span> transformation.</p>
<p>Thoughts on the Box-Cox transformation:</p>
<ol style="list-style-type: decimal">
<li>In general, I prefer to using a larger-than-optimal model when picking a transformation and then go about the model building process. After a suitable model has been chosen, I’ll double check the my transformation was appropriate given the model that I ended up with.</li>
<li>Outliers can have a profound effect on this method. If the “optimal” transformation is extreme (<span class="math inline">\(\lambda=5\)</span> or something silly) then you might have to remove the outliers and refit the transformation.</li>
<li>If the range of the response <span class="math inline">\(y\)</span> is small, then the method is not as sensitive.</li>
<li>These are not the only possible transformations. For example, for binary data, the <code>logit</code> and <code>probit</code> transformations are common. In classical non-parametric statistics, we take a rank transformation to the y-values.</li>
</ol>
</div>
</div>
<div id="transforming-the-predictors" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Transforming the predictors</h2>
<div id="polynomials-of-a-predictor" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Polynomials of a predictor</h3>
<p>Perhaps the most common transformation to make is to make a quadratic function in <span class="math inline">\(x\)</span>. Often the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> follows a curve and we want to fit a quadratic model
<span class="math display">\[\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x+\hat{\beta}_{2}x^{2}\]</span>
and we should note that this is still a linear model because <span class="math inline">\(\hat{y}\)</span> is a linear function of <span class="math inline">\(x\)</span> and <span class="math inline">\(x^{2}\)</span>. As we have already seen, it is easy to fit the model. Adding the column of <span class="math inline">\(x^{2}\)</span> values to the design matrix does the trick.</p>
<p>The difficult part comes in the interpretation of the parameter values. No longer is <span class="math inline">\(\hat{\beta}_{1}\)</span> the increase in <span class="math inline">\(y\)</span> for every one unit increase in <span class="math inline">\(x\)</span>. Instead the three parameters in my model interact in a complicated fashion. For example, the peak of the parabola is at <span class="math inline">\(-\hat{\beta}_{1}/2\hat{\beta}_{2}\)</span> and whether the parabola is cup shaped vs dome shaped and its steepness is controlled by <span class="math inline">\(\hat{\beta}_{2}\)</span>. Because my geometric understanding of degree <span class="math inline">\(q\)</span> polynomials relies on have all factors of degree <span class="math inline">\(q\)</span> or lower, whenever I include a covariate raised to a power, I should include all the lower powers as well.</p>
</div>
<div id="log-and-square-root-of-a-predictor" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Log and Square Root of a predictor</h3>
<p>Often the effect of a covariate is not linearly related to response, but rather some function of the covariate. For example the area of a circle is not linearly related to its radius, but it is linearly related to the radius squared.
<span class="math display">\[Area=\pi r^{2}\]</span>
Similar situations might arise in biological settings, such as the volume of conducting tissue being related to the square of the diameter. Or perhaps an animals metabolic requirements are related to some power of body length. In sociology, it is often seen that the utility of, say, $1000 drops off in a logarithmic fashion according to the person’s income. To a graduate student, $1K is a big deal, but to a corporate CEO, $1K is just another weekend at the track. Making a log transformation on any monetary covariate, might account for the non-linear nature of “utility”.</p>
<p>Picking a good transformation for a covariate is quite difficult, but most fields of study have spent plenty of time thinking about these issues. When in doubt, look at scatter plots of the covariate vs the response and ask what transformation would make the data fall onto a line?</p>
</div>
<div id="galapagos-example" class="section level3" number="8.3.3">
<h3><span class="header-section-number">8.3.3</span> Galapagos Example</h3>
<p>To illustrate how to add a transformation of a predictor to a linear model in R, we will consider the Galapagos data in <code>faraway</code>.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="8-LogTransformations-Chapter.html#cb206-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&#39;gala&#39;</span>, <span class="dt">package=</span><span class="st">&#39;faraway&#39;</span>)</span>
<span id="cb206-2"><a href="8-LogTransformations-Chapter.html#cb206-2" aria-hidden="true"></a><span class="co"># look at all the scatterplots</span></span>
<span id="cb206-3"><a href="8-LogTransformations-Chapter.html#cb206-3" aria-hidden="true"></a>gala <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb206-4"><a href="8-LogTransformations-Chapter.html#cb206-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">LogSpecies =</span> <span class="kw">log</span>(Species)) <span class="op">%&gt;%</span></span>
<span id="cb206-5"><a href="8-LogTransformations-Chapter.html#cb206-5" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(LogSpecies, Area, Elevation, Nearest, Scruz, Adjacent) <span class="op">%&gt;%</span></span>
<span id="cb206-6"><a href="8-LogTransformations-Chapter.html#cb206-6" aria-hidden="true"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>(<span class="dt">upper=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;points&#39;</span>), <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;cor&#39;</span>))</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-132-1.png" width="672" /></p>
<p>Looking at these graphs, I think I should definitely transform <code>Area</code> and <code>Adjacent</code>, and I wouldn’t object to doing the same to <code>Elevation</code>, <code>Nearest</code> and <code>Scruz</code>. Given the high leverages, a log transformation should be a good idea. One problem is that <span class="math inline">\(\log(0) = -\infty\)</span>. A quick look at the data set summary:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="8-LogTransformations-Chapter.html#cb207-1" aria-hidden="true"></a>gala <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb207-2"><a href="8-LogTransformations-Chapter.html#cb207-2" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(Species, Area, Elevation, Nearest,Scruz, Adjacent) <span class="op">%&gt;%</span></span>
<span id="cb207-3"><a href="8-LogTransformations-Chapter.html#cb207-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>##     Species            Area            Elevation          Nearest     
##  Min.   :  2.00   Min.   :   0.010   Min.   :  25.00   Min.   : 0.20  
##  1st Qu.: 13.00   1st Qu.:   0.258   1st Qu.:  97.75   1st Qu.: 0.80  
##  Median : 42.00   Median :   2.590   Median : 192.00   Median : 3.05  
##  Mean   : 85.23   Mean   : 261.709   Mean   : 368.03   Mean   :10.06  
##  3rd Qu.: 96.00   3rd Qu.:  59.237   3rd Qu.: 435.25   3rd Qu.:10.03  
##  Max.   :444.00   Max.   :4669.320   Max.   :1707.00   Max.   :47.40  
##      Scruz           Adjacent      
##  Min.   :  0.00   Min.   :   0.03  
##  1st Qu.: 11.03   1st Qu.:   0.52  
##  Median : 46.65   Median :   2.59  
##  Mean   : 56.98   Mean   : 261.10  
##  3rd Qu.: 81.08   3rd Qu.:  59.24  
##  Max.   :290.20   Max.   :4669.32</code></pre>
<p>reveals that <code>Scruz</code> has a zero value, and so a log transformation will result in a <span class="math inline">\(-\infty\)</span>. So, lets take the square root of <code>Scruz</code></p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="8-LogTransformations-Chapter.html#cb209-1" aria-hidden="true"></a>gala <span class="op">%&gt;%</span></span>
<span id="cb209-2"><a href="8-LogTransformations-Chapter.html#cb209-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">LogSpecies =</span> <span class="kw">log</span>(Species), <span class="dt">LogElevation=</span><span class="kw">log</span>(Elevation), <span class="dt">LogArea=</span><span class="kw">log</span>(Area), <span class="dt">LogNearest=</span><span class="kw">log</span>(Nearest),</span>
<span id="cb209-3"><a href="8-LogTransformations-Chapter.html#cb209-3" aria-hidden="true"></a>         <span class="dt">SqrtScruz=</span><span class="kw">sqrt</span>(Scruz), <span class="dt">LogAdjacent=</span><span class="kw">log</span>(Adjacent)) <span class="op">%&gt;%</span></span>
<span id="cb209-4"><a href="8-LogTransformations-Chapter.html#cb209-4" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(LogSpecies, LogElevation, LogArea, LogNearest, SqrtScruz, LogAdjacent) <span class="op">%&gt;%</span></span>
<span id="cb209-5"><a href="8-LogTransformations-Chapter.html#cb209-5" aria-hidden="true"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>(<span class="dt">upper=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;points&#39;</span>), <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;cor&#39;</span>))</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-134-1.png" width="672" /></p>
<p>Looking at these graphs, it is clear that <code>log(Elevation)</code> and <code>log(Area)</code> are highly correlated and we should probably have one or the other, but not both in the model.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="8-LogTransformations-Chapter.html#cb210-1" aria-hidden="true"></a>m.c &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Species) <span class="op">~</span><span class="st">  </span><span class="kw">log</span>(Area) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(Nearest) <span class="op">+</span><span class="st"> </span><span class="kw">sqrt</span>(Scruz) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(Adjacent), <span class="dt">data=</span>gala)</span>
<span id="cb210-2"><a href="8-LogTransformations-Chapter.html#cb210-2" aria-hidden="true"></a><span class="kw">summary</span>(m.c)<span class="op">$</span>coefficients <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits=</span><span class="dv">3</span>) <span class="co"># more readable...</span></span></code></pre></div>
<pre><code>##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      3.285      0.275  11.960    0.000
## log(Area)        0.402      0.043   9.443    0.000
## log(Nearest)    -0.041      0.118  -0.351    0.728
## sqrt(Scruz)     -0.049      0.045  -1.085    0.288
## log(Adjacent)   -0.024      0.046  -0.529    0.602</code></pre>
<p>We will remove all the parameters that appear to be superfluous, and perform an F-test to confirm that the simple model is sufficient.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="8-LogTransformations-Chapter.html#cb212-1" aria-hidden="true"></a>m.s &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Species) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(Area), <span class="dt">data=</span>gala)</span>
<span id="cb212-2"><a href="8-LogTransformations-Chapter.html#cb212-2" aria-hidden="true"></a><span class="kw">anova</span>(m.s, m.c)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: log(Species) ~ log(Area)
## Model 2: log(Species) ~ log(Area) + log(Nearest) + sqrt(Scruz) + log(Adjacent)
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     28 17.218                           
## 2     25 15.299  3    1.9196 1.0456 0.3897</code></pre>
<p>Next we will look at the coefficients.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="8-LogTransformations-Chapter.html#cb214-1" aria-hidden="true"></a><span class="kw">summary</span>(m.s)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(Species) ~ log(Area), data = gala)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5442 -0.4001  0.0941  0.5449  1.3752 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.9037     0.1571  18.484  &lt; 2e-16 ***
## log(Area)     0.3886     0.0416   9.342 4.23e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7842 on 28 degrees of freedom
## Multiple R-squared:  0.7571, Adjusted R-squared:  0.7484 
## F-statistic: 87.27 on 1 and 28 DF,  p-value: 4.23e-10</code></pre>
<p>The slope coefficient (0.3886) is the increase in log(Species) for every 1 unit increase in log(Area). Unfortunately that is not particularly convenient to interpretation and we will address this in the next section of this chapter.</p>
<p>Finally, we might be interested in creating a confidence interval for the expected number of tortoise species for an island with <code>Area=50</code>.</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="8-LogTransformations-Chapter.html#cb216-1" aria-hidden="true"></a>x0 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Area=</span><span class="dv">50</span>)</span>
<span id="cb216-2"><a href="8-LogTransformations-Chapter.html#cb216-2" aria-hidden="true"></a>log.Species.CI &lt;-<span class="st"> </span><span class="kw">predict</span>(m.s, <span class="dt">newdata=</span>x0, <span class="dt">interval=</span><span class="st">&#39;confidence&#39;</span>)</span>
<span id="cb216-3"><a href="8-LogTransformations-Chapter.html#cb216-3" aria-hidden="true"></a>log.Species.CI       <span class="co"># Log(Species) scale</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 4.423903 4.068412 4.779394</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="8-LogTransformations-Chapter.html#cb218-1" aria-hidden="true"></a><span class="kw">exp</span>(log.Species.CI)  <span class="co"># Species scale</span></span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 83.42122 58.46403 119.0322</code></pre>
<p>Notice that on the species-scale, we see that the fitted value is not in the center of the confidence interval.</p>
<p>To help us understand what the log transformations are doing, we can produce a plot with the island Area on the x-axis and the expected number of Species on the y-axis and hopefully that will help us understand the relationship between the two.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="8-LogTransformations-Chapter.html#cb220-1" aria-hidden="true"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb220-2"><a href="8-LogTransformations-Chapter.html#cb220-2" aria-hidden="true"></a>pred.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Area=</span><span class="dv">1</span><span class="op">:</span><span class="dv">50</span>)</span>
<span id="cb220-3"><a href="8-LogTransformations-Chapter.html#cb220-3" aria-hidden="true"></a>pred.data &lt;-<span class="st"> </span>pred.data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb220-4"><a href="8-LogTransformations-Chapter.html#cb220-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">cbind</span>( <span class="kw">predict</span>(m.s, <span class="dt">newdata=</span>pred.data, <span class="dt">interval=</span><span class="st">&#39;conf&#39;</span>))</span>
<span id="cb220-5"><a href="8-LogTransformations-Chapter.html#cb220-5" aria-hidden="true"></a><span class="kw">ggplot</span>(pred.data, <span class="kw">aes</span>(<span class="dt">x=</span>Area)) <span class="op">+</span></span>
<span id="cb220-6"><a href="8-LogTransformations-Chapter.html#cb220-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span><span class="kw">exp</span>(fit))) <span class="op">+</span></span>
<span id="cb220-7"><a href="8-LogTransformations-Chapter.html#cb220-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span><span class="kw">exp</span>(lwr), <span class="dt">ymax=</span><span class="kw">exp</span>(upr)), <span class="dt">alpha=</span>.<span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb220-8"><a href="8-LogTransformations-Chapter.html#cb220-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;Number of Species&#39;</span>)</span></code></pre></div>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
</div>
</div>
<div id="interpretation-of-log_10-and-log-transformed-variables" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Interpretation of <span class="math inline">\(\log_{10}\)</span> and <span class="math inline">\(\log\)</span> transformed variables</h2>
<p>One of the most difficult issues surrounding transformed variables is that the interpretation is difficult. Compared to taking the square root, <span class="math inline">\(\log\)</span> transformations are surprisingly interpretable on the original scale. Here we look at the interpretation of log transformed variables.</p>
<p>To investigate the effects of a log transformation, we’ll examine a dataset that predicts the writing scores of <span class="math inline">\(n=200\)</span> students using the gender, reading and math scores. This example was taken from the UCLA Statistical Consulting Group.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="8-LogTransformations-Chapter.html#cb221-1" aria-hidden="true"></a>file &lt;-<span class="st"> &#39;https://stats.idre.ucla.edu/wp-content/uploads/2016/02/lgtrans.csv&#39;</span>  <span class="co"># on the web</span></span>
<span id="cb221-2"><a href="8-LogTransformations-Chapter.html#cb221-2" aria-hidden="true"></a>file &lt;-<span class="st"> &#39;data-raw/lgtrans.csv&#39;</span>                                                <span class="co"># on my laptop</span></span>
<span id="cb221-3"><a href="8-LogTransformations-Chapter.html#cb221-3" aria-hidden="true"></a>scores &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file=</span>file)</span>
<span id="cb221-4"><a href="8-LogTransformations-Chapter.html#cb221-4" aria-hidden="true"></a>scores &lt;-<span class="st"> </span>scores <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(<span class="dt">gender =</span> female)</span>
<span id="cb221-5"><a href="8-LogTransformations-Chapter.html#cb221-5" aria-hidden="true"></a></span>
<span id="cb221-6"><a href="8-LogTransformations-Chapter.html#cb221-6" aria-hidden="true"></a>scores <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb221-7"><a href="8-LogTransformations-Chapter.html#cb221-7" aria-hidden="true"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(write, read, math, gender) <span class="op">%&gt;%</span></span>
<span id="cb221-8"><a href="8-LogTransformations-Chapter.html#cb221-8" aria-hidden="true"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>( <span class="kw">aes</span>(<span class="dt">color=</span>gender),</span>
<span id="cb221-9"><a href="8-LogTransformations-Chapter.html#cb221-9" aria-hidden="true"></a>    <span class="dt">upper=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;points&#39;</span>), <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span><span class="st">&#39;cor&#39;</span>))</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="Statistical-Methods-II_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
<p>These data look pretty decent, and I’m not certain that I would do <em>any</em> transformation, but for the sake of having a concrete example that has both continuous and categorical covariates, we will interpret effects on a students’ writing score.</p>
<div id="log-transformed-response-un-transformed-covariates" class="section level3" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Log-transformed response, un-transformed covariates</h3>
<p>We consider the model where we have transformed the response variable and just an intercept term.
<span class="math display">\[\log y=\beta_{0}+\epsilon\]</span></p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="8-LogTransformations-Chapter.html#cb223-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(write) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>scores)</span>
<span id="cb223-2"><a href="8-LogTransformations-Chapter.html#cb223-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)     3.95    0.0137      288. 7.01e-263</code></pre>
<p>We interpret the intercept as the mean of the log-transformed response values. We could back transform this to the original scale <span class="math inline">\(\hat{y} = e^{\hat{\beta}_{0}} = e^{3.94835} = 51.85\)</span> as a typical value of write. To distinguish this from the usually defined mean of the write values, we will call this as the <em>geometric mean</em>. Instead of calculating this by hand, we can have <code>emmeans()</code> do it for us.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="8-LogTransformations-Chapter.html#cb225-1" aria-hidden="true"></a><span class="kw">emmeans</span>(model, <span class="op">~</span><span class="dv">1</span>)                   <span class="co"># Return y-hat value on the log-scale</span></span></code></pre></div>
<pre><code>##  1       emmean     SE  df lower.CL upper.CL
##  overall   3.95 0.0137 199     3.92     3.98
## 
## Results are given on the log (not the response) scale. 
## Confidence level used: 0.95</code></pre>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="8-LogTransformations-Chapter.html#cb227-1" aria-hidden="true"></a><span class="kw">emmeans</span>(model, <span class="op">~</span><span class="dv">1</span>, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)  <span class="co"># Return y-hat value on the original scale</span></span></code></pre></div>
<pre><code>##  1       response   SE  df lower.CL upper.CL
##  overall     51.8 0.71 199     50.5     53.3
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale</code></pre>
<p>Next we examine how to interpret the model when a categorical variable is added to the model.
<span class="math display">\[\log y=\begin{cases}
\beta_{0}+\epsilon &amp; \;\;\textrm{if female}\\
\beta_{0}+\beta_{1}+\epsilon &amp; \;\;\textrm{if male}
\end{cases}\]</span></p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="8-LogTransformations-Chapter.html#cb229-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(write) <span class="op">~</span><span class="st"> </span>gender, <span class="dt">data=</span>scores)</span>
<span id="cb229-2"><a href="8-LogTransformations-Chapter.html#cb229-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)    4.00     0.0179    223.   1.02e-239
## 2 gendermale    -0.103    0.0266     -3.89 1.39e-  4</code></pre>
<p>The intercept is now the mean of the log-transformed <code>write</code> responses for the females and thus <span class="math inline">\(e^{\hat{\beta}_0} = \hat{y}_{f}\)</span> and the offset for males is the change in <code>log(write)</code> from the female group. Notice that for the males, we have
<span class="math display">\[\begin{aligned}
\log\hat{y}_m   &amp;=  \hat{\beta}_{0}+\hat{\beta}_{1} \\
    \hat{y}_m   &amp;=  e^{\hat{\beta}_{0}+\hat{\beta}_{1}} \\
              &amp;=    \underset{\hat{y}_{f}}{\underbrace{e^{\hat{\beta}_{0}}}}\;\;\;\;\;\underset{\textrm{multiplier for males}}{*\;\;\underbrace{e^{\hat{\beta}_{1}}}} 
\end{aligned}\]</span></p>
<p>and therefore we see that males tend to have writing scores <span class="math inline">\(e^{-0.103}=0.90=90\%\)</span> of the females. Typically this sort of result would be reported as the males have a 10% lower writing score than the females.</p>
<p>Hand calculating these is challenging to do it correctly, but as usual we can have <code>emmeans</code> calculate it for us.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="8-LogTransformations-Chapter.html#cb231-1" aria-hidden="true"></a><span class="co"># I used reverse pairwise to get the ratio as male/female instead of female/male</span></span>
<span id="cb231-2"><a href="8-LogTransformations-Chapter.html#cb231-2" aria-hidden="true"></a><span class="kw">emmeans</span>(model, revpairwise<span class="op">~</span>gender, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb231-3"><a href="8-LogTransformations-Chapter.html#cb231-3" aria-hidden="true"></a><span class="st">  </span>.[[<span class="st">&#39;contrasts&#39;</span>]]</span></code></pre></div>
<pre><code>##  contrast      ratio    SE  df t.ratio p.value
##  male / female 0.902 0.024 198 -3.887  0.0001 
## 
## Tests are performed on the log scale</code></pre>
<p>The model with a continuous covariate has a similar interpretation.
<span class="math display">\[\log y=\begin{cases}
\beta_{0}+\beta_{2}x+\epsilon &amp; \;\;\textrm{if female}\\
\beta_{0}+\beta_{1}+\beta_{2}x+\epsilon &amp; \;\;\textrm{if male}
\end{cases}\]</span></p>
<p>We will use the reading score read to predict the writing score. Then <span class="math inline">\(\hat{\beta}_{2}\)</span> is the predicted increase in <code>log(write)</code> for every 1-unit increase in read score. The interpretation of <span class="math inline">\(\hat{\beta}_{0}\)</span> is now <span class="math inline">\(\log\hat{y}\)</span> when <span class="math inline">\(x=0\)</span> and therefore <span class="math inline">\(\hat{y}=e^{\hat{\beta}_{0}}\)</span> when <span class="math inline">\(x=0\)</span>.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="8-LogTransformations-Chapter.html#cb233-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(write) <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>read, <span class="dt">data=</span>scores)  <span class="co"># main effects model</span></span>
<span id="cb233-2"><a href="8-LogTransformations-Chapter.html#cb233-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   3.41     0.0546      62.5  8.68e-132
## 2 gendermale   -0.116    0.0210      -5.52 1.08e-  7
## 3 read          0.0113   0.00102     11.1  2.02e- 22</code></pre>
<p>For females, we consider the difference in <span class="math inline">\(\log\hat{y}\)</span> for a 1-unit increase in <span class="math inline">\(x\)</span> and will interpret this on the original write scale.
<span class="math display">\[\begin{aligned}
\log\hat{y}_f   &amp;=  \hat{\beta}_{0}+\hat{\beta}_{2}x \\
\hat{y}_f       &amp;=  e^{\hat{\beta}_{0}+\hat{\beta}_{2}x}
\end{aligned}\]</span>
therefore we consider <span class="math inline">\(e^{\hat{\beta}_{2}}\)</span> as the multiplicative increase in write score for a 1-unit increase in <span class="math inline">\(x\)</span> because of the following. Consider <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2 = x_1 +1\)</span>. Then we consider the ratio of predicted values:
<span class="math display">\[
\frac{\hat{y}_2}{\hat{y}_1} 
  = \frac{e^{\hat{\beta}_{0}+\hat{\beta}_{2}\,\left(x+1\right)}}{e^{\hat{\beta}_{0}+\hat{\beta}_{2}\,x}} 
  = \frac{e^{\hat{\beta}_{0}}e^{\hat{\beta}_{2}\,x}e^{\hat{\beta}_{2}}}{e^{\hat{\beta}_{0}}e^{\hat{\beta}_{2}\,x}} 
  = e^{\hat{\beta}_{2}}
\]</span></p>
<p>For our writing scores example we have that <span class="math inline">\(e^{\hat{\beta}_{2}}=e^{0.011}=1.01\)</span>
meaning there is an estimated <span class="math inline">\(1\%\)</span> increase in <code>write</code> score for every 1-point increase in <code>read</code> score.</p>
<p>If we are interested in, say, a 20-unit increase in <span class="math inline">\(x\)</span>, then that would result in an increase of</p>
<p><span class="math display">\[\frac{e^{\hat{\beta}_{0} + \hat{\beta}_{2} \, \left(x+20\right)}} {e^{\hat{\beta}_{0}+\hat{\beta}_{2} \, x}}
 =\frac{e^{\hat{\beta}_{0}} e^{\hat{\beta}_{2}\,x} e^{20\hat{\beta}_{2}}}{e^{\hat{\beta}_{0}} e^{\hat{\beta}_{2} \, x}}
 = e^{20\hat{\beta}_{2}} = \left( e^{\hat{\beta}_{2}} \right)^{20}\]</span></p>
<p>and for the writing scores we have <span class="math display">\[e^{20\hat{\beta}_{2}} = \left( e^{\hat{\beta}_{2}} \right)^{20}=1.01^{20} = 1.22\]</span> or a 22% increase in writing score for a 20-point increase in reading score.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="8-LogTransformations-Chapter.html#cb235-1" aria-hidden="true"></a><span class="co"># to make emmeans calculate this, we must specify a 1-unit or 20-unit increase</span></span>
<span id="cb235-2"><a href="8-LogTransformations-Chapter.html#cb235-2" aria-hidden="true"></a><span class="kw">emmeans</span>(model, pairwise <span class="op">~</span><span class="st"> </span>read, <span class="dt">at=</span><span class="kw">list</span>(<span class="dt">read=</span><span class="kw">c</span>(<span class="dv">51</span>,<span class="dv">50</span>)), <span class="dt">type=</span><span class="st">&#39;response&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb235-3"><a href="8-LogTransformations-Chapter.html#cb235-3" aria-hidden="true"></a><span class="st">  </span>.[[<span class="st">&#39;contrasts&#39;</span>]]</span></code></pre></div>
<pre><code>##  contrast ratio       SE  df t.ratio p.value
##  51 / 50  1.011 0.001032 197 11.057  &lt;.0001 
## 
## Results are averaged over the levels of: gender 
## Tests are performed on the log scale</code></pre>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="8-LogTransformations-Chapter.html#cb237-1" aria-hidden="true"></a><span class="kw">emmeans</span>(model, pairwise <span class="op">~</span><span class="st"> </span>read, <span class="dt">at=</span><span class="kw">list</span>(<span class="dt">read=</span><span class="kw">c</span>(<span class="dv">70</span>,<span class="dv">50</span>)), <span class="dt">type=</span><span class="st">&#39;response&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb237-2"><a href="8-LogTransformations-Chapter.html#cb237-2" aria-hidden="true"></a><span class="st">  </span>.[[<span class="st">&#39;contrasts&#39;</span>]]</span></code></pre></div>
<pre><code>##  contrast ratio     SE  df t.ratio p.value
##  70 / 50   1.25 0.0256 197 11.057  &lt;.0001 
## 
## Results are averaged over the levels of: gender 
## Tests are performed on the log scale</code></pre>
<p>In short, we can interpret <span class="math inline">\(e^{\hat{\beta}_{i}}\)</span> as the multiplicative increase/decrease in the non-transformed response variable. Some students get confused by what is meant by a <span class="math inline">\(\%\)</span> increase or decrease in <span class="math inline">\(y\)</span>.</p>
<ul>
<li>A <span class="math inline">\(75\%\)</span> decrease in <span class="math inline">\(y\)</span> has a resulting value of <span class="math inline">\(\left(1-0.75\right)y=\left(0.25\right) y\)</span></li>
<li>A <span class="math inline">\(75\%\)</span> increase in <span class="math inline">\(y\)</span> has a resulting value of <span class="math inline">\(\left(1+0.75\right)y=\left(1.75\right) y\)</span></li>
<li>A <span class="math inline">\(100\%\)</span> increase in <span class="math inline">\(y\)</span> has a resulting value of <span class="math inline">\(\left(1+1.00\right)y= 2y\)</span> and is a doubling of <span class="math inline">\(y\)</span>.</li>
<li>A <span class="math inline">\(50\%\)</span> decrease in <span class="math inline">\(y\)</span> has a resulting value of <span class="math inline">\(\left(1-0.5\right)y=\left(0.5\right) y\)</span> and is a halving of <span class="math inline">\(y\)</span>.</li>
</ul>
</div>
<div id="un-transformed-response-log-transformed-covariate" class="section level3" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Un-transformed response, log-transformed covariate</h3>
<p>We consider the model
<span class="math display">\[y=\beta_{0}+\beta_{2}\log x+\epsilon\]</span>
and consider two different values of <span class="math inline">\(x\)</span> (which we’ll call <span class="math inline">\(x_{1}\)</span> and <span class="math inline">\(x_{2}\)</span> and we are considering the effect of moving from <span class="math inline">\(x_{1}\)</span> to <span class="math inline">\(x_{2}\)</span>) and look at the differences between the predicted values <span class="math inline">\(\hat{y}_2 - \hat{y}_1\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
\hat{y}_{2}-\hat{y}_{1} 
  &amp; =   \left[\hat{\beta}_{0}+\hat{\beta}_{2}\log x_{2}\right]-\left[\hat{\beta}_{0}+\hat{\beta}_{2}\log x_{1}\right] \\
    &amp; = \hat{\beta}_{2}\left[\log x_{2}-\log x_{1}\right] \\
    &amp; = \hat{\beta}_{2}\log\left[\frac{x_{2}}{x_{1}}\right]
    \end{aligned}\]</span></p>
<p>This means that so long as the ratio between the two x-values is constant, then the change in <span class="math inline">\(\hat{y}\)</span> is the same. So doubling the value of <span class="math inline">\(x\)</span> from 1 to 2 has the same effect on <span class="math inline">\(\hat{y}\)</span> as changing x from 50 to 100.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="8-LogTransformations-Chapter.html#cb239-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>( write <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(read), <span class="dt">data=</span>scores)</span>
<span id="cb239-2"><a href="8-LogTransformations-Chapter.html#cb239-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   -59.1       9.95     -5.94 1.28e- 8
## 2 gendermale     -5.43      1.01     -5.36 2.29e- 7
## 3 log(read)      29.0       2.53     11.5  9.98e-24</code></pre>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="8-LogTransformations-Chapter.html#cb241-1" aria-hidden="true"></a><span class="co"># predict writing scores for three females, </span></span>
<span id="cb241-2"><a href="8-LogTransformations-Chapter.html#cb241-2" aria-hidden="true"></a><span class="co"># each with a reading score 50% larger than the other previous</span></span>
<span id="cb241-3"><a href="8-LogTransformations-Chapter.html#cb241-3" aria-hidden="true"></a><span class="kw">predict</span>(model, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">gender=</span><span class="kw">rep</span>(<span class="st">&#39;female&#39;</span>,<span class="dv">3</span>),</span>
<span id="cb241-4"><a href="8-LogTransformations-Chapter.html#cb241-4" aria-hidden="true"></a>                                  <span class="dt">read=</span><span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">60</span>, <span class="dv">90</span>)))</span></code></pre></div>
<pre><code>##        1        2        3 
## 48.06622 59.84279 71.61936</code></pre>
<p>We should see a
<span class="math display">\[29.045 \; \log \left( 1.5 \right) = 11.78\]</span><br />
difference in <span class="math inline">\(\hat{y}\)</span> values for the first and second students and the second and third.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="8-LogTransformations-Chapter.html#cb243-1" aria-hidden="true"></a><span class="kw">emmeans</span>(model, pairwise<span class="op">~</span><span class="kw">log</span>(read), <span class="dt">at=</span><span class="kw">list</span>(<span class="dt">read=</span><span class="kw">c</span>(<span class="dv">60</span>,<span class="dv">40</span>)))</span></code></pre></div>
<pre><code>## $emmeans
##  read emmean    SE  df lower.CL upper.CL
##    60   57.1 0.643 197     55.9     58.4
##    40   45.4 0.806 197     43.8     46.9
## 
## Results are averaged over the levels of: gender 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast estimate   SE  df t.ratio p.value
##  60 - 40      11.8 1.02 197 11.493  &lt;.0001 
## 
## Results are averaged over the levels of: gender</code></pre>
</div>
<div id="log-transformed-response-log-transformed-covariate" class="section level3" number="8.4.3">
<h3><span class="header-section-number">8.4.3</span> Log-transformed response, log-transformed covariate</h3>
<p>This combines the interpretations in the previous two sections. We consider
<span class="math display">\[\log y=\beta_{0}+\beta_{2}\log x+\epsilon\]</span>
and we again consider two <span class="math inline">\(x\)</span> values (again <span class="math inline">\(x_{1}\)</span> and <span class="math inline">\(x_{2}\)</span>). We then examine the difference in the <span class="math inline">\(\log\hat{y}\)</span> values as
<span class="math display">\[\begin{aligned}
\log\hat{y}_{2}-\log\hat{y}_{1} &amp;= \left[\hat{\beta}_{0}+\hat{\beta}_{2}\log x_{2}\right]-\left[\hat{\beta}_{0}+\hat{\beta}_{2}\log x_{1}\right] \\
\log\left[\frac{\hat{y}_{2}}{\hat{y}_{1}}\right]    &amp;=  \hat{\beta}_{2}\log\left[\frac{x_{2}}{x_{1}}\right] \\
\log\left[\frac{\hat{y}_{2}}{\hat{y}_{1}}\right]    &amp;=  \log\left[\left(\frac{x_{2}}{x_{1}}\right)^{\hat{\beta}_{2}}\right] \\
\frac{\hat{y}_{2}}{\hat{y}_{1}} &amp;=  \left(\frac{x_{2}}{x_{1}}\right)^{\hat{\beta}_{2}}
\end{aligned}\]</span></p>
<p>This allows us to examine the effect of some arbitrary percentage increase in <span class="math inline">\(x\)</span> value as a percentage increase in <span class="math inline">\(y\)</span> value.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="8-LogTransformations-Chapter.html#cb245-1" aria-hidden="true"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(write) <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(read), <span class="dt">data=</span>scores)</span>
<span id="cb245-2"><a href="8-LogTransformations-Chapter.html#cb245-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(model)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    1.71     0.205       8.36 1.14e-14
## 2 gendermale    -0.114    0.0209     -5.48 1.27e- 7
## 3 log(read)      0.581    0.0521     11.1  1.08e-22</code></pre>
<p>which implies for a <span class="math inline">\(10\)</span>% increase in <code>read</code> score, we should see a <span class="math inline">\(1.10^{0.581}=1.056\)</span> multiplier in <code>write</code> score. That is to say, a <span class="math inline">\(10\%\)</span> increase in reading score results in a <span class="math inline">\(5\%\)</span> increase in writing score.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="8-LogTransformations-Chapter.html#cb247-1" aria-hidden="true"></a><span class="kw">emmeans</span>(model, pairwise<span class="op">~</span><span class="kw">log</span>(read), <span class="dt">at=</span><span class="kw">list</span>(<span class="dt">read=</span><span class="kw">c</span>(<span class="dv">55</span>,<span class="dv">50</span>)),</span>
<span id="cb247-2"><a href="8-LogTransformations-Chapter.html#cb247-2" aria-hidden="true"></a>         <span class="dt">var=</span><span class="st">&#39;log(read)&#39;</span>, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)</span></code></pre></div>
<pre><code>## $emmeans
##  read response    SE  df lower.CL upper.CL
##    55     53.8 0.594 197     52.6     54.9
##    50     50.9 0.535 197     49.8     51.9
## 
## Results are averaged over the levels of: gender 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale 
## 
## $contrasts
##  contrast ratio      SE  df t.ratio p.value
##  55 / 50   1.06 0.00525 197 11.148  &lt;.0001 
## 
## Results are averaged over the levels of: gender 
## Tests are performed on the log scale</code></pre>
<p>For the Galapagos islands, we had</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="8-LogTransformations-Chapter.html#cb249-1" aria-hidden="true"></a>m.s &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Species) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(Area), <span class="dt">data=</span>gala)</span>
<span id="cb249-2"><a href="8-LogTransformations-Chapter.html#cb249-2" aria-hidden="true"></a>broom<span class="op">::</span><span class="kw">tidy</span>(m.s)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    2.90     0.157      18.5  3.17e-17
## 2 log(Area)      0.389    0.0416      9.34 4.23e-10</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="8-LogTransformations-Chapter.html#cb251-1" aria-hidden="true"></a><span class="kw">emmeans</span>(m.s, pairwise<span class="op">~</span>Area, <span class="dt">at=</span><span class="kw">list</span>(<span class="dt">Area=</span><span class="kw">c</span>(<span class="dv">400</span>, <span class="dv">200</span>)), <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)</span></code></pre></div>
<pre><code>## $emmeans
##  Area response   SE df lower.CL upper.CL
##   400      187 43.7 28    116.0      302
##   200      143 30.2 28     92.7      221
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale 
## 
## $contrasts
##  contrast  ratio     SE df t.ratio p.value
##  400 / 200  1.31 0.0377 28 9.342   &lt;.0001 
## 
## Tests are performed on the log scale</code></pre>
<p>and therefore doubling of Area (i.e. the ratio of the <span class="math inline">\(Area_{2} / Area_{1} = 2\)</span>) results in a <span class="math inline">\(2^{0.389}=1.31\)</span> multiplier of the <code>Species</code> value. That is to say doubling the island area increases the number of species by <span class="math inline">\(31\%\)</span>.</p>
<p>In the table below <span class="math inline">\(\beta\)</span> represents the group offset value, or the slope value associated with <span class="math inline">\(x\)</span>. If we are in a model with multiple slopes such as an ANCOVA model, then the beta term represents the slope of whatever group you are interested.</p>
<table>
<colgroup>
<col width="18%" />
<col width="28%" />
<col width="15%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Response</th>
<th align="center">Explanatory</th>
<th align="center">Term</th>
<th align="left">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\log(y)\)</span></td>
<td align="center">Categorical</td>
<td align="center"><span class="math inline">\(e^\beta\)</span></td>
<td align="left">Switching from the reference group results in this <em>multiplicative</em> change on <span class="math inline">\(y\)</span>.</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\log(y)\)</span></td>
<td align="center">Continuous <span class="math inline">\(x\)</span></td>
<td align="center"><span class="math inline">\(e^\beta\)</span></td>
<td align="left">A 1-unit change in <span class="math inline">\(x\)</span> results in this <em>multiplicative</em> change on <span class="math inline">\(y\)</span>.</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\log(y)\)</span></td>
<td align="center">Continuous <span class="math inline">\(x\)</span></td>
<td align="center"><span class="math inline">\(\left(e^\beta\right)^\delta\)</span></td>
<td align="left">A <span class="math inline">\(\delta\)</span>-unit change in <span class="math inline">\(x\)</span> results in this <em>multiplicative</em> change on <span class="math inline">\(y\)</span>.</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(y\)</span></td>
<td align="center">Continuous <span class="math inline">\(\log(x)\)</span></td>
<td align="center"><span class="math inline">\(\beta \, \log\left(\frac{x_2}{x_1}\right)\)</span></td>
<td align="left">The proportional change in <span class="math inline">\(x\)</span> results in an <em>additive</em> change on <span class="math inline">\(y\)</span>.</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\log(y)\)</span></td>
<td align="center">Continuous <span class="math inline">\(\log(x)\)</span></td>
<td align="center"><span class="math inline">\(\left(\frac{x_2}{x_1}\right)^\beta\)</span></td>
<td align="left">The proportional change in <span class="math inline">\(x\)</span> results in the <em>multiplicative</em> change on <span class="math inline">\(y\)</span>.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="Transformation-Exercises" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>In the ANCOVA chapter, we examined the relationship on dose of vitamin C on guinea pig tooth growth based on how the vitamin was delivered (orange juice vs a pill supplement).</p>
<ol style="list-style-type: lower-alpha">
<li>Load the <code>ToothGrowth</code> data which is pre-loaded in base R and calculate the <span class="math inline">\(\log_{10}\)</span> dose level.</li>
<li>Plot the data with log dose level on the x-axis and tooth length growth on the y-axis. Color the points by supplement type.</li>
<li>Fit a linear model using the log transformed dose.</li>
<li>Interpret the effect of doubling the dose (NOT LOG DOSE!) on tooth growth for the OJ and VC supplement groups.</li>
</ol></li>
<li><p>We will consider the relationship between income and race using a subset of employed individuals from the American Community Survey.</p>
<ol style="list-style-type: lower-alpha">
<li>Load the <code>EmployedACS</code> dataset from the <code>Lock5Data</code> package.</li>
<li>Create a box plot showing the relationship between <code>Race</code> and <code>Income</code>.</li>
<li>Consider the boxcox family of transformations of <code>Income</code>. What transformation seems appropriate.</li>
<li>Using your transformed <code>Income</code> variable, fit an ANOVA model and evaluate the relationship between race and income utilizing these data. <em>Importantly, we haven’t accounted for many sources of variability such as education level and job type. There is much more to consider than just this simple analysis.</em></li>
</ol></li>
<li><p>ANOVA with log(y) response where there is a significant difference.</p></li>
<li><p>ANCOVA with log(y) and log(x)</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="7-Diagnostics-Chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="9-MultipleRegression-Chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"],
"google": false,
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dereksonderegger/571/blob/master/08_Transformations.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/dereksonderegger/571/raw/master/08_Transformations.Rmd",
"text": null
},
"download": [["Statistical_Methods_II.pdf", "PDF"], ["Statistical_Methods_II.epub", "EPUB"]],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
